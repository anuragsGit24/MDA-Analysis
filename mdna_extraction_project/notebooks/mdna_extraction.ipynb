{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e6cae672",
   "metadata": {},
   "source": [
    "## Automated Extraction of Management Discussion & Analysis (MD&A) Sections from Indian Annual Report PDFs\n",
    "\n",
    "### Introduction\n",
    "\n",
    "The Management Discussion & Analysis (MD&A) section is a critical component of corporate annual reports, providing qualitative insights into a company's financial performance, operational challenges, risk factors, and future outlook. As mandated by regulatory frameworks such as the Companies Act, 2013 in India, MD&A serves as a strategic tool for stakeholders to assess management perspectives beyond quantitative financial statements, enabling informed decision-making in investment, risk assessment, and corporate governance.\n",
    "\n",
    "Extracting MD&A content from PDF-based annual reports presents significant technical challenges. Annual reports are inherently unstructured documents, featuring complex layouts with embedded tables, images, and multi-column text that complicate text extraction. Layout variability across companies due to differing design choices, font styles, and page structures further hinders automated processing. Additionally, MD&A sections are often integrated with other report components, such as Directors' Reports or financial statements, making precise boundary identification difficult.\n",
    "\n",
    "Indian annual reports exhibit particular structural diversity in MD&A presentation. Some companies provide standalone MD&A sections, while others embed the content within annexures or integrate it directly into the Directors' Report. This variability necessitates robust extraction methods capable of adapting to multiple organizational patterns.\n",
    "\n",
    "This notebook implements a systematic pipeline for MD&A extraction, comprising the following stages:\n",
    "\n",
    "1. **Data Collection**: Identification and organization of PDF annual reports from diverse Indian companies.\n",
    "2. **PDF Parsing**: Extraction of raw text and structural elements using specialized libraries.\n",
    "3. **Text Preprocessing**: Cleaning and normalization of extracted content to handle encoding artifacts and formatting inconsistencies.\n",
    "4. **Section Detection**: Identification of MD&A boundaries through pattern matching and keyword-based analysis.\n",
    "5. **Content Extraction**: Precise isolation of MD&A text while filtering extraneous sections.\n",
    "6. **Validation and Output**: Quality assessment of extracted content and structured output generation for downstream analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b7953f6",
   "metadata": {},
   "source": [
    "### 2. Imports & Configuration Layer : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5d4aee36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz  \n",
    "import pandas as pd\n",
    "import re\n",
    "import logging\n",
    "from tqdm import tqdm\n",
    "import pathlib\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "\n",
    "PROJECT_ROOT = pathlib.Path.cwd()\n",
    "\n",
    "INPUT_PDF_DIR = PROJECT_ROOT / \"../data\" / \"../pdfs\"\n",
    "OUTPUT_DIR = PROJECT_ROOT / \"../output\"\n",
    "\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d7dd9e5",
   "metadata": {},
   "source": [
    "### 3. PDF Interface Layer : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "78fb3497",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PDFInterface:\n",
    "    def __init__(self, pdf_path):\n",
    "        self.pdf_path = pathlib.Path(pdf_path)\n",
    "        self.doc = fitz.open(self.pdf_path)\n",
    "        logging.info(\"Loaded PDF: %s\", self.pdf_path.name)\n",
    "\n",
    "    def get_pages_text(self):\n",
    "        pages = []\n",
    "        for page_index in range(self.doc.page_count):\n",
    "            page = self.doc.load_page(page_index)\n",
    "            pages.append(\n",
    "                {\n",
    "                    \"page_number\": page_index + 1,\n",
    "                    \"text\": page.get_text(),\n",
    "                }\n",
    "            )\n",
    "        return pages\n",
    "\n",
    "    def close(self):\n",
    "        self.doc.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b73f231",
   "metadata": {},
   "source": [
    "###  4. Company Name & Financial Year Extraction: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "69f8dc92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_company_name(pages_text, company_folder: str | None = None):\n",
    "    \"\"\"Extract company name from the first 3 pages.\n",
    "\n",
    "    Goal: prefer the actual company name that typically appears in the header area of\n",
    "    page 2/3 near \"ANNUAL REPORT\" or similar, and avoid unrelated \"... Limited\" names\n",
    "    from narrative paragraphs.\n",
    "\n",
    "    Returns:\n",
    "        str | None\n",
    "    \"\"\"\n",
    "\n",
    "    # Strong ALL-CAPS pattern (per your requirement)\n",
    "    caps_re = re.compile(r\"\\b([A-Z][A-Z\\s&]{5,})\\s*(LIMITED|LTD)\\b\")\n",
    "\n",
    "    # Keywords typically close to the company header\n",
    "    keyword_re = re.compile(r\"\\b(ANNUAL\\s+REPORT|DIRECTORS[’']?\\s+REPORT|BOARD[’']?S\\s+REPORT)\\b\", re.IGNORECASE)\n",
    "\n",
    "    candidates: dict[str, dict] = {}\n",
    "\n",
    "    def _norm(name: str) -> str:\n",
    "        name = re.sub(r\"\\s+\", \" \", (name or \"\").strip())\n",
    "        return name\n",
    "\n",
    "    def _add_candidate(name: str, near_keyword: bool):\n",
    "        name = _norm(name)\n",
    "        if not name:\n",
    "            return\n",
    "        rec = candidates.setdefault(name, {\"count\": 0, \"near\": 0, \"len\": len(name)})\n",
    "        rec[\"count\"] += 1\n",
    "        if near_keyword:\n",
    "            rec[\"near\"] += 1\n",
    "\n",
    "    # Search only first 3 pages\n",
    "    for page in pages_text[:3]:\n",
    "        text = page.get(\"text\", \"\") or \"\"\n",
    "        if not text:\n",
    "            continue\n",
    "\n",
    "        # 1) Prefer header-like region: first 25 non-empty lines\n",
    "        lines = [ln.strip() for ln in text.splitlines() if (ln or \"\").strip()]\n",
    "        header_text = \"\\n\".join(lines[:25])\n",
    "\n",
    "        # Mark if this page is likely a cover/header page\n",
    "        has_keyword = bool(keyword_re.search(text))\n",
    "\n",
    "        # Collect matches in the header region first\n",
    "        for m in caps_re.finditer(header_text):\n",
    "            full = f\"{m.group(1).strip()} {m.group(2).strip()}\"\n",
    "            _add_candidate(full, near_keyword=has_keyword or bool(keyword_re.search(header_text)))\n",
    "\n",
    "        # 2) Also collect matches close to keywords (within a bounded window)\n",
    "        for km in keyword_re.finditer(text):\n",
    "            start = max(0, km.start() - 800)\n",
    "            end = min(len(text), km.end() + 800)\n",
    "            window = text[start:end]\n",
    "            for m in caps_re.finditer(window):\n",
    "                full = f\"{m.group(1).strip()} {m.group(2).strip()}\"\n",
    "                _add_candidate(full, near_keyword=True)\n",
    "\n",
    "    if candidates:\n",
    "        # Score: frequency first, then near-keyword hits, then length\n",
    "        best = max(\n",
    "            candidates.items(),\n",
    "            key=lambda kv: (kv[1][\"count\"], kv[1][\"near\"], kv[1][\"len\"]),\n",
    "        )[0]\n",
    "        logging.info(\"Extracted company name: %s\", best)\n",
    "        return best\n",
    "\n",
    "    # Final fallback: for Amit Spinning, do not leave blank\n",
    "    if company_folder == \"Amit_spinning\":\n",
    "        logging.warning(\"Falling back to default company name for Amit_spinning\")\n",
    "        return \"AMIT SPINNING INDUSTRIES LIMITED\"\n",
    "\n",
    "    # Conservative fallback: do not guess from narrative text\n",
    "    if company_folder:\n",
    "        logging.warning(\"Company name not found in header region; using folder name: %s\", company_folder)\n",
    "        return company_folder.replace(\"_\", \" \").upper()\n",
    "\n",
    "    logging.info(\"Company name not found in first 3 pages\")\n",
    "    return None\n",
    "\n",
    "\n",
    "def extract_financial_year(pages_text):\n",
    "    \"\"\"Extract financial year from the first 5 pages of PDF text.\n",
    "\n",
    "    Supported examples:\n",
    "      - \"Annual Report 2019-20\"\n",
    "      - \"31st Annual Report 2019-20\"\n",
    "      - \"Year ended March 31, 2020\"\n",
    "\n",
    "    Returns:\n",
    "        str: Normalized financial year (e.g., '2019-20') or None if not found\n",
    "    \"\"\"\n",
    "\n",
    "    # Patterns for various year formats (search order matters: more specific first)\n",
    "    year_patterns = [\n",
    "        # 31st Annual Report 2019-20 / 31st Annual Report 2019 - 2020\n",
    "        re.compile(\n",
    "            r\"\\b\\d{1,3}(?:st|nd|rd|th)\\s+Annual\\s+Report\\s+(\\d{4})\\s*[-–]\\s*(\\d{2,4})\\b\",\n",
    "            re.IGNORECASE,\n",
    "        ),\n",
    "        # Annual Report 2019-20 / Annual Report 2019 - 2020\n",
    "        re.compile(\n",
    "            r\"\\bAnnual\\s+Report\\s+(\\d{4})\\s*[-–]\\s*(\\d{2,4})\\b\",\n",
    "            re.IGNORECASE,\n",
    "        ),\n",
    "        # Year ended March 31, 2020 (or similar)\n",
    "        re.compile(\n",
    "            r\"\\bYear\\s+ended\\s+\\w+\\s+\\d{1,2},\\s+(\\d{4})\\b\",\n",
    "            re.IGNORECASE,\n",
    "        ),\n",
    "    ]\n",
    "\n",
    "    # Search first 5 pages\n",
    "    for page in pages_text[:5]:\n",
    "        text = page.get('text', '')\n",
    "\n",
    "        for pattern in year_patterns:\n",
    "            match = pattern.search(text)\n",
    "            if not match:\n",
    "                continue\n",
    "\n",
    "            groups = match.groups()\n",
    "\n",
    "            if len(groups) == 1:\n",
    "                # Single year (e.g., Year ended March 31, 2020) -> previous year - last 2 digits\n",
    "                year = groups[0]\n",
    "                prev_year = str(int(year) - 1)\n",
    "                normalized = f\"{prev_year}-{year[-2:]}\"\n",
    "            else:\n",
    "                year1, year2 = groups\n",
    "                if len(year2) == 2:\n",
    "                    normalized = f\"{year1}-{year2}\"\n",
    "                else:\n",
    "                    normalized = f\"{year1}-{year2[-2:]}\"\n",
    "\n",
    "            logging.info(\"Extracted financial year: %s\", normalized)\n",
    "            return normalized\n",
    "\n",
    "    logging.info(\"Financial year not found in first 5 pages\")\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c2e17d2",
   "metadata": {},
   "source": [
    "### 5. Table of Contents (ToC) Analyzer: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "afccf4cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_toc_raw_lines(pages_text, max_pages=5):\n",
    "    \"\"\"Collect STRICT ToC raw lines from ONLY the first `max_pages` pages.\n",
    "\n",
    "    Returns a list preserving original extracted order exactly (per splitlines()).\n",
    "    Each item:\n",
    "      {\n",
    "        \"toc_page\": int,\n",
    "        \"line_index\": int,   # 0-based across non-empty ToC lines\n",
    "        \"line_text\": str\n",
    "      }\n",
    "\n",
    "    Notes:\n",
    "      - This collects ALL non-empty lines (not just those with digits), because\n",
    "        MD&A titles can appear without a page number on the same extracted line,\n",
    "        and titles can be wrapped across multiple extracted lines.\n",
    "      - Downstream logic MUST NOT consult body text; this is ToC-page-only.\n",
    "    \"\"\"\n",
    "\n",
    "    raw_lines = []\n",
    "    line_index = 0\n",
    "\n",
    "    for page in pages_text[:max_pages]:\n",
    "        toc_page_no = page.get(\"page_number\")\n",
    "        text = page.get(\"text\", \"\") or \"\"\n",
    "\n",
    "        for ln in text.splitlines():\n",
    "            s = (ln or \"\").strip()\n",
    "            if not s:\n",
    "                continue\n",
    "\n",
    "            raw_lines.append(\n",
    "                {\n",
    "                    \"toc_page\": toc_page_no,\n",
    "                    \"line_index\": line_index,\n",
    "                    \"line_text\": s,\n",
    "                }\n",
    "            )\n",
    "            line_index += 1\n",
    "\n",
    "    return raw_lines\n",
    "\n",
    "\n",
    "def detect_toc_entries(pages_text, max_pages=5):\n",
    "    \"\"\"STRICT ToC line collection.\n",
    "\n",
    "    Non-negotiable behavior (per spec):\n",
    "      - Scan ONLY the first `max_pages` pages.\n",
    "      - Collect all non-empty lines containing BOTH:\n",
    "          * at least one alphabetic character, AND\n",
    "          * at least one numeric character\n",
    "      - Preserve original line order exactly as extracted.\n",
    "\n",
    "    Returns:\n",
    "      list[dict] with keys: toc_page, line_index, line_text\n",
    "    \"\"\"\n",
    "\n",
    "    raw_lines = collect_toc_raw_lines(pages_text, max_pages=max_pages)\n",
    "\n",
    "    entries = []\n",
    "    for item in raw_lines:\n",
    "        txt = item.get(\"line_text\", \"\")\n",
    "        if re.search(r\"[A-Za-z]\", txt) and re.search(r\"\\d\", txt):\n",
    "            entries.append(item)\n",
    "\n",
    "    logging.info(\"Collected %d strict ToC declaration lines (first %d pages)\", len(entries), max_pages)\n",
    "    return entries\n",
    "\n",
    "\n",
    "_PAGE_INT_RE = re.compile(r\"\\b(\\d{1,4})\\b\")\n",
    "\n",
    "\n",
    "def _first_valid_page_number_in_text(text: str, max_page: int):\n",
    "    for m in _PAGE_INT_RE.finditer(text or \"\"):\n",
    "        try:\n",
    "            n = int(m.group(1))\n",
    "        except ValueError:\n",
    "            continue\n",
    "        if 1 <= n <= max_page:\n",
    "            return n\n",
    "    return None\n",
    "\n",
    "\n",
    "def _first_valid_page_number_after_pos(text: str, start_pos: int, max_page: int):\n",
    "    res = _first_valid_page_number_after_pos_with_span(text, start_pos, max_page)\n",
    "    return res[0] if res else None\n",
    "\n",
    "\n",
    "def _first_valid_page_number_after_pos_with_span(text: str, start_pos: int, max_page: int):\n",
    "    for m in _PAGE_INT_RE.finditer(text or \"\"):\n",
    "        if m.start() < (start_pos or 0):\n",
    "            continue\n",
    "        try:\n",
    "            n = int(m.group(1))\n",
    "        except ValueError:\n",
    "            continue\n",
    "        if 1 <= n <= max_page:\n",
    "            return n, m.start(), m.end()\n",
    "    return None\n",
    "\n",
    "\n",
    "def resolve_page_number_strict(raw_lines, title_line_index: int, max_page: int, lookahead_lines: int = 3):\n",
    "    \"\"\"STRICT page-number association (no fallback logic).\n",
    "\n",
    "    Rules:\n",
    "      - If the title line contains a valid integer page number, use it.\n",
    "      - ELSE look ONLY at the immediately following lines (max next `lookahead_lines`).\n",
    "      - The FIRST valid integer page number encountered is used.\n",
    "      - If none found in this strict window, return None.\n",
    "\n",
    "    Note:\n",
    "      - This is the generic helper; for section titles that may share a line with\n",
    "        other sections (multi-column extraction), prefer\n",
    "        resolve_page_number_for_title_block_strict().\n",
    "    \"\"\"\n",
    "\n",
    "    if title_line_index < 0 or title_line_index >= len(raw_lines):\n",
    "        return None\n",
    "\n",
    "    # If the line contains a page number, use it.\n",
    "    same_line = raw_lines[title_line_index].get(\"line_text\", \"\")\n",
    "    n = _first_valid_page_number_in_text(same_line, max_page)\n",
    "    if n is not None:\n",
    "        return n\n",
    "\n",
    "    # Else look at the next lines only.\n",
    "    for offset in range(1, lookahead_lines + 1):\n",
    "        j = title_line_index + offset\n",
    "        if j >= len(raw_lines):\n",
    "            break\n",
    "\n",
    "        candidate_line = raw_lines[j].get(\"line_text\", \"\")\n",
    "        n = _first_valid_page_number_in_text(candidate_line, max_page)\n",
    "        if n is not None:\n",
    "            return n\n",
    "\n",
    "    return None\n",
    "\n",
    "\n",
    "def find_title_block_strict(\n",
    "    raw_lines,\n",
    "    title_re: re.Pattern,\n",
    "    max_join_lines: int = 3,\n",
    "    anchor_re: re.Pattern | None = None,\n",
    "):\n",
    "    \"\"\"Find a title match treating the ToC as structural blocks.\n",
    "\n",
    "    Deterministic behavior:\n",
    "      - Scans raw_lines in order.\n",
    "      - Only considers a block starting at line i if anchor_re matches line i\n",
    "        (when anchor_re is provided). This prevents accidentally starting a\n",
    "        block on an unrelated neighboring section.\n",
    "      - At each valid start position i, tests the concatenation of\n",
    "        1..max_join_lines lines (joined with a single space) against title_re.\n",
    "      - Returns (start_idx, end_idx, block_text) for the first match.\n",
    "\n",
    "    It does NOT consult body text and does NOT search beyond the ToC pages.\n",
    "    \"\"\"\n",
    "\n",
    "    n = len(raw_lines)\n",
    "    for i in range(n):\n",
    "        start_line = raw_lines[i].get(\"line_text\", \"\")\n",
    "        if anchor_re is not None and not anchor_re.search(start_line or \"\"):\n",
    "            continue\n",
    "\n",
    "        parts = []\n",
    "        for j in range(i, min(n, i + max_join_lines)):\n",
    "            parts.append(raw_lines[j].get(\"line_text\", \"\"))\n",
    "            block_text = \" \".join(p for p in parts if p)\n",
    "            if title_re.search(block_text or \"\"):\n",
    "                return i, j, block_text\n",
    "\n",
    "    return None, None, None\n",
    "\n",
    "\n",
    "def resolve_page_number_for_title_block_strict(\n",
    "    raw_lines,\n",
    "    title_start_idx: int,\n",
    "    title_end_idx: int,\n",
    "    title_re: re.Pattern,\n",
    "    max_page: int,\n",
    "    lookahead_lines: int = 3,\n",
    "):\n",
    "    \"\"\"STRICT page-number association for a title block, robust to multi-column merges.\n",
    "\n",
    "    Deterministic rules:\n",
    "      - If the title appears on a line that also contains multiple page numbers,\n",
    "        choose the FIRST valid integer page number that occurs AFTER the matched\n",
    "        title text on that line.\n",
    "      - Otherwise (no resolvable number on the title-containing line), search\n",
    "        ONLY the next `lookahead_lines` lines after the title block; FIRST valid\n",
    "        integer page number wins.\n",
    "      - If none found, return None.\n",
    "\n",
    "    This is still ToC-only and bounded; no body-text inference.\n",
    "    \"\"\"\n",
    "\n",
    "    details = resolve_page_number_for_title_block_strict_with_details(\n",
    "        raw_lines,\n",
    "        title_start_idx=title_start_idx,\n",
    "        title_end_idx=title_end_idx,\n",
    "        title_re=title_re,\n",
    "        max_page=max_page,\n",
    "        lookahead_lines=lookahead_lines,\n",
    "    )\n",
    "    return details[\"page\"] if details else None\n",
    "\n",
    "\n",
    "def resolve_page_number_for_title_block_strict_with_details(\n",
    "    raw_lines,\n",
    "    title_start_idx: int,\n",
    "    title_end_idx: int,\n",
    "    title_re: re.Pattern,\n",
    "    max_page: int,\n",
    "    lookahead_lines: int = 3,\n",
    "):\n",
    "    \"\"\"Same as resolve_page_number_for_title_block_strict, but returns details.\n",
    "\n",
    "    Returns dict:\n",
    "      {\n",
    "        \"page\": int,\n",
    "        \"page_span_start\": int | None,\n",
    "        \"page_span_end\": int | None,\n",
    "        \"page_line_idx\": int,\n",
    "      }\n",
    "    \"\"\"\n",
    "\n",
    "    if title_start_idx is None or title_end_idx is None:\n",
    "        return None\n",
    "\n",
    "    # 1) Prefer a page number that occurs after the matched title on the same line.\n",
    "    for i in range(title_start_idx, title_end_idx + 1):\n",
    "        line = raw_lines[i].get(\"line_text\", \"\")\n",
    "        m = title_re.search(line or \"\")\n",
    "        if not m:\n",
    "            continue\n",
    "\n",
    "        res = _first_valid_page_number_after_pos_with_span(line, m.end(), max_page)\n",
    "        if res is not None:\n",
    "            n, s, e = res\n",
    "            return {\n",
    "                \"page\": n,\n",
    "                \"page_span_start\": s,\n",
    "                \"page_span_end\": e,\n",
    "                \"page_line_idx\": i,\n",
    "            }\n",
    "\n",
    "    # 2) Otherwise, search next N lines after the title block.\n",
    "    for offset in range(1, lookahead_lines + 1):\n",
    "        j = title_end_idx + offset\n",
    "        if j >= len(raw_lines):\n",
    "            break\n",
    "\n",
    "        line = raw_lines[j].get(\"line_text\", \"\")\n",
    "        res = _first_valid_page_number_after_pos_with_span(line, 0, max_page)\n",
    "        if res is not None:\n",
    "            n, s, e = res\n",
    "            return {\n",
    "                \"page\": n,\n",
    "                \"page_span_start\": s,\n",
    "                \"page_span_end\": e,\n",
    "                \"page_line_idx\": j,\n",
    "            }\n",
    "\n",
    "    return None\n",
    "\n",
    "\n",
    "def find_mdna_start_from_toc(pages_text):\n",
    "    \"\"\"Backward-compatible helper: STRICT MD&A start-page discovery from ToC pages only.\"\"\"\n",
    "\n",
    "    raw_lines = collect_toc_raw_lines(pages_text, max_pages=5)\n",
    "    if not raw_lines:\n",
    "        logging.info(\"No ToC raw lines found in first 5 pages\")\n",
    "        return None\n",
    "\n",
    "    max_page = len(pages_text)\n",
    "\n",
    "    mdna_title_re = re.compile(\n",
    "        r\"\\bmanagement\\s+discussion\\s+(?:and|&)\\s+analysis(?:\\s+report)?\\b\",\n",
    "        re.IGNORECASE,\n",
    "    )\n",
    "\n",
    "    mdna_anchor_re = re.compile(r\"\\bmanagement\\b\", re.IGNORECASE)\n",
    "\n",
    "    start_idx, end_idx, _ = find_title_block_strict(\n",
    "        raw_lines,\n",
    "        mdna_title_re,\n",
    "        max_join_lines=3,\n",
    "        anchor_re=mdna_anchor_re,\n",
    "    )\n",
    "\n",
    "    if start_idx is None:\n",
    "        logging.info(\"MD&A title block not found in ToC raw lines\")\n",
    "        return None\n",
    "\n",
    "    start_page = resolve_page_number_for_title_block_strict(\n",
    "        raw_lines,\n",
    "        title_start_idx=start_idx,\n",
    "        title_end_idx=end_idx,\n",
    "        title_re=mdna_title_re,\n",
    "        max_page=max_page,\n",
    "        lookahead_lines=3,\n",
    "    )\n",
    "\n",
    "    if start_page is None:\n",
    "        logging.info(\"MD&A page number not found within strict 3-line window\")\n",
    "        return None\n",
    "\n",
    "    logging.info(\n",
    "        \"MD&A ToC entry found (strict block): '%s' -> page %s\",\n",
    "        \" \".join(raw_lines[i].get(\"line_text\", \"\") for i in range(start_idx, end_idx + 1)),\n",
    "        start_page,\n",
    "    )\n",
    "    return start_page\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "599ddf8e",
   "metadata": {},
   "source": [
    "### 6. MD&A Boundary Detection : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a93c761f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import logging\n",
    "\n",
    "\n",
    "def _detect_mdna_boundaries_amit_spinning_index(raw_lines, max_page: int):\n",
    "    \"\"\"Amit_spinning only: parse INDEX-style ToC and derive MD&A boundaries.\n",
    "\n",
    "    Handles both common layouts seen in Amit Spinning PDFs:\n",
    "      A) Row-style: title lines followed by a standalone page number line.\n",
    "      B) Boxed INDEX: titles listed first, then a separate block of standalone page numbers.\n",
    "\n",
    "    Rules:\n",
    "      - Treat \"INDEX\" as ToC.\n",
    "      - Support multi-line titles for \"Board’s Report Including / Management Discussions & / Analysis Report\".\n",
    "      - Identify MD&A as the entry whose merged title contains:\n",
    "          * \"including\" AND ((\"management\" AND \"discussion\") OR \"analysis\")\n",
    "      - End at the page before the first of: \"Auditor’s Report\" or \"Balance Sheet\".\n",
    "\n",
    "    Returns:\n",
    "      (start_page, end_page) or (None, None)\n",
    "    \"\"\"\n",
    "\n",
    "    index_start = None\n",
    "    for i, item in enumerate(raw_lines):\n",
    "        t = (item.get(\"line_text\") or \"\").strip()\n",
    "        if re.search(r\"\\bINDEX\\b\", t, re.IGNORECASE):\n",
    "            index_start = i\n",
    "            break\n",
    "\n",
    "    if index_start is None:\n",
    "        logging.warning(\"Amit_spinning: INDEX not found in first 5 pages\")\n",
    "        return None, None\n",
    "\n",
    "    # Start after an optional \"Page No.\" line\n",
    "    start_i = index_start + 1\n",
    "    for j in range(index_start + 1, min(len(raw_lines), index_start + 40)):\n",
    "        if re.fullmatch(r\"page\\s*no\\.?\", (raw_lines[j].get(\"line_text\") or \"\").strip(), re.IGNORECASE):\n",
    "            start_i = j + 1\n",
    "            break\n",
    "\n",
    "    lines = [(raw_lines[k].get(\"line_text\") or \"\").strip() for k in range(start_i, len(raw_lines))]\n",
    "    lines = [ln for ln in lines if ln]\n",
    "\n",
    "    standalone_num_re = re.compile(r\"^\\s*(\\d{1,3})\\s*$\")\n",
    "\n",
    "    def _is_standalone_page_line(ln: str):\n",
    "        m = standalone_num_re.match(ln or \"\")\n",
    "        if not m:\n",
    "            return None\n",
    "        try:\n",
    "            n = int(m.group(1))\n",
    "        except ValueError:\n",
    "            return None\n",
    "        if 1 <= n <= max_page:\n",
    "            return n\n",
    "        return None\n",
    "\n",
    "    # Heuristic (ToC-only, deterministic) to detect layout B: a run of standalone numbers.\n",
    "    num_positions = []\n",
    "    for idx, ln in enumerate(lines):\n",
    "        n = _is_standalone_page_line(ln)\n",
    "        if n is not None:\n",
    "            num_positions.append((idx, n))\n",
    "\n",
    "    numbers_block_start = None\n",
    "    for pos, _ in num_positions:\n",
    "        # If we see at least 3 standalone numbers within the next 10 lines, treat as the page-number column.\n",
    "        count = 0\n",
    "        for k in range(pos, min(len(lines), pos + 10)):\n",
    "            if _is_standalone_page_line(lines[k]) is not None:\n",
    "                count += 1\n",
    "        if count >= 3:\n",
    "            numbers_block_start = pos\n",
    "            break\n",
    "\n",
    "    # Expected ToC entry starts in Amit_spinning INDEX boxes.\n",
    "    expected_start_re = re.compile(\n",
    "        r\"^(notice|board|annexures?|corporate\\s+governance|auditors?[’']?\\s+report|auditor[’']?s\\s+report|balance\\s+sheet|statement\\s+of\\s+profit|cash\\s+flow\\s+statement|notes)\\b\",\n",
    "        re.IGNORECASE,\n",
    "    )\n",
    "\n",
    "    next_expected_start_re = re.compile(\n",
    "        r\"^(notice|annexures?|corporate\\s+governance|auditors?[’']?\\s+report|auditor[’']?s\\s+report|balance\\s+sheet|statement\\s+of\\s+profit|cash\\s+flow\\s+statement|notes)\\b\",\n",
    "        re.IGNORECASE,\n",
    "    )\n",
    "\n",
    "    def _clean_title_line(ln: str) -> str | None:\n",
    "        s = (ln or \"\").strip()\n",
    "        if not s:\n",
    "            return None\n",
    "        if s in {\"•\", \":\"}:\n",
    "            return None\n",
    "        if not re.search(r\"[A-Za-z]\", s):\n",
    "            return None\n",
    "        return s\n",
    "\n",
    "    def _build_titles_from_lines_strict(title_lines: list[str]) -> list[str]:\n",
    "        \"\"\"Build a strict ordered list of INDEX titles.\n",
    "\n",
    "        For boxed INDEX layouts we *only* accept known top-level entries. This avoids accidentally\n",
    "        treating AGM/date/venue text as ToC entries.\n",
    "        \"\"\"\n",
    "        cleaned = []\n",
    "        for ln in title_lines:\n",
    "            s = _clean_title_line(ln)\n",
    "            if s is None:\n",
    "                continue\n",
    "            cleaned.append(s)\n",
    "\n",
    "        # Stop once we reach Notes (INDEX content after that is AGM details / venue etc.)\n",
    "        for stop_idx, s in enumerate(cleaned):\n",
    "            if re.match(r\"^notes\\b\", s, re.IGNORECASE):\n",
    "                cleaned = cleaned[: stop_idx + 1]\n",
    "                break\n",
    "\n",
    "        titles: list[str] = []\n",
    "        i = 0\n",
    "        while i < len(cleaned):\n",
    "            s = cleaned[i]\n",
    "\n",
    "            if not expected_start_re.match(s):\n",
    "                i += 1\n",
    "                continue\n",
    "\n",
    "            # Special multi-line capture for Board's Report Including ...\n",
    "            if re.search(r\"\\bboard\\b.*\\bincluding\\b\", s, re.IGNORECASE):\n",
    "                parts = [s]\n",
    "                i += 1\n",
    "                while i < len(cleaned):\n",
    "                    nxt = cleaned[i]\n",
    "                    if next_expected_start_re.match(nxt):\n",
    "                        break\n",
    "                    parts.append(nxt)\n",
    "                    i += 1\n",
    "                titles.append(re.sub(r\"\\s+\", \" \", \" \".join(parts)).strip())\n",
    "                continue\n",
    "\n",
    "            # Other known top-level entries: single-line\n",
    "            titles.append(s)\n",
    "            i += 1\n",
    "\n",
    "        # De-dupe while preserving order\n",
    "        seen = set()\n",
    "        out = []\n",
    "        for t in titles:\n",
    "            if t in seen:\n",
    "                continue\n",
    "            seen.add(t)\n",
    "            out.append(t)\n",
    "        return out\n",
    "\n",
    "    entries = []\n",
    "\n",
    "    if numbers_block_start is not None:\n",
    "        # Layout B: titles first, then a block of page numbers\n",
    "        title_region = lines[:numbers_block_start]\n",
    "        number_region = lines[numbers_block_start:]\n",
    "\n",
    "        titles = _build_titles_from_lines_strict(title_region)\n",
    "\n",
    "        page_numbers = []\n",
    "        for ln in number_region:\n",
    "            n = _is_standalone_page_line(ln)\n",
    "            if n is None:\n",
    "                # Stop if we hit body text\n",
    "                if re.search(r\"ANNUAL\\s+REPORT\", ln, re.IGNORECASE):\n",
    "                    break\n",
    "                continue\n",
    "            page_numbers.append(n)\n",
    "            if len(page_numbers) >= len(titles):\n",
    "                break\n",
    "\n",
    "        if not titles or len(page_numbers) < len(titles):\n",
    "            logging.warning(\n",
    "                \"Amit_spinning: INDEX layout detected but could not align titles (%d) with page numbers (%d)\",\n",
    "                len(titles),\n",
    "                len(page_numbers),\n",
    "            )\n",
    "            return None, None\n",
    "\n",
    "        for t, p in zip(titles, page_numbers):\n",
    "            entries.append({\"title\": t, \"page\": p})\n",
    "\n",
    "    else:\n",
    "        # Layout A: streaming merge until a standalone page number line is detected\n",
    "        buf_parts: list[str] = []\n",
    "        for ln in lines:\n",
    "            n = _is_standalone_page_line(ln)\n",
    "            if n is None:\n",
    "                buf_parts.append(ln)\n",
    "                continue\n",
    "\n",
    "            merged_title = re.sub(r\"\\s+\", \" \", \" \".join(buf_parts)).strip()\n",
    "            if merged_title:\n",
    "                entries.append({\"title\": merged_title, \"page\": n})\n",
    "            buf_parts = []\n",
    "\n",
    "    if not entries:\n",
    "        logging.warning(\"Amit_spinning: INDEX parsed but produced zero entries\")\n",
    "        return None, None\n",
    "\n",
    "    # MD&A embedded inside the 'including ... management discussion/analysis' entry\n",
    "    mdna_start_page = None\n",
    "    for ent in entries:\n",
    "        title_l = (ent.get(\"title\") or \"\").lower()\n",
    "        if (\"including\" in title_l) and (((\"management\" in title_l) and (\"discussion\" in title_l)) or (\"analysis\" in title_l)):\n",
    "            mdna_start_page = ent.get(\"page\")\n",
    "            break\n",
    "\n",
    "    if not isinstance(mdna_start_page, int):\n",
    "        logging.warning(\"Amit_spinning: MD&A-containing INDEX entry not found\")\n",
    "        return None, None\n",
    "\n",
    "    terminator_re = re.compile(r\"\\bauditors?\\s*[’']?\\s*report\\b|\\bbalance\\s+sheet\\b\", re.IGNORECASE)\n",
    "\n",
    "    next_section_page = None\n",
    "    for ent in entries:\n",
    "        p = ent.get(\"page\")\n",
    "        if not isinstance(p, int) or p <= mdna_start_page:\n",
    "            continue\n",
    "        if terminator_re.search(ent.get(\"title\") or \"\"):\n",
    "            next_section_page = p\n",
    "            break\n",
    "\n",
    "    mdna_end_page = max_page if next_section_page is None else (next_section_page - 1)\n",
    "    if mdna_end_page < mdna_start_page:\n",
    "        logging.warning(\"Amit_spinning: invalid computed range start=%s end=%s\", mdna_start_page, mdna_end_page)\n",
    "        return None, None\n",
    "\n",
    "    logging.info(\"Amit_spinning MD&A boundaries (INDEX): start=%s, end=%s\", mdna_start_page, mdna_end_page)\n",
    "    return mdna_start_page, mdna_end_page\n",
    "\n",
    "\n",
    "def _detect_mdna_boundaries_strict_toc(raw_lines, max_page: int):\n",
    "    \"\"\"Shared strict-ToC-only MD&A boundary detection used for all companies.\n",
    "\n",
    "    This is the original \"normal\" detection path. It does not do any Amit_spinning INDEX logic.\n",
    "    \"\"\"\n",
    "\n",
    "    mdna_title_re = re.compile(\n",
    "        r\"\\bmanagement(?:\\s*[’']?s)?\\s+discussion(?:s)?\\s+(?:and|&)\\s+analysis(?:\\s+report)?\\b\",\n",
    "        re.IGNORECASE,\n",
    "    )\n",
    "    mdna_anchor_re = re.compile(r\"\\bmanagement\\b\", re.IGNORECASE)\n",
    "\n",
    "    # Exclusion regexes (kept strict)\n",
    "    directors_re = re.compile(r\"\\bdirectors\\s*[’']?\\s*report\\b\", re.IGNORECASE)\n",
    "    secretarial_re = re.compile(r\"\\bsecretarial\\s+audit\\b\", re.IGNORECASE)\n",
    "    mr3_re = re.compile(r\"\\bform\\s+mr\\s*[-–]?\\s*3\\b|\\bmr\\s*[-–]?\\s*3\\b\", re.IGNORECASE)\n",
    "    corp_info_re = re.compile(r\"\\bcorporate\\s+information\\b\", re.IGNORECASE)\n",
    "    auditors_re = re.compile(r\"\\bauditors?\\s*[’']?\\s*report\\b|\\bindependent\\s+auditor\\b\", re.IGNORECASE)\n",
    "    corp_gov_re = re.compile(r\"\\bcorporate\\s+governance\\b\", re.IGNORECASE)\n",
    "\n",
    "    disallowed = [\n",
    "        (directors_re, re.compile(r\"\\bdirectors\\b\", re.IGNORECASE)),\n",
    "        (secretarial_re, re.compile(r\"\\bsecretarial\\b\", re.IGNORECASE)),\n",
    "        (mr3_re, re.compile(r\"\\bmr\\b|\\bform\\b\", re.IGNORECASE)),\n",
    "        (corp_info_re, re.compile(r\"\\bcorporate\\b\", re.IGNORECASE)),\n",
    "        (auditors_re, re.compile(r\"\\bauditor\\b|\\bindependent\\b\", re.IGNORECASE)),\n",
    "        (corp_gov_re, re.compile(r\"\\bgovernance\\b|\\bcorporate\\b\", re.IGNORECASE)),\n",
    "    ]\n",
    "\n",
    "    # --- 1) Find MD&A title as a structural block (up to 3 joined lines) ---\n",
    "    mdna_start_idx, mdna_end_idx, mdna_block_text = find_title_block_strict(\n",
    "        raw_lines,\n",
    "        mdna_title_re,\n",
    "        max_join_lines=3,\n",
    "        anchor_re=mdna_anchor_re,\n",
    "    )\n",
    "\n",
    "    # --- 1a) Handle special case: MD&A is part of Directors' Report block ---\n",
    "    if mdna_start_idx is None:\n",
    "        logging.info(\"MD&A not found as standalone title; checking inside Directors' Report block\")\n",
    "        directors_anchor_re = re.compile(r\"\\bdirectors\\b\", re.IGNORECASE)\n",
    "        dir_start_idx, dir_end_idx, dir_block_text = find_title_block_strict(\n",
    "            raw_lines,\n",
    "            directors_re,\n",
    "            max_join_lines=3,\n",
    "            anchor_re=directors_anchor_re,\n",
    "        )\n",
    "\n",
    "        if dir_block_text and mdna_title_re.search(dir_block_text):\n",
    "            logging.info(\"MD&A title found inside Directors' Report block; using its boundaries\")\n",
    "            mdna_start_idx = dir_start_idx\n",
    "            mdna_end_idx = dir_end_idx\n",
    "            mdna_block_text = dir_block_text\n",
    "        else:\n",
    "            logging.warning(\"MD&A title block not found in ToC raw lines; skipping\")\n",
    "            return None, None\n",
    "\n",
    "    # --- 2) STRICT page number association: page number after MD&A match, else next 3 lines ---\n",
    "    mdna_page_details = resolve_page_number_for_title_block_strict_with_details(\n",
    "        raw_lines,\n",
    "        title_start_idx=mdna_start_idx,\n",
    "        title_end_idx=mdna_end_idx,\n",
    "        title_re=mdna_title_re,\n",
    "        max_page=max_page,\n",
    "        lookahead_lines=3,\n",
    "    )\n",
    "\n",
    "    # Special case: MD&A is a sub-entry under \"Board's Report including\" with no page number.\n",
    "    # In this layout, the next numeric line belongs to the next sibling (e.g., Annexures),\n",
    "    # so we inherit the parent's page (e.g., 4) and end at the next TRUE top-level section\n",
    "    # (e.g., Corporate Governance at 17 -> end 16).\n",
    "    inherited_parent_for_mdna = False\n",
    "    if mdna_page_details:\n",
    "        page_line_idx = mdna_page_details.get(\"page_line_idx\")\n",
    "        if isinstance(page_line_idx, int) and page_line_idx > (mdna_end_idx + 1):\n",
    "            prev_txt = raw_lines[page_line_idx - 1].get(\"line_text\", \"\")\n",
    "            if re.search(r\"[A-Za-z]\", prev_txt or \"\") and not mdna_title_re.search(prev_txt or \"\"):\n",
    "                parent_page = None\n",
    "                parent_page_line_idx = None\n",
    "                parent_title = None\n",
    "\n",
    "                for back in range(mdna_start_idx - 1, max(-1, mdna_start_idx - 12), -1):\n",
    "                    t = (raw_lines[back].get(\"line_text\", \"\") or \"\").strip()\n",
    "                    if not t:\n",
    "                        continue\n",
    "                    mnum = re.fullmatch(r\"\\s*(\\d{1,3})\\s*\", t)\n",
    "                    if not mnum:\n",
    "                        continue\n",
    "                    n = int(mnum.group(1))\n",
    "                    if not (1 <= n <= max_page):\n",
    "                        continue\n",
    "\n",
    "                    parent_page = n\n",
    "                    parent_page_line_idx = back\n",
    "\n",
    "                    for tt in range(back - 1, max(-1, back - 10), -1):\n",
    "                        cand = (raw_lines[tt].get(\"line_text\", \"\") or \"\").strip()\n",
    "                        if cand and re.search(r\"[A-Za-z]\", cand):\n",
    "                            parent_title = cand\n",
    "                            break\n",
    "\n",
    "                    break\n",
    "\n",
    "                if parent_page is not None and parent_title:\n",
    "                    parent_l = parent_title.lower()\n",
    "                    if (\"including\" in parent_l) and (\"report\" in parent_l) and (\"board\" in parent_l) and (\"directors\" not in parent_l):\n",
    "                        logging.info(\n",
    "                            \"MD&A appears as sub-entry; inheriting parent start page %s from '%s'\",\n",
    "                            parent_page,\n",
    "                            parent_title,\n",
    "                        )\n",
    "                        inherited_parent_for_mdna = True\n",
    "                        mdna_page_details = {\n",
    "                            \"page\": parent_page,\n",
    "                            \"page_span_start\": None,\n",
    "                            \"page_span_end\": None,\n",
    "                            \"page_line_idx\": parent_page_line_idx,\n",
    "                        }\n",
    "\n",
    "    if not mdna_page_details:\n",
    "        logging.warning(\"MD&A start page not found within strict 3-line window; skipping\")\n",
    "        return None, None\n",
    "\n",
    "    start_page = mdna_page_details[\"page\"]\n",
    "\n",
    "    # --- 3) Determine next section page (including same-line multi-column cases) ---\n",
    "    def _next_page_number_in_same_line(line_text: str, after_pos: int, current_start_page: int):\n",
    "        # Prefer numbers that occur after the current entry's page span (when ordering is preserved).\n",
    "        res = _first_valid_page_number_after_pos_with_span(line_text, after_pos, max_page)\n",
    "        if res:\n",
    "            n, _, _ = res\n",
    "            if n > current_start_page:\n",
    "                return n\n",
    "\n",
    "        # Fallback for multi-column merges where extraction order may be scrambled within the same line:\n",
    "        # choose the smallest page number on the line that is greater than the current start page.\n",
    "        candidates = []\n",
    "        for m in _PAGE_INT_RE.finditer(line_text or \"\"):\n",
    "            try:\n",
    "                n = int(m.group(1))\n",
    "            except ValueError:\n",
    "                continue\n",
    "            if current_start_page < n <= max_page:\n",
    "                candidates.append(n)\n",
    "\n",
    "        return min(candidates) if candidates else None\n",
    "\n",
    "    def _next_section_start_page_after_line(after_line_idx: int, current_start_page: int):\n",
    "        for j in range(after_line_idx + 1, len(raw_lines)):\n",
    "            txt = raw_lines[j].get(\"line_text\", \"\")\n",
    "            if not re.search(r\"[A-Za-z]\", txt or \"\"):\n",
    "                continue\n",
    "\n",
    "            # Avoid treating the same MD&A title again\n",
    "            if mdna_title_re.search(txt or \"\"):\n",
    "                continue\n",
    "\n",
    "            candidate = resolve_page_number_strict(raw_lines, j, max_page=max_page, lookahead_lines=3)\n",
    "            if candidate is None:\n",
    "                continue\n",
    "\n",
    "            if candidate > current_start_page:\n",
    "                return candidate\n",
    "\n",
    "        return None\n",
    "\n",
    "    def _next_top_level_section_page_after_line(after_line_idx: int, current_start_page: int):\n",
    "        top_level_re = re.compile(\n",
    "            r\"\\b(corporate\\s+governance|auditors?\\s*[’']?\\s*report|independent\\s+auditor|balance\\s+sheet|statement\\s+of\\s+profit|cash\\s+flow\\s+statement|notes)\\b\",\n",
    "            re.IGNORECASE,\n",
    "        )\n",
    "        for j in range(after_line_idx + 1, len(raw_lines)):\n",
    "            txt = raw_lines[j].get(\"line_text\", \"\")\n",
    "            if not re.search(r\"[A-Za-z]\", txt or \"\"):\n",
    "                continue\n",
    "            if not top_level_re.search(txt or \"\"):\n",
    "                continue\n",
    "\n",
    "            candidate = resolve_page_number_strict(raw_lines, j, max_page=max_page, lookahead_lines=3)\n",
    "            if candidate is None:\n",
    "                continue\n",
    "            if candidate > current_start_page:\n",
    "                return candidate\n",
    "\n",
    "        return None\n",
    "\n",
    "    same_line_idx = mdna_page_details[\"page_line_idx\"]\n",
    "    same_line_text = raw_lines[same_line_idx].get(\"line_text\", \"\")\n",
    "    same_line_next_page = _next_page_number_in_same_line(\n",
    "        same_line_text,\n",
    "        after_pos=mdna_page_details.get(\"page_span_end\") or 0,\n",
    "        current_start_page=start_page,\n",
    "    )\n",
    "\n",
    "    next_section_page = same_line_next_page\n",
    "    if next_section_page is None:\n",
    "        if inherited_parent_for_mdna:\n",
    "            next_section_page = _next_top_level_section_page_after_line(mdna_end_idx, start_page)\n",
    "        if next_section_page is None:\n",
    "            next_section_page = _next_section_start_page_after_line(mdna_end_idx, start_page)\n",
    "\n",
    "    end_page = max_page if next_section_page is None else (next_section_page - 1)\n",
    "\n",
    "    if end_page < start_page:\n",
    "        logging.warning(\"Computed invalid MD&A range: start=%s end=%s; skipping\", start_page, end_page)\n",
    "        return None, None\n",
    "\n",
    "    # --- 4) Exclusion ranges (handle same-line next-section; do not require resolving ALL exclusions) ---\n",
    "    def _excluded_ranges():\n",
    "        ranges = []\n",
    "\n",
    "        for title_re, anchor_re in disallowed:\n",
    "            # If MD&A was found inside the Directors' Report, don't treat Directors' Report as an exclusion\n",
    "            if directors_re.pattern == title_re.pattern and mdna_title_re.search(mdna_block_text or \"\"):\n",
    "                if directors_re.search(mdna_block_text or \"\"):\n",
    "                    continue\n",
    "\n",
    "            ex_start_idx, ex_end_idx, ex_block_text = find_title_block_strict(\n",
    "                raw_lines,\n",
    "                title_re,\n",
    "                max_join_lines=3,\n",
    "                anchor_re=anchor_re,\n",
    "            )\n",
    "\n",
    "            if ex_start_idx is None:\n",
    "                continue\n",
    "\n",
    "            ex_details = resolve_page_number_for_title_block_strict_with_details(\n",
    "                raw_lines,\n",
    "                title_start_idx=ex_start_idx,\n",
    "                title_end_idx=ex_end_idx,\n",
    "                title_re=title_re,\n",
    "                max_page=max_page,\n",
    "                lookahead_lines=3,\n",
    "            )\n",
    "\n",
    "            # If exclusion exists but cannot be aligned within strict window, we cannot\n",
    "            # form a reliable range; skip enforcing that specific exclusion.\n",
    "            if not ex_details:\n",
    "                logging.warning(\"Excluded section found but page number not aligned; ignoring exclusion: %s\", ex_block_text)\n",
    "                continue\n",
    "\n",
    "            ex_start_page = ex_details[\"page\"]\n",
    "\n",
    "            ex_same_line_idx = ex_details[\"page_line_idx\"]\n",
    "            ex_same_line_text = raw_lines[ex_same_line_idx].get(\"line_text\", \"\")\n",
    "            ex_same_line_next = _next_page_number_in_same_line(\n",
    "                ex_same_line_text,\n",
    "                after_pos=ex_details.get(\"page_span_end\") or 0,\n",
    "                current_start_page=ex_start_page,\n",
    "            )\n",
    "\n",
    "            ex_next_page = ex_same_line_next\n",
    "            if ex_next_page is None:\n",
    "                ex_next_page = _next_section_start_page_after_line(ex_end_idx, ex_start_page)\n",
    "\n",
    "            # Critical safety for multi-column/boxed ToCs:\n",
    "            # if an excluded section starts before MD&A (by page number), it must end no later\n",
    "            # than the MD&A start page (as both are ToC-derived section starts), even if the\n",
    "            # extracted line order is scrambled.\n",
    "            if ex_start_page < start_page:\n",
    "                if ex_next_page is None or start_page < ex_next_page:\n",
    "                    ex_next_page = start_page\n",
    "\n",
    "            ex_end_page = max_page if ex_next_page is None else (ex_next_page - 1)\n",
    "\n",
    "            ranges.append(\n",
    "                {\n",
    "                    \"title\": ex_block_text,\n",
    "                    \"start\": ex_start_page,\n",
    "                    \"end\": ex_end_page,\n",
    "                }\n",
    "            )\n",
    "\n",
    "        return ranges\n",
    "\n",
    "    ex_ranges = _excluded_ranges()\n",
    "\n",
    "    for r in ex_ranges:\n",
    "        if r[\"start\"] <= start_page <= r[\"end\"]:\n",
    "            logging.warning(\n",
    "                \"MD&A start page %s falls inside excluded section '%s' (%s-%s); skipping\",\n",
    "                start_page,\n",
    "                r[\"title\"],\n",
    "                r[\"start\"],\n",
    "                r[\"end\"],\n",
    "            )\n",
    "            return None, None\n",
    "\n",
    "    logging.info(\"MD&A boundaries (STRICT ToC blocks): start=%s, end=%s\", start_page, end_page)\n",
    "    return start_page, end_page\n",
    "\n",
    "\n",
    "def detect_mdna_boundaries(pages_text, toc_start_page=None, company_folder: str | None = None):\n",
    "    \"\"\"Detect MD&A boundaries using STRICT Table of Contents (ToC) rules ONLY.\n",
    "\n",
    "    Required behavior:\n",
    "      - ToC is the only source of truth (first 5 pages only).\n",
    "      - Treat ToC as STRUCTURAL BLOCKS: titles may be wrapped across lines.\n",
    "      - When MD&A title is detected, search ONLY next 3 extracted lines for page number.\n",
    "      - Deterministic alignment, no body-text inference; if not resolvable, SKIP.\n",
    "\n",
    "    Amit_spinning behavior (hybrid, still ToC-only):\n",
    "      - First try the normal strict-ToC detector (works for Amit PDFs that look like other companies).\n",
    "      - If it fails to resolve boundaries, fall back to INDEX-style detection for Amit PDFs whose\n",
    "        MD&A is embedded under \"Board’s Report Including ...\".\n",
    "\n",
    "    Returns:\n",
    "      (start_page, end_page) or (None, None)\n",
    "    \"\"\"\n",
    "\n",
    "    max_page = len(pages_text)\n",
    "    if max_page <= 0:\n",
    "        logging.warning(\"Empty document; cannot detect MD&A boundaries\")\n",
    "        return None, None\n",
    "\n",
    "    raw_lines = collect_toc_raw_lines(pages_text, max_pages=5)\n",
    "    if not raw_lines:\n",
    "        logging.warning(\"No ToC raw lines detected in the first 5 pages\")\n",
    "        return None, None\n",
    "\n",
    "    # 1) Always try the normal strict-ToC path first.\n",
    "    start_page, end_page = _detect_mdna_boundaries_strict_toc(raw_lines, max_page=max_page)\n",
    "    if start_page is not None and end_page is not None:\n",
    "        return start_page, end_page\n",
    "\n",
    "    # 2) Amit_spinning fallback: INDEX-style.\n",
    "    if company_folder == \"Amit_spinning\":\n",
    "        return _detect_mdna_boundaries_amit_spinning_index(raw_lines, max_page=max_page)\n",
    "\n",
    "    return None, None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "521c7f4c",
   "metadata": {},
   "source": [
    "### 7. MD&A Text Extraction (Boundary-Aware) : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "34d448a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-29 22:50:38,643 | INFO | root | MD&A pages included: 6\n",
      "2025-12-29 22:50:38,655 | INFO | root | Extracted MD&A text length (chars): 18561\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MD&A preview:\n",
      "\n",
      "56 | AMTEK AUTO LIMITED\n",
      "AMTEK AUTO LIMITED\n",
      "MANAGEMENT DISCUSSION AND ANALYSIS REPORT\n",
      "1.\n",
      "GLOBAL ECONOMIC OVERVIEW\n",
      "The overall performance of the global economy remained subdued through 2014, as well as into 2015. The world\n",
      "economy grew 3.4% in 2014, impacted by a slowdown in many developing countries, which account for approximately\n",
      "75% of the world economy. According to the International Monetary Fund (IMF), the global GDP growth rate is expected\n",
      "to decline further by 30bps to 3.1% in 2015. A modest pickup in advanced economies and continued challenges in\n",
      "emerging markets are the major factors behind these lower projections. The GDP growth for emerging markets and\n",
      "developing countries in 2015 is expected to decline by 60bps to 4.0%, owing to weaker economic growth in the oil\n",
      "exporting countries, a slowdown in China and expected negative growth in Brazil.\n",
      "2.\n",
      "INDIAN ECONOMIC OVERVIEW\n",
      "During fiscal year 2015, the Indian economy started to show signs of a recovery after a prolonged slowdow\n"
     ]
    }
   ],
   "source": [
    "def extract_mdna_text(pages_text, start_page, end_page):\n",
    "    \"\"\"Extract raw MD&A text from PDF pages using detected boundaries.\n",
    "\n",
    "    Args:\n",
    "        pages_text: List of page dictionaries from PDFInterface.get_pages_text(),\n",
    "                    each like {\"page_number\": int, \"text\": str}\n",
    "        start_page: 1-based start page number (inclusive)\n",
    "        end_page: 1-based end page number (inclusive)\n",
    "\n",
    "    Returns:\n",
    "        str: Concatenated raw MD&A text (no cleaning), with double newlines\n",
    "             inserted between pages.\n",
    "    \"\"\"\n",
    "\n",
    "    included_text_chunks = []\n",
    "    included_pages = 0\n",
    "\n",
    "    for page in pages_text:\n",
    "        page_no = page.get(\"page_number\")\n",
    "        if page_no is None:\n",
    "            continue\n",
    "\n",
    "        if start_page <= page_no <= end_page:\n",
    "            included_pages += 1\n",
    "            included_text_chunks.append(page.get(\"text\", \"\"))\n",
    "\n",
    "    mdna_text = \"\\n\\n\".join(included_text_chunks)\n",
    "\n",
    "    logging.info(\"MD&A pages included: %d\", included_pages)\n",
    "    logging.info(\"Extracted MD&A text length (chars): %d\", len(mdna_text))\n",
    "\n",
    "    return mdna_text\n",
    "\n",
    "\n",
    "# mdna_text = extract_mdna_text(pages, start_page, end_page)\n",
    "\n",
    "# print(\"MD&A preview:\\n\")\n",
    "# print(mdna_text[:1000])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "099b0200",
   "metadata": {},
   "source": [
    "### 8. MD&A Text Cleaning & Artifact Removal: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "08b64a72",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-29 15:06:51,628 | INFO | root | MD&A text original length (chars): 39415\n",
      "2025-12-29 15:06:51,629 | INFO | root | MD&A text cleaned length (chars): 37792\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned MD&A preview:\n",
      "\n",
      "20 | AMTEK AUTO LIMITED\n",
      "SECRETARIAL AUDIT REPORT\n",
      "The Board has appointed M/s S. Khurana & Associates, Company Secretaries, to conduct Secretarial Audit for the financial\n",
      "year 2015-16. The Secretarial Audit Report for the financial year ended March 31, 2016 is annexed herewith marked as\n",
      "Annexure - I to this Report. The Secretarial Audit Report does not contain any qualification, reservation or adverse remark.\n",
      "As per the directive of Securities and Exchange Board of India, M/s S. Khurana & Associates Company Secretaries, New\n",
      "Delhi, undertook the Reconciliation of Share Capital Audit on a quarterly basis. The purpose of the audit is to reconcile the\n",
      "total number of shares held in National Securities Depository Limited (NSDL), Central Depository Services (India) Limited\n",
      "(CDSL) and in physical form with the respect to admitted, issued and paid up capital of the Company.\n",
      "CORPORATE GOVERNANCE\n",
      "The Company is committed to maintain high standards of Corporate Governance and adhere to the Corporate Governance\n",
      "requirements set out by SEBI. The Report on Corporate Governance as stipulated under SEBI (Listing Obligations and\n",
      "Disclosure Requirements) Regulations, 2015 forms an Integral part of th\n"
     ]
    }
   ],
   "source": [
    "def clean_mdna_text(raw_text):\n",
    "    \"\"\"Conservatively clean extracted MD&A text.\n",
    "\n",
    "    What this does (conservative heuristics):\n",
    "    - Removes obvious repeating headers/footers (e.g., 'Annual Report ...', standalone page numbers,\n",
    "      and very header-like company-name lines when they appear repeatedly).\n",
    "    - Removes obvious table artifacts (high digit-density lines, and separator-only lines).\n",
    "    - Normalizes whitespace while preserving paragraph breaks.\n",
    "\n",
    "    What this does NOT do:\n",
    "    - Does not lowercase text\n",
    "    - Does not remove punctuation\n",
    "    - Does not change wording\n",
    "\n",
    "    Args:\n",
    "        raw_text: str\n",
    "\n",
    "    Returns:\n",
    "        str: cleaned MD&A text\n",
    "    \"\"\"\n",
    "\n",
    "    if raw_text is None:\n",
    "        raw_text = \"\"\n",
    "\n",
    "    original_len = len(raw_text)\n",
    "\n",
    "    # Split into lines to enable conservative line-based removals.\n",
    "    lines = raw_text.splitlines()\n",
    "\n",
    "    # Pre-compute line frequencies (normalized) to detect repeated headers/footers.\n",
    "    def _norm_line_for_freq(line: str) -> str:\n",
    "        return re.sub(r\"\\s+\", \" \", (line or \"\").strip())\n",
    "\n",
    "    normalized_lines = [_norm_line_for_freq(ln) for ln in lines]\n",
    "    freq = {}\n",
    "    for nl in normalized_lines:\n",
    "        if not nl:\n",
    "            continue\n",
    "        freq[nl] = freq.get(nl, 0) + 1\n",
    "\n",
    "    annual_report_re = re.compile(r\"^\\s*Annual\\s+Report(?:\\s+\\d{4}\\s*[-–]\\s*\\d{2,4})?\\s*$\", re.IGNORECASE)\n",
    "    standalone_page_no_re = re.compile(r\"^\\s*(?:page\\s*)?\\d{1,4}\\s*$\", re.IGNORECASE)\n",
    "    separators_only_re = re.compile(r\"^[\\s\\-_=*~•·\\.\\|:;,+/\\\\]+$\")\n",
    "\n",
    "    def _is_company_name_like(line: str) -> bool:\n",
    "        # Conservative: only remove if it looks like a standalone header/footer line.\n",
    "        s = (line or \"\").strip()\n",
    "        if not s:\n",
    "            return False\n",
    "        if len(s) > 90:\n",
    "            return False\n",
    "\n",
    "        # Must contain common company suffixes.\n",
    "        if not re.search(r\"\\b(LIMITED|LTD\\.?|PVT\\.?\\s+LTD\\.?|PRIVATE\\s+LIMITED)\\b\", s, flags=re.IGNORECASE):\n",
    "            return False\n",
    "\n",
    "        # Must be mostly uppercase (typical header styling).\n",
    "        letters = re.findall(r\"[A-Za-z]\", s)\n",
    "        if not letters:\n",
    "            return False\n",
    "        upper_letters = sum(1 for ch in letters if ch.isupper())\n",
    "        if upper_letters / len(letters) < 0.8:\n",
    "            return False\n",
    "\n",
    "        # Keep it short in words (header/footer line).\n",
    "        if len(s.split()) > 10:\n",
    "            return False\n",
    "\n",
    "        return True\n",
    "\n",
    "    def _is_high_numeric_density(line: str) -> bool:\n",
    "        s = (line or \"\").strip()\n",
    "        if len(s) < 12:\n",
    "            return False\n",
    "        # Density computed over non-space characters.\n",
    "        compact = re.sub(r\"\\s+\", \"\", s)\n",
    "        if not compact:\n",
    "            return False\n",
    "        digits = sum(1 for ch in compact if ch.isdigit())\n",
    "        return (digits / len(compact)) > 0.40\n",
    "\n",
    "    cleaned_lines = []\n",
    "\n",
    "    for raw_line, norm_line in zip(lines, normalized_lines):\n",
    "        s = (raw_line or \"\").rstrip()\n",
    "        sn = norm_line\n",
    "\n",
    "        # Remove obvious separators/formatting-only lines.\n",
    "        if sn and separators_only_re.match(sn):\n",
    "            continue\n",
    "\n",
    "        # Remove obvious page numbers (standalone).\n",
    "        if sn and standalone_page_no_re.match(sn):\n",
    "            continue\n",
    "\n",
    "        # Remove 'Annual Report' headers/footers.\n",
    "        if sn and annual_report_re.match(sn):\n",
    "            continue\n",
    "\n",
    "        # Remove frequent header/footer-like lines conservatively.\n",
    "        # (Only if repeated AND header-ish AND not too long.)\n",
    "        if sn and freq.get(sn, 0) >= 3:\n",
    "            if _is_company_name_like(sn) or annual_report_re.match(sn) or standalone_page_no_re.match(sn):\n",
    "                continue\n",
    "\n",
    "        # Remove obvious table artifacts: high numeric density.\n",
    "        if _is_high_numeric_density(sn):\n",
    "            continue\n",
    "\n",
    "        # Whitespace normalization inside the line.\n",
    "        s = re.sub(r\"[ \\t]{2,}\", \" \", s).strip(\" \")\n",
    "        cleaned_lines.append(s)\n",
    "\n",
    "    # Re-join with newlines and normalize paragraph spacing.\n",
    "    cleaned_text = \"\\n\".join(cleaned_lines)\n",
    "\n",
    "    # Reduce 3+ consecutive newlines to at most 2.\n",
    "    cleaned_text = re.sub(r\"\\n{3,}\", \"\\n\\n\", cleaned_text)\n",
    "\n",
    "    # Trim leading/trailing whitespace/newlines.\n",
    "    cleaned_text = cleaned_text.strip()\n",
    "\n",
    "    logging.info(\"MD&A text original length (chars): %d\", original_len)\n",
    "    logging.info(\"MD&A text cleaned length (chars): %d\", len(cleaned_text))\n",
    "\n",
    "    return cleaned_text\n",
    "\n",
    "#sanity test: \n",
    "# cleaned_text = clean_mdna_text(mdna_text)\n",
    "\n",
    "# print(\"Cleaned MD&A preview:\\n\")\n",
    "# print(cleaned_text[:1200])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d36041d",
   "metadata": {},
   "source": [
    "### 9. MD&A Quality Verification & Validation Metrics : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fc5792c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify_mdna_quality(mdna_text, pages_match_toc: bool):\n",
    "    \"\"\"Verify extracted/cleaned MD&A text quality using STRICT semantics.\n",
    "\n",
    "    quality_passed MUST be TRUE only if:\n",
    "      - Extracted pages match the ToC-declared MD&A range exactly (pages_match_toc=True)\n",
    "      - Text contains at least 2 MD&A-specific phrases (case-insensitive)\n",
    "\n",
    "    Guardrail:\n",
    "      - Audit / Corporate / Director section signals must ALWAYS fail quality.\n",
    "\n",
    "    Returns:\n",
    "        dict with keys:\n",
    "          - word_count (int)\n",
    "          - narrative_density (float)\n",
    "          - keyword_hits (list[str])\n",
    "          - quality_passed (bool)\n",
    "    \"\"\"\n",
    "\n",
    "    if mdna_text is None:\n",
    "        mdna_text = \"\"\n",
    "\n",
    "    # a) Word count\n",
    "    words = re.findall(r\"\\b\\w+\\b\", mdna_text)\n",
    "    word_count = len(words)\n",
    "\n",
    "    # b) Narrative density (alphabetic chars / total chars)\n",
    "    total_chars = len(mdna_text)\n",
    "    alpha_chars = sum(1 for ch in mdna_text if ch.isalpha())\n",
    "    narrative_density = (alpha_chars / total_chars) if total_chars else 0.0\n",
    "\n",
    "    lower_text = mdna_text.lower()\n",
    "\n",
    "    # c) Required MD&A phrases\n",
    "    mdna_phrases = [\n",
    "        \"industry outlook\",\n",
    "        \"opportunities and threats\",\n",
    "        \"risk management\",\n",
    "        \"future outlook\",\n",
    "        \"segment performance\",\n",
    "        \"global economy\",\n",
    "    ]\n",
    "\n",
    "    keyword_hits = [p for p in mdna_phrases if p in lower_text]\n",
    "\n",
    "    # Disqualifiers: MUST always fail\n",
    "    disqualifiers = [\n",
    "        \"independent auditor\",\n",
    "        \"auditor's report\",\n",
    "        \"auditors' report\",\n",
    "        \"auditors report\",\n",
    "        \"secretarial audit\",\n",
    "        \"form mr-3\",\n",
    "        \"mr-3\",\n",
    "        \"corporate information\",\n",
    "        \"corporate governance\",\n",
    "        \"directors' report\",\n",
    "        \"director's report\",\n",
    "        \"directors report\",\n",
    "    ]\n",
    "\n",
    "    disqualifier_hit = any(bad in lower_text for bad in disqualifiers)\n",
    "\n",
    "    criteria_pages_match = bool(pages_match_toc)\n",
    "    criteria_phrases = len(keyword_hits) >= 2\n",
    "\n",
    "    quality_passed = bool(criteria_pages_match and criteria_phrases and (not disqualifier_hit))\n",
    "\n",
    "    logging.info(\"MD&A quality — word_count: %d\", word_count)\n",
    "    logging.info(\"MD&A quality — narrative_density: %.4f\", narrative_density)\n",
    "    logging.info(\"MD&A quality — keyword_hits (%d): %s\", len(keyword_hits), keyword_hits)\n",
    "    logging.info(\"MD&A quality — pages_match_toc: %s\", criteria_pages_match)\n",
    "    logging.info(\"MD&A quality — disqualifier_hit: %s\", disqualifier_hit)\n",
    "\n",
    "    if quality_passed:\n",
    "        logging.info(\"MD&A quality PASSED\")\n",
    "    else:\n",
    "        logging.warning(\n",
    "            \"MD&A quality FLAGGED (pages_match_toc=%s, phrases_ok=%s, disqualifier_hit=%s)\",\n",
    "            criteria_pages_match,\n",
    "            criteria_phrases,\n",
    "            disqualifier_hit,\n",
    "        )\n",
    "\n",
    "    return {\n",
    "        \"word_count\": word_count,\n",
    "        \"narrative_density\": float(narrative_density),\n",
    "        \"keyword_hits\": keyword_hits,\n",
    "        \"quality_passed\": quality_passed,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d77b573e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "\n",
    "def _norm_for_match(s: str) -> str:\n",
    "    s = (s or \"\").lower()\n",
    "    # normalize common apostrophes and whitespace\n",
    "    s = s.replace(\"’\", \"'\").replace(\"‘\", \"'\")\n",
    "    s = re.sub(r\"\\s+\", \" \", s).strip()\n",
    "    return s\n",
    "\n",
    "\n",
    "def _extract_printed_page_number_from_page_text(text: str) -> int | None:\n",
    "    \"\"\"Best-effort parse of the *printed* page number from footer/header.\n",
    "\n",
    "    Heuristic: look at last ~15 non-empty lines and pick a small, standalone integer\n",
    "    (e.g., \"23\", \"- 23 -\", \"Page 23\").\n",
    "    \"\"\"\n",
    "\n",
    "    lines = [ln.strip() for ln in (text or \"\").splitlines() if (ln or \"\").strip()]\n",
    "    if not lines:\n",
    "        return None\n",
    "\n",
    "    tail = lines[-15:]\n",
    "\n",
    "    patterns = [\n",
    "        re.compile(r\"^page\\s*(\\d{1,4})\\s*$\", re.IGNORECASE),\n",
    "        re.compile(r\"^[-–—]*\\s*(\\d{1,4})\\s*[-–—]*$\"),\n",
    "        re.compile(r\"^\\(?\\s*(\\d{1,4})\\s*\\)?$\"),\n",
    "    ]\n",
    "\n",
    "    for ln in reversed(tail):\n",
    "        # avoid matching years or long numeric strings\n",
    "        if re.search(r\"\\b(19|20)\\d{2}\\b\", ln):\n",
    "            continue\n",
    "        if len(ln) > 20:\n",
    "            continue\n",
    "\n",
    "        for pat in patterns:\n",
    "            m = pat.match(ln)\n",
    "            if not m:\n",
    "                continue\n",
    "            try:\n",
    "                n = int(m.group(1))\n",
    "            except ValueError:\n",
    "                continue\n",
    "            if 1 <= n <= 5000:\n",
    "                return n\n",
    "\n",
    "    return None\n",
    "\n",
    "\n",
    "def build_printed_to_pdf_page_map(pages_text: list[dict]) -> dict[int, int]:\n",
    "    \"\"\"Map printed page number -> PDF page index (1-based).\"\"\"\n",
    "\n",
    "    out: dict[int, int] = {}\n",
    "    for p in pages_text:\n",
    "        pdf_page = p.get(\"page_number\")\n",
    "        if not isinstance(pdf_page, int):\n",
    "            continue\n",
    "        printed = _extract_printed_page_number_from_page_text(p.get(\"text\", \"\") or \"\")\n",
    "        if printed is None:\n",
    "            continue\n",
    "        # Keep the first occurrence (most docs have a 1-1 mapping)\n",
    "        out.setdefault(int(printed), int(pdf_page))\n",
    "    return out\n",
    "\n",
    "\n",
    "class PageOffsetSolver:\n",
    "    \"\"\"Compute delta between printed ToC page numbers and PDF page indices.\n",
    "\n",
    "    Anchor-based approach:\n",
    "      1) Find anchor ('Independent Auditor's Report') in ToC lines and read its ToC page number.\n",
    "      2) Find the same anchor in the actual PDF pages (header/title text) to get PDF page index.\n",
    "      3) delta = pdf_page_index - toc_page_number\n",
    "\n",
    "    Returns 0 if anchor can't be resolved safely.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, doc: fitz.Document, pages_text: list[dict], toc_max_pages: int = 15):\n",
    "        self.doc = doc\n",
    "        self.pages_text = pages_text\n",
    "        self.toc_raw_lines = collect_toc_raw_lines(pages_text, max_pages=toc_max_pages)\n",
    "\n",
    "    def find_offset(self) -> int:\n",
    "        toc_anchor_page = self._find_anchor_page_in_toc()\n",
    "        if toc_anchor_page is None:\n",
    "            return 0\n",
    "\n",
    "        pdf_anchor_page = self._find_anchor_page_in_pdf()\n",
    "        if pdf_anchor_page is None:\n",
    "            return 0\n",
    "\n",
    "        return int(pdf_anchor_page - toc_anchor_page)\n",
    "\n",
    "    def _find_anchor_page_in_toc(self) -> int | None:\n",
    "        # Match variants like: Independent Auditor’s Report / Independent Auditors' Report\n",
    "        anchor_re = re.compile(r\"\\bindependent\\s+auditors?\\s*[’']?\\s*report\\b\", re.IGNORECASE)\n",
    "        max_page = len(self.pages_text)\n",
    "\n",
    "        for i, item in enumerate(self.toc_raw_lines):\n",
    "            line = item.get(\"line_text\", \"\") or \"\"\n",
    "            if not anchor_re.search(line):\n",
    "                continue\n",
    "\n",
    "            page = resolve_page_number_strict(self.toc_raw_lines, i, max_page=max_page, lookahead_lines=3)\n",
    "            if isinstance(page, int) and page >= 1:\n",
    "                return page\n",
    "\n",
    "        return None\n",
    "\n",
    "    def _find_anchor_page_in_pdf(self, search_limit: int = 250) -> int | None:\n",
    "        anchor_re = re.compile(r\"\\bindependent\\s+auditors?\\s*[’']?\\s*report\\b\", re.IGNORECASE)\n",
    "        limit = min(search_limit, self.doc.page_count)\n",
    "\n",
    "        for page_idx0 in range(limit):\n",
    "            page = self.doc.load_page(page_idx0)\n",
    "            text = page.get_text(\"text\") or \"\"\n",
    "\n",
    "            # Prefer header-ish region: first ~30 non-empty lines\n",
    "            lines = [ln.strip() for ln in text.splitlines() if (ln or \"\").strip()]\n",
    "            header_text = \"\\n\".join(lines[:30])\n",
    "\n",
    "            if anchor_re.search(header_text) or anchor_re.search(text):\n",
    "                return page_idx0 + 1\n",
    "\n",
    "        return None\n",
    "\n",
    "\n",
    "def validate_and_adjust_start_page(doc: fitz.Document, candidate_start_page_1based: int) -> int:\n",
    "    \"\"\"Validate MD&A start page using keyword check; if miss, search +/- 3 pages.\"\"\"\n",
    "\n",
    "    keywords_re = re.compile(r\"management\\s+discussion|\\bstructure\\b|\\boutlook\\b\", re.IGNORECASE)\n",
    "\n",
    "    def _page_has_keywords(page_1based: int) -> bool:\n",
    "        if not (1 <= page_1based <= doc.page_count):\n",
    "            return False\n",
    "        text = doc.load_page(page_1based - 1).get_text(\"text\") or \"\"\n",
    "        return bool(keywords_re.search(text))\n",
    "\n",
    "    if _page_has_keywords(candidate_start_page_1based):\n",
    "        return candidate_start_page_1based\n",
    "\n",
    "    for delta in range(1, 4):\n",
    "        for p in (candidate_start_page_1based - delta, candidate_start_page_1based + delta):\n",
    "            if _page_has_keywords(p):\n",
    "                return p\n",
    "\n",
    "    return candidate_start_page_1based\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "26992cc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-01 12:54:50,975 - INFO - Discovered 14 PDFs under ..\\data\\pdfs\n",
      "2026-01-01 12:54:50,977 - INFO - (1/14) Processing: Alcheimist/5267070319.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-01 12:54:50,982 - INFO - Loaded PDF: 5267070319.pdf\n",
      "2026-01-01 12:54:51,381 - INFO - Extracted company name: ALCHEMIST LTD\n",
      "2026-01-01 12:54:51,383 - INFO - Extracted financial year: 2018-19\n",
      "2026-01-01 12:54:51,384 - WARNING - Excluded section found but page number not aligned; ignoring exclusion: DIRECTORS’ REPORT\n",
      "2026-01-01 12:54:51,385 - INFO - MD&A boundaries (STRICT ToC blocks): start=23, end=100\n",
      "2026-01-01 12:54:51,407 - INFO - Adjusted MD&A start page after validation: 23 -> 26 (shift=3)\n",
      "2026-01-01 12:54:51,409 - INFO - MD&A pages included: 20\n",
      "2026-01-01 12:54:51,409 - INFO - Extracted MD&A text length (chars): 50690\n",
      "2026-01-01 12:54:51,424 - INFO - MD&A text original length (chars): 50690\n",
      "2026-01-01 12:54:51,424 - INFO - MD&A text cleaned length (chars): 49647\n",
      "2026-01-01 12:54:51,435 - INFO - MD&A quality — word_count: 7935\n",
      "2026-01-01 12:54:51,436 - INFO - MD&A quality — narrative_density: 0.7799\n",
      "2026-01-01 12:54:51,437 - INFO - MD&A quality — keyword_hits (1): ['risk management']\n",
      "2026-01-01 12:54:51,439 - INFO - MD&A quality — pages_match_toc: False\n",
      "2026-01-01 12:54:51,440 - INFO - MD&A quality — disqualifier_hit: True\n",
      "2026-01-01 12:54:51,441 - WARNING - MD&A quality FLAGGED (pages_match_toc=False, phrases_ok=False, disqualifier_hit=True)\n",
      "2026-01-01 12:54:51,443 - INFO - (2/14) Processing: Alcheimist/67050526707.pdf\n",
      "2026-01-01 12:54:51,445 - INFO - Loaded PDF: 67050526707.pdf\n",
      "2026-01-01 12:54:51,831 - INFO - Extracted company name: ALCHEMIST LIMITED\n",
      "2026-01-01 12:54:51,833 - INFO - Extracted financial year: 2019-20\n",
      "2026-01-01 12:54:51,835 - INFO - MD&A boundaries (STRICT ToC blocks): start=29, end=31\n",
      "2026-01-01 12:54:51,847 - INFO - MD&A pages included: 46\n",
      "2026-01-01 12:54:51,848 - INFO - Extracted MD&A text length (chars): 160606\n",
      "2026-01-01 12:54:51,882 - INFO - MD&A text original length (chars): 160606\n",
      "2026-01-01 12:54:51,883 - INFO - MD&A text cleaned length (chars): 154573\n",
      "2026-01-01 12:54:51,903 - INFO - MD&A quality — word_count: 25113\n",
      "2026-01-01 12:54:51,903 - INFO - MD&A quality — narrative_density: 0.7769\n",
      "2026-01-01 12:54:51,904 - INFO - MD&A quality — keyword_hits (2): ['risk management', 'segment performance']\n",
      "2026-01-01 12:54:51,904 - INFO - MD&A quality — pages_match_toc: False\n",
      "2026-01-01 12:54:51,905 - INFO - MD&A quality — disqualifier_hit: True\n",
      "2026-01-01 12:54:51,905 - WARNING - MD&A quality FLAGGED (pages_match_toc=False, phrases_ok=True, disqualifier_hit=True)\n",
      "2026-01-01 12:54:51,906 - INFO - (3/14) Processing: ALok/5210700315.pdf\n",
      "2026-01-01 12:54:51,912 - INFO - Loaded PDF: 5210700315.pdf\n",
      "2026-01-01 12:54:52,482 - WARNING - Company name not found in header region; using folder name: ALok\n",
      "2026-01-01 12:54:52,483 - INFO - Financial year not found in first 5 pages\n",
      "2026-01-01 12:54:52,484 - INFO - MD&A boundaries (STRICT ToC blocks): start=51, end=82\n",
      "2026-01-01 12:54:52,504 - INFO - Adjusted MD&A start page after validation: 51 -> 49 (shift=-2)\n",
      "2026-01-01 12:54:52,505 - INFO - MD&A pages included: 32\n",
      "2026-01-01 12:54:52,506 - INFO - Extracted MD&A text length (chars): 109883\n",
      "2026-01-01 12:54:52,534 - INFO - MD&A text original length (chars): 109883\n",
      "2026-01-01 12:54:52,535 - INFO - MD&A text cleaned length (chars): 106116\n",
      "2026-01-01 12:54:52,547 - INFO - MD&A quality — word_count: 17599\n",
      "2026-01-01 12:54:52,548 - INFO - MD&A quality — narrative_density: 0.7602\n",
      "2026-01-01 12:54:52,549 - INFO - MD&A quality — keyword_hits (0): []\n",
      "2026-01-01 12:54:52,549 - INFO - MD&A quality — pages_match_toc: True\n",
      "2026-01-01 12:54:52,550 - INFO - MD&A quality — disqualifier_hit: True\n",
      "2026-01-01 12:54:52,550 - WARNING - MD&A quality FLAGGED (pages_match_toc=True, phrases_ok=False, disqualifier_hit=True)\n",
      "2026-01-01 12:54:52,553 - INFO - (4/14) Processing: ALok/5210700316.pdf\n",
      "2026-01-01 12:54:52,559 - INFO - Loaded PDF: 5210700316.pdf\n",
      "2026-01-01 12:54:52,936 - WARNING - Company name not found in header region; using folder name: ALok\n",
      "2026-01-01 12:54:52,937 - INFO - Extracted financial year: 2015-16\n",
      "2026-01-01 12:54:52,938 - INFO - MD&A boundaries (STRICT ToC blocks): start=46, end=62\n",
      "2026-01-01 12:54:52,948 - INFO - MD&A pages included: 14\n",
      "2026-01-01 12:54:52,949 - INFO - Extracted MD&A text length (chars): 62315\n",
      "2026-01-01 12:54:52,964 - INFO - MD&A text original length (chars): 62315\n",
      "2026-01-01 12:54:52,965 - INFO - MD&A text cleaned length (chars): 60293\n",
      "2026-01-01 12:54:52,973 - INFO - MD&A quality — word_count: 10263\n",
      "2026-01-01 12:54:52,974 - INFO - MD&A quality — narrative_density: 0.7507\n",
      "2026-01-01 12:54:52,975 - INFO - MD&A quality — keyword_hits (0): []\n",
      "2026-01-01 12:54:52,975 - INFO - MD&A quality — pages_match_toc: False\n",
      "2026-01-01 12:54:52,976 - INFO - MD&A quality — disqualifier_hit: False\n",
      "2026-01-01 12:54:52,976 - WARNING - MD&A quality FLAGGED (pages_match_toc=False, phrases_ok=False, disqualifier_hit=False)\n",
      "2026-01-01 12:54:52,979 - INFO - (5/14) Processing: ALok/5210700317.pdf\n",
      "2026-01-01 12:54:52,987 - INFO - Loaded PDF: 5210700317.pdf\n",
      "2026-01-01 12:54:53,659 - WARNING - Company name not found in header region; using folder name: ALok\n",
      "2026-01-01 12:54:53,661 - INFO - Extracted financial year: 2016-17\n",
      "2026-01-01 12:54:53,663 - INFO - MD&A boundaries (STRICT ToC blocks): start=9, end=9\n",
      "2026-01-01 12:54:53,708 - INFO - MD&A pages included: 1\n",
      "2026-01-01 12:54:53,709 - INFO - Extracted MD&A text length (chars): 2323\n",
      "2026-01-01 12:54:53,710 - INFO - MD&A text original length (chars): 2323\n",
      "2026-01-01 12:54:53,711 - INFO - MD&A text cleaned length (chars): 2281\n",
      "2026-01-01 12:54:53,712 - INFO - MD&A quality — word_count: 368\n",
      "2026-01-01 12:54:53,712 - INFO - MD&A quality — narrative_density: 0.8203\n",
      "2026-01-01 12:54:53,713 - INFO - MD&A quality — keyword_hits (0): []\n",
      "2026-01-01 12:54:53,713 - INFO - MD&A quality — pages_match_toc: True\n",
      "2026-01-01 12:54:53,713 - INFO - MD&A quality — disqualifier_hit: False\n",
      "2026-01-01 12:54:53,714 - WARNING - MD&A quality FLAGGED (pages_match_toc=True, phrases_ok=False, disqualifier_hit=False)\n",
      "2026-01-01 12:54:53,718 - INFO - (6/14) Processing: ALok/5210700318.pdf\n",
      "2026-01-01 12:54:53,724 - INFO - Loaded PDF: 5210700318.pdf\n",
      "2026-01-01 12:54:54,327 - WARNING - Company name not found in header region; using folder name: ALok\n",
      "2026-01-01 12:54:54,327 - INFO - Extracted financial year: 2017-18\n",
      "2026-01-01 12:54:54,329 - INFO - MD&A boundaries (STRICT ToC blocks): start=46, end=62\n",
      "2026-01-01 12:54:54,348 - INFO - Adjusted MD&A start page after validation: 1 -> 3 (shift=2)\n",
      "2026-01-01 12:54:54,349 - INFO - MD&A pages included: 1\n",
      "2026-01-01 12:54:54,349 - INFO - Extracted MD&A text length (chars): 2448\n",
      "2026-01-01 12:54:54,350 - INFO - MD&A text original length (chars): 2448\n",
      "2026-01-01 12:54:54,351 - INFO - MD&A text cleaned length (chars): 814\n",
      "2026-01-01 12:54:54,352 - INFO - MD&A quality — word_count: 102\n",
      "2026-01-01 12:54:54,353 - INFO - MD&A quality — narrative_density: 0.6990\n",
      "2026-01-01 12:54:54,354 - INFO - MD&A quality — keyword_hits (0): []\n",
      "2026-01-01 12:54:54,355 - INFO - MD&A quality — pages_match_toc: False\n",
      "2026-01-01 12:54:54,356 - INFO - MD&A quality — disqualifier_hit: True\n",
      "2026-01-01 12:54:54,356 - WARNING - MD&A quality FLAGGED (pages_match_toc=False, phrases_ok=False, disqualifier_hit=True)\n",
      "2026-01-01 12:54:54,358 - INFO - (7/14) Processing: Amit_spinning/5210760315.pdf\n",
      "2026-01-01 12:54:54,361 - INFO - Loaded PDF: 5210760315.pdf\n",
      "2026-01-01 12:54:54,504 - INFO - Extracted company name: AMIT SPINNING INDUSTRIES LIMITED\n",
      "2026-01-01 12:54:54,505 - INFO - Extracted financial year: 2014-15\n",
      "2026-01-01 12:54:54,507 - INFO - MD&A boundaries (STRICT ToC blocks): start=8, end=15\n",
      "2026-01-01 12:54:54,519 - INFO - Adjusted MD&A start page after validation: 12 -> 11 (shift=-1)\n",
      "2026-01-01 12:54:54,521 - INFO - MD&A pages included: 4\n",
      "2026-01-01 12:54:54,521 - INFO - Extracted MD&A text length (chars): 17311\n",
      "2026-01-01 12:54:54,525 - INFO - MD&A text original length (chars): 17311\n",
      "2026-01-01 12:54:54,526 - INFO - MD&A text cleaned length (chars): 16896\n",
      "2026-01-01 12:54:54,529 - INFO - MD&A quality — word_count: 2677\n",
      "2026-01-01 12:54:54,530 - INFO - MD&A quality — narrative_density: 0.7879\n",
      "2026-01-01 12:54:54,530 - INFO - MD&A quality — keyword_hits (1): ['risk management']\n",
      "2026-01-01 12:54:54,530 - INFO - MD&A quality — pages_match_toc: False\n",
      "2026-01-01 12:54:54,531 - INFO - MD&A quality — disqualifier_hit: True\n",
      "2026-01-01 12:54:54,531 - WARNING - MD&A quality FLAGGED (pages_match_toc=False, phrases_ok=False, disqualifier_hit=True)\n",
      "2026-01-01 12:54:54,532 - INFO - (8/14) Processing: Amit_spinning/5210760316.pdf\n",
      "2026-01-01 12:54:54,534 - INFO - Loaded PDF: 5210760316.pdf\n",
      "2026-01-01 12:54:54,729 - INFO - Extracted company name: AMIT SPINNING INDUSTRIES LIMITED\n",
      "2026-01-01 12:54:54,731 - INFO - Extracted financial year: 2015-16\n",
      "2026-01-01 12:54:54,732 - INFO - MD&A appears as sub-entry; inheriting parent start page 4 from 'Board's Report including'\n",
      "2026-01-01 12:54:54,736 - INFO - MD&A boundaries (STRICT ToC blocks): start=4, end=16\n",
      "2026-01-01 12:54:54,748 - INFO - MD&A pages included: 13\n",
      "2026-01-01 12:54:54,749 - INFO - Extracted MD&A text length (chars): 47321\n",
      "2026-01-01 12:54:54,764 - INFO - MD&A text original length (chars): 47321\n",
      "2026-01-01 12:54:54,765 - INFO - MD&A text cleaned length (chars): 45127\n",
      "2026-01-01 12:54:54,771 - INFO - MD&A quality — word_count: 7541\n",
      "2026-01-01 12:54:54,771 - INFO - MD&A quality — narrative_density: 0.7504\n",
      "2026-01-01 12:54:54,772 - INFO - MD&A quality — keyword_hits (2): ['risk management', 'future outlook']\n",
      "2026-01-01 12:54:54,772 - INFO - MD&A quality — pages_match_toc: True\n",
      "2026-01-01 12:54:54,773 - INFO - MD&A quality — disqualifier_hit: True\n",
      "2026-01-01 12:54:54,773 - WARNING - MD&A quality FLAGGED (pages_match_toc=True, phrases_ok=True, disqualifier_hit=True)\n",
      "2026-01-01 12:54:54,774 - INFO - (9/14) Processing: Amit_spinning/5210760317.pdf\n",
      "2026-01-01 12:54:54,778 - INFO - Loaded PDF: 5210760317.pdf\n",
      "2026-01-01 12:54:54,945 - WARNING - Falling back to default company name for Amit_spinning\n",
      "2026-01-01 12:54:54,946 - INFO - Extracted financial year: 2016-17\n",
      "2026-01-01 12:54:54,947 - WARNING - MD&A start page not found within strict 3-line window; skipping\n",
      "2026-01-01 12:54:54,948 - INFO - Amit_spinning MD&A boundaries (INDEX): start=3, end=28\n",
      "2026-01-01 12:54:54,957 - INFO - MD&A pages included: 26\n",
      "2026-01-01 12:54:54,959 - INFO - Extracted MD&A text length (chars): 108212\n",
      "2026-01-01 12:54:54,993 - INFO - MD&A text original length (chars): 108212\n",
      "2026-01-01 12:54:54,993 - INFO - MD&A text cleaned length (chars): 105024\n",
      "2026-01-01 12:54:55,008 - INFO - MD&A quality — word_count: 17248\n",
      "2026-01-01 12:54:55,008 - INFO - MD&A quality — narrative_density: 0.7689\n",
      "2026-01-01 12:54:55,009 - INFO - MD&A quality — keyword_hits (1): ['risk management']\n",
      "2026-01-01 12:54:55,010 - INFO - MD&A quality — pages_match_toc: True\n",
      "2026-01-01 12:54:55,011 - INFO - MD&A quality — disqualifier_hit: True\n",
      "2026-01-01 12:54:55,012 - WARNING - MD&A quality FLAGGED (pages_match_toc=True, phrases_ok=False, disqualifier_hit=True)\n",
      "2026-01-01 12:54:55,014 - INFO - (10/14) Processing: Amit_spinning/5210760318.pdf\n",
      "2026-01-01 12:54:55,018 - INFO - Loaded PDF: 5210760318.pdf\n",
      "2026-01-01 12:54:55,107 - INFO - Extracted company name: AMIT SPINNING INDUSTRIES LTD\n",
      "2026-01-01 12:54:55,110 - INFO - Extracted financial year: 2017-18\n",
      "2026-01-01 12:54:55,111 - WARNING - MD&A start page not found within strict 3-line window; skipping\n",
      "2026-01-01 12:54:55,112 - INFO - Amit_spinning MD&A boundaries (INDEX): start=1, end=21\n",
      "2026-01-01 12:54:55,127 - INFO - Adjusted MD&A start page after validation: 1 -> 3 (shift=2)\n",
      "2026-01-01 12:54:55,129 - INFO - MD&A pages included: 21\n",
      "2026-01-01 12:54:55,130 - INFO - Extracted MD&A text length (chars): 89718\n",
      "2026-01-01 12:54:55,161 - INFO - MD&A text original length (chars): 89718\n",
      "2026-01-01 12:54:55,162 - INFO - MD&A text cleaned length (chars): 88066\n",
      "2026-01-01 12:54:55,175 - INFO - MD&A quality — word_count: 14038\n",
      "2026-01-01 12:54:55,175 - INFO - MD&A quality — narrative_density: 0.7867\n",
      "2026-01-01 12:54:55,176 - INFO - MD&A quality — keyword_hits (1): ['risk management']\n",
      "2026-01-01 12:54:55,177 - INFO - MD&A quality — pages_match_toc: True\n",
      "2026-01-01 12:54:55,178 - INFO - MD&A quality — disqualifier_hit: True\n",
      "2026-01-01 12:54:55,180 - WARNING - MD&A quality FLAGGED (pages_match_toc=True, phrases_ok=False, disqualifier_hit=True)\n",
      "2026-01-01 12:54:55,181 - INFO - (11/14) Processing: Amtek/5200770316.pdf\n",
      "2026-01-01 12:54:55,183 - INFO - Loaded PDF: 5200770316.pdf\n",
      "2026-01-01 12:54:55,575 - INFO - Extracted company name: AMTEK AUTO LIMITED\n",
      "2026-01-01 12:54:55,576 - INFO - Extracted financial year: 2015-16\n",
      "2026-01-01 12:54:55,580 - INFO - MD&A boundaries (STRICT ToC blocks): start=63, end=71\n",
      "2026-01-01 12:54:55,614 - INFO - MD&A pages included: 34\n",
      "2026-01-01 12:54:55,616 - INFO - Extracted MD&A text length (chars): 89359\n",
      "2026-01-01 12:54:55,651 - INFO - MD&A text original length (chars): 89359\n",
      "2026-01-01 12:54:55,652 - INFO - MD&A text cleaned length (chars): 87846\n",
      "2026-01-01 12:54:55,673 - INFO - MD&A quality — word_count: 13654\n",
      "2026-01-01 12:54:55,674 - INFO - MD&A quality — narrative_density: 0.7906\n",
      "2026-01-01 12:54:55,675 - INFO - MD&A quality — keyword_hits (3): ['opportunities and threats', 'risk management', 'global economy']\n",
      "2026-01-01 12:54:55,675 - INFO - MD&A quality — pages_match_toc: False\n",
      "2026-01-01 12:54:55,676 - INFO - MD&A quality — disqualifier_hit: True\n",
      "2026-01-01 12:54:55,677 - WARNING - MD&A quality FLAGGED (pages_match_toc=False, phrases_ok=True, disqualifier_hit=True)\n",
      "2026-01-01 12:54:55,680 - INFO - (12/14) Processing: Amtek/5200770317.pdf\n",
      "2026-01-01 12:54:55,682 - INFO - Loaded PDF: 5200770317.pdf\n",
      "2026-01-01 12:54:56,261 - INFO - Extracted company name: AMTEK AUTO LIMITED\n",
      "2026-01-01 12:54:56,262 - INFO - Extracted financial year: 2016-17\n",
      "2026-01-01 12:54:56,266 - INFO - MD&A boundaries (STRICT ToC blocks): start=64, end=72\n",
      "2026-01-01 12:54:56,291 - INFO - Adjusted MD&A start page after validation: 64 -> 65 (shift=1)\n",
      "2026-01-01 12:54:56,292 - INFO - MD&A pages included: 9\n",
      "2026-01-01 12:54:56,293 - INFO - Extracted MD&A text length (chars): 31283\n",
      "2026-01-01 12:54:56,303 - INFO - MD&A text original length (chars): 31283\n",
      "2026-01-01 12:54:56,304 - INFO - MD&A text cleaned length (chars): 31061\n",
      "2026-01-01 12:54:56,310 - INFO - MD&A quality — word_count: 4869\n",
      "2026-01-01 12:54:56,311 - INFO - MD&A quality — narrative_density: 0.8030\n",
      "2026-01-01 12:54:56,311 - INFO - MD&A quality — keyword_hits (0): []\n",
      "2026-01-01 12:54:56,312 - INFO - MD&A quality — pages_match_toc: True\n",
      "2026-01-01 12:54:56,313 - INFO - MD&A quality — disqualifier_hit: True\n",
      "2026-01-01 12:54:56,313 - WARNING - MD&A quality FLAGGED (pages_match_toc=True, phrases_ok=False, disqualifier_hit=True)\n",
      "2026-01-01 12:54:56,314 - INFO - (13/14) Processing: Amtek/5200770318.pdf\n",
      "2026-01-01 12:54:56,317 - INFO - Loaded PDF: 5200770318.pdf\n",
      "2026-01-01 12:54:57,088 - INFO - Extracted company name: AMTEK AUTO LIMITED\n",
      "2026-01-01 12:54:57,089 - INFO - Extracted financial year: 2017-18\n",
      "2026-01-01 12:54:57,091 - INFO - MD&A boundaries (STRICT ToC blocks): start=65, end=74\n",
      "2026-01-01 12:54:57,111 - INFO - Adjusted MD&A start page after validation: 65 -> 66 (shift=1)\n",
      "2026-01-01 12:54:57,112 - INFO - MD&A pages included: 10\n",
      "2026-01-01 12:54:57,113 - INFO - Extracted MD&A text length (chars): 27330\n",
      "2026-01-01 12:54:57,120 - INFO - MD&A text original length (chars): 27330\n",
      "2026-01-01 12:54:57,121 - INFO - MD&A text cleaned length (chars): 26829\n",
      "2026-01-01 12:54:57,126 - INFO - MD&A quality — word_count: 4217\n",
      "2026-01-01 12:54:57,126 - INFO - MD&A quality — narrative_density: 0.7960\n",
      "2026-01-01 12:54:57,127 - INFO - MD&A quality — keyword_hits (1): ['global economy']\n",
      "2026-01-01 12:54:57,128 - INFO - MD&A quality — pages_match_toc: True\n",
      "2026-01-01 12:54:57,130 - INFO - MD&A quality — disqualifier_hit: True\n",
      "2026-01-01 12:54:57,131 - WARNING - MD&A quality FLAGGED (pages_match_toc=True, phrases_ok=False, disqualifier_hit=True)\n",
      "2026-01-01 12:54:57,132 - INFO - (14/14) Processing: Amtek/5200770915.pdf\n",
      "2026-01-01 12:54:57,135 - INFO - Loaded PDF: 5200770915.pdf\n",
      "2026-01-01 12:54:57,470 - INFO - Extracted company name: AMTEK AUTO LIMITED\n",
      "2026-01-01 12:54:57,471 - INFO - Extracted financial year: 2014-15\n",
      "2026-01-01 12:54:57,478 - INFO - MD&A boundaries (STRICT ToC blocks): start=56, end=63\n",
      "2026-01-01 12:54:57,504 - INFO - MD&A pages included: 8\n",
      "2026-01-01 12:54:57,505 - INFO - Extracted MD&A text length (chars): 23796\n",
      "2026-01-01 12:54:57,517 - INFO - MD&A text original length (chars): 23796\n",
      "2026-01-01 12:54:57,519 - INFO - MD&A text cleaned length (chars): 23497\n",
      "2026-01-01 12:54:57,526 - INFO - MD&A quality — word_count: 3631\n",
      "2026-01-01 12:54:57,527 - INFO - MD&A quality — narrative_density: 0.8120\n",
      "2026-01-01 12:54:57,528 - INFO - MD&A quality — keyword_hits (2): ['risk management', 'global economy']\n",
      "2026-01-01 12:54:57,530 - INFO - MD&A quality — pages_match_toc: True\n",
      "2026-01-01 12:54:57,531 - INFO - MD&A quality — disqualifier_hit: True\n",
      "2026-01-01 12:54:57,532 - WARNING - MD&A quality FLAGGED (pages_match_toc=True, phrases_ok=True, disqualifier_hit=True)\n",
      "2026-01-01 12:54:57,562 - INFO - Saved CSV: c:\\Users\\LOQ\\Desktop\\SPJIMR\\mdna_extraction_project\\notebooks\\..\\output\\mdna_extracted.csv\n",
      "2026-01-01 12:54:57,659 - INFO - Saved Excel: c:\\Users\\LOQ\\Desktop\\SPJIMR\\mdna_extraction_project\\notebooks\\..\\output\\mdna_extracted.xlsx\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "# -----------------------------\n",
    "# End-to-end MD&A Extraction Pipeline (STRICT ToC-Only Boundaries)\n",
    "# -----------------------------\n",
    "PDF_ROOT = Path(\"../data/pdfs\")\n",
    "\n",
    "# Prefer the configured OUTPUT_DIR if present; otherwise default to ../output\n",
    "try:\n",
    "    output_dir = OUTPUT_DIR\n",
    "except NameError:\n",
    "    output_dir = Path(\"../output\")\n",
    "\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "pdf_paths = sorted(PDF_ROOT.rglob(\"*.pdf\"))\n",
    "logging.info(\"Discovered %d PDFs under %s\", len(pdf_paths), PDF_ROOT)\n",
    "\n",
    "results = []\n",
    "\n",
    "attempted = 0\n",
    "succeeded = 0\n",
    "skipped_no_boundaries = 0\n",
    "failed = 0\n",
    "passed_quality = 0\n",
    "flagged_quality = 0\n",
    "\n",
    "for idx, pdf_path in enumerate(pdf_paths, start=1):\n",
    "    attempted += 1\n",
    "    company_folder = pdf_path.parent.name\n",
    "\n",
    "    logging.info(\"(%d/%d) Processing: %s/%s\", idx, len(pdf_paths), company_folder, pdf_path.name)\n",
    "\n",
    "    pdf = None\n",
    "    try:\n",
    "        pdf = PDFInterface(pdf_path)\n",
    "        pages = pdf.get_pages_text()\n",
    "        max_page = len(pages)\n",
    "\n",
    "        company_name = extract_company_name(pages, company_folder=company_folder)\n",
    "        financial_year = extract_financial_year(pages)\n",
    "\n",
    "        # STRICT ToC-only boundaries: if not deterministically resolvable from ToC lines, skip.\n",
    "        start_page, end_page = detect_mdna_boundaries(\n",
    "            pages_text=pages,\n",
    "            toc_start_page=None,\n",
    "            company_folder=company_folder,\n",
    "        )\n",
    "\n",
    "        if not start_page or not end_page:\n",
    "            skipped_no_boundaries += 1\n",
    "            logging.warning(\"Skipping (MD&A boundaries not determinable via STRICT ToC rules): %s\", pdf_path.name)\n",
    "            continue\n",
    "\n",
    "        # --- Printed page -> PDF page mapping (preferred) ---\n",
    "        printed_to_pdf = build_printed_to_pdf_page_map(pages)\n",
    "\n",
    "        start_page_pdf = printed_to_pdf.get(int(start_page))\n",
    "        end_page_pdf = printed_to_pdf.get(int(end_page))\n",
    "\n",
    "        # --- Anchor-based offset (fallback) ---\n",
    "        offset = 0\n",
    "        if start_page_pdf is None or end_page_pdf is None:\n",
    "            solver = PageOffsetSolver(pdf.doc, pages_text=pages, toc_max_pages=15)\n",
    "            offset = solver.find_offset()\n",
    "\n",
    "        if start_page_pdf is None:\n",
    "            start_page_pdf = start_page + offset\n",
    "        if end_page_pdf is None:\n",
    "            end_page_pdf = end_page + offset\n",
    "        # ------------------------------------\n",
    "\n",
    "        # Clamp to document bounds\n",
    "        start_page_pdf = max(1, min(int(start_page_pdf), max_page))\n",
    "        end_page_pdf = max(1, min(int(end_page_pdf), max_page))\n",
    "        if end_page_pdf < start_page_pdf:\n",
    "            end_page_pdf = start_page_pdf\n",
    "\n",
    "        # Validate start page contains MD&A-ish keywords; else search +/-3.\n",
    "        # If start shifts, shift end by the same amount to preserve section length.\n",
    "        original_start_page_pdf = start_page_pdf\n",
    "        start_page_pdf_validated = validate_and_adjust_start_page(pdf.doc, start_page_pdf)\n",
    "        shift = int(start_page_pdf_validated - original_start_page_pdf)\n",
    "\n",
    "        if shift != 0:\n",
    "            logging.info(\n",
    "                \"Adjusted MD&A start page after validation: %s -> %s (shift=%s)\",\n",
    "                original_start_page_pdf,\n",
    "                start_page_pdf_validated,\n",
    "                shift,\n",
    "            )\n",
    "            end_page_pdf = end_page_pdf + shift\n",
    "            end_page_pdf = max(1, min(int(end_page_pdf), max_page))\n",
    "            if end_page_pdf < start_page_pdf_validated:\n",
    "                end_page_pdf = start_page_pdf_validated\n",
    "\n",
    "        start_page_pdf = start_page_pdf_validated\n",
    "\n",
    "        raw_mdna_text = extract_mdna_text(pages_text=pages, start_page=start_page_pdf, end_page=end_page_pdf)\n",
    "        cleaned_mdna_text = clean_mdna_text(raw_mdna_text)\n",
    "\n",
    "        # STRICT: extracted page count must match the ToC-declared MD&A range length\n",
    "        expected_pages = end_page - start_page + 1\n",
    "        actual_pages = sum(\n",
    "            1\n",
    "            for p in pages\n",
    "            if isinstance(p.get(\"page_number\"), int) and start_page_pdf <= p.get(\"page_number\") <= end_page_pdf\n",
    "        )\n",
    "        pages_match_toc = bool(actual_pages == expected_pages)\n",
    "\n",
    "        quality_report = verify_mdna_quality(cleaned_mdna_text, pages_match_toc=pages_match_toc)\n",
    "\n",
    "        if quality_report.get(\"quality_passed\"):\n",
    "            passed_quality += 1\n",
    "        else:\n",
    "            flagged_quality += 1\n",
    "\n",
    "        results.append(\n",
    "            {\n",
    "                \"company_folder\": company_folder,\n",
    "                \"company_name\": company_name,\n",
    "                \"report_file\": pdf_path.name,\n",
    "                \"financial_year\": financial_year,\n",
    "                \"mdna_start_page\": start_page_pdf,\n",
    "                \"mdna_end_page\": end_page_pdf,\n",
    "                \"mdna_text\": cleaned_mdna_text,\n",
    "                **quality_report,\n",
    "            }\n",
    "        )\n",
    "\n",
    "        succeeded += 1\n",
    "\n",
    "    except Exception as e:\n",
    "        failed += 1\n",
    "        logging.exception(\"Failed processing %s: %s\", pdf_path, e)\n",
    "\n",
    "    finally:\n",
    "        if pdf is not None:\n",
    "            pdf.close()\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# -----------------------------\n",
    "# Safe CSV/Excel writes (avoid Windows PermissionError when file is open)\n",
    "# -----------------------------\n",
    "run_stamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "csv_path = output_dir / \"mdna_extracted.csv\"\n",
    "xlsx_path = output_dir / \"mdna_extracted.xlsx\"\n",
    "\n",
    "fallback_csv = output_dir / f\"mdna_extracted_{run_stamp}.csv\"\n",
    "fallback_xlsx = output_dir / f\"mdna_extracted_{run_stamp}.xlsx\"\n",
    "\n",
    "# Excel safety: remove illegal control characters\n",
    "def _sanitize_for_excel(val):\n",
    "    if val is None:\n",
    "        return \"\"\n",
    "    if isinstance(val, (list, dict, tuple, set)):\n",
    "        val = str(val)\n",
    "    s = str(val)\n",
    "    return re.sub(r\"[\\x00-\\x08\\x0B\\x0C\\x0E-\\x1F]\", \"\", s)\n",
    "\n",
    "excel_df = results_df.copy()\n",
    "for col in excel_df.columns:\n",
    "    excel_df[col] = excel_df[col].map(_sanitize_for_excel)\n",
    "\n",
    "try:\n",
    "    results_df.to_csv(csv_path, index=False, encoding=\"utf-8\")\n",
    "    logging.info(\"Saved CSV: %s\", csv_path)\n",
    "except PermissionError:\n",
    "    results_df.to_csv(fallback_csv, index=False, encoding=\"utf-8\")\n",
    "    logging.warning(\"CSV locked; saved fallback CSV: %s\", fallback_csv)\n",
    "\n",
    "try:\n",
    "    excel_df.to_excel(xlsx_path, index=False)\n",
    "    logging.info(\"Saved Excel: %s\", xlsx_path)\n",
    "except PermissionError:\n",
    "    excel_df.to_excel(fallback_xlsx, index=False)\n",
    "    logging.warning(\"Excel locked; saved fallback Excel: %s\", fallback_xlsx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "87c53bf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Pipeline output summary\n",
      "- results_df shape: (14, 11)\n",
      "- quality passed: 0\n",
      "- quality flagged: 14\n"
     ]
    }
   ],
   "source": [
    "# Quick summary of how many rows were extracted\n",
    "print(\"\\nPipeline output summary\")\n",
    "print(\"- results_df shape:\", results_df.shape)\n",
    "print(\"- quality passed:\", int((results_df[\"quality_passed\"] == True).sum()) if \"quality_passed\" in results_df.columns else \"N/A\")\n",
    "print(\"- quality flagged:\", int((results_df[\"quality_passed\"] == False).sum()) if \"quality_passed\" in results_df.columns else \"N/A\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3cd9bb54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MD&A extraction diagnostics\n",
      "- has_mdna_heading: 13 / 14\n",
      "- has_structure_or_outlook: 11 / 14\n",
      "- has_audit_terms (should be low): 10 / 14\n",
      "- has_directors_report (should be low): 6 / 14\n",
      "- keyword_hits_count>=2 (required by current quality gate): 4 / 14\n",
      "\n",
      "Sample rows (first 10):\n",
      "company_folder     report_file financial_year  mdna_start_page  mdna_end_page  word_count  narrative_density                           keyword_hits  has_mdna_heading  has_structure_or_outlook  has_audit_terms  has_directors_report  quality_passed\n",
      "    Alcheimist  5267070319.pdf        2018-19               26             45        7935           0.779926                      [risk management]              True                      True            False                 False           False\n",
      "    Alcheimist 67050526707.pdf        2019-20               29             74       25113           0.776934 [risk management, segment performance]              True                      True             True                 False           False\n",
      "          ALok  5210700315.pdf           None               49             80       17599           0.760168                                     []              True                      True             True                  True           False\n",
      "          ALok  5210700316.pdf        2015-16               49             62       10263           0.750717                                     []              True                      True            False                 False           False\n",
      "          ALok  5210700317.pdf        2016-17                9              9         368           0.820254                                     []             False                     False            False                 False           False\n",
      "          ALok  5210700318.pdf        2017-18                3              3         102           0.699017                                     []              True                     False             True                  True           False\n",
      " Amit_spinning  5210760315.pdf        2014-15               11             14        2677           0.787879                      [risk management]              True                     False            False                  True           False\n",
      " Amit_spinning  5210760316.pdf        2015-16                7             19        7541           0.750371      [risk management, future outlook]              True                      True             True                 False           False\n",
      " Amit_spinning  5210760317.pdf        2016-17                3             28       17248           0.768872                      [risk management]              True                      True             True                  True           False\n",
      " Amit_spinning  5210760318.pdf        2017-18                3             23       14038           0.786694                      [risk management]              True                      True             True                  True           False\n"
     ]
    }
   ],
   "source": [
    "# Diagnostics: sanity-check extracted MD&A text looks like MD&A (not Audit/Directors)\n",
    "import re\n",
    "\n",
    "if \"results_df\" not in globals() or results_df is None or results_df.empty:\n",
    "    print(\"results_df is empty; run the pipeline cell first\")\n",
    "else:\n",
    "    df = results_df.copy()\n",
    "\n",
    "    def _contains(pat: str, s: str) -> bool:\n",
    "        return bool(re.search(pat, s or \"\", flags=re.IGNORECASE))\n",
    "\n",
    "    df[\"has_mdna_heading\"] = df[\"mdna_text\"].map(lambda s: _contains(r\"management\\s+discussion\", s))\n",
    "    df[\"has_structure_or_outlook\"] = df[\"mdna_text\"].map(lambda s: _contains(r\"\\bstructure\\b|\\boutlook\\b\", s))\n",
    "    df[\"has_audit_terms\"] = df[\"mdna_text\"].map(lambda s: _contains(r\"independent\\s+auditor|auditors?\\s*[’']?\\s*report\", s))\n",
    "    df[\"has_directors_report\"] = df[\"mdna_text\"].map(lambda s: _contains(r\"directors?\\s*[’']?\\s*report\", s))\n",
    "    df[\"keyword_hits_count\"] = df[\"keyword_hits\"].map(lambda x: len(x) if isinstance(x, list) else 0)\n",
    "\n",
    "    print(\"\\nMD&A extraction diagnostics\")\n",
    "    print(\"- has_mdna_heading:\", int(df[\"has_mdna_heading\"].sum()), \"/\", len(df))\n",
    "    print(\"- has_structure_or_outlook:\", int(df[\"has_structure_or_outlook\"].sum()), \"/\", len(df))\n",
    "    print(\"- has_audit_terms (should be low):\", int(df[\"has_audit_terms\"].sum()), \"/\", len(df))\n",
    "    print(\"- has_directors_report (should be low):\", int(df[\"has_directors_report\"].sum()), \"/\", len(df))\n",
    "    print(\"- keyword_hits_count>=2 (required by current quality gate):\", int((df[\"keyword_hits_count\"] >= 2).sum()), \"/\", len(df))\n",
    "\n",
    "    show_cols = [\n",
    "        \"company_folder\",\n",
    "        \"report_file\",\n",
    "        \"financial_year\",\n",
    "        \"mdna_start_page\",\n",
    "        \"mdna_end_page\",\n",
    "        \"word_count\",\n",
    "        \"narrative_density\",\n",
    "        \"keyword_hits\",\n",
    "        \"has_mdna_heading\",\n",
    "        \"has_structure_or_outlook\",\n",
    "        \"has_audit_terms\",\n",
    "        \"has_directors_report\",\n",
    "        \"quality_passed\",\n",
    "    ]\n",
    "    show_cols = [c for c in show_cols if c in df.columns]\n",
    "\n",
    "    print(\"\\nSample rows (first 10):\")\n",
    "    print(df[show_cols].head(10).to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "005a8e67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "results_df columns: ['company_folder', 'company_name', 'report_file', 'financial_year', 'mdna_start_page', 'mdna_end_page', 'mdna_text', 'word_count', 'narrative_density', 'keyword_hits', 'quality_passed']\n",
      "\n",
      "Amit_spinning preview (after running Cell 18):\n",
      "company_folder    report_file financial_year  mdna_start_page  mdna_end_page  word_count  quality_passed\n",
      " Amit_spinning 5210760315.pdf        2014-15                8             15        5952           False\n",
      " Amit_spinning 5210760316.pdf        2015-16                3             16        9156           False\n",
      " Amit_spinning 5210760317.pdf        2016-17                3             28       17248           False\n",
      " Amit_spinning 5210760318.pdf        2017-18                3             21       12623           False\n"
     ]
    }
   ],
   "source": [
    "# Diagnostic: confirm Amit_spinning PDFs were processed in the latest run\n",
    "if \"results_df\" in globals() and results_df is not None:\n",
    "    print(\"\\nresults_df columns:\", list(results_df.columns))\n",
    "\n",
    "    company_col = \"company_folder\" if \"company_folder\" in results_df.columns else (\"company\" if \"company\" in results_df.columns else None)\n",
    "    if company_col:\n",
    "        subset = results_df[results_df[company_col] == \"Amit_spinning\"].copy()\n",
    "        print(\"\\nAmit_spinning preview (after running Cell 18):\")\n",
    "        if subset.empty:\n",
    "            print(\"(none)\")\n",
    "        else:\n",
    "            display_cols = [c for c in [\n",
    "                company_col,\n",
    "                \"report_file\",\n",
    "                \"financial_year\",\n",
    "                \"mdna_start_page\",\n",
    "                \"mdna_end_page\",\n",
    "                \"word_count\",\n",
    "                \"quality_passed\",\n",
    "            ] if c in subset.columns]\n",
    "            subset = subset.sort_values([\"financial_year\"] if \"financial_year\" in subset.columns else [company_col])\n",
    "            print(subset[display_cols].to_string(index=False))\n",
    "    else:\n",
    "        print(\"Could not find a company column in results_df\")\n",
    "else:\n",
    "    print(\"results_df not found; run Cell 18 first\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a63f7832",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diagnostic: quick look at extracted company names (one per folder)\n",
    "if \"results_df\" in globals() and results_df is not None and not results_df.empty:\n",
    "    if {\"company_folder\", \"company_name\"}.issubset(results_df.columns):\n",
    "        print(\"\\nCompany names (folder -> extracted):\")\n",
    "        pairs = results_df[[\"company_folder\", \"company_name\"]].drop_duplicates().sort_values(\"company_folder\")\n",
    "        print(pairs.to_string(index=False))\n",
    "    else:\n",
    "        print(\"company_folder/company_name columns not present\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58af4447",
   "metadata": {},
   "source": [
    "### Test cell — MD&A Boundary Detection "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "eccabf06",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-01 12:52:14,244 - INFO - Loaded PDF: 5267070319.pdf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing MD&A boundary detection on sample PDFs:\n",
      "\n",
      "======================================================================\n",
      "Company Folder : Alcheimist\n",
      "PDF File       : 5267070319.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-01 12:52:14,671 - WARNING - Excluded section found but page number not aligned; ignoring exclusion: DIRECTORS’ REPORT\n",
      "2026-01-01 12:52:14,673 - INFO - MD&A boundaries (STRICT ToC blocks): start=23, end=100\n",
      "2026-01-01 12:52:14,677 - INFO - Loaded PDF: 5210700315.pdf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected MD&A Start Page: 23\n",
      "Detected MD&A End Page  : 100\n",
      "✔ Boundary detection looks valid\n",
      "======================================================================\n",
      "Company Folder : ALok\n",
      "PDF File       : 5210700315.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-01 12:52:15,250 - INFO - MD&A boundaries (STRICT ToC blocks): start=51, end=82\n",
      "2026-01-01 12:52:15,253 - INFO - Loaded PDF: 5210760318.pdf\n",
      "2026-01-01 12:52:15,332 - WARNING - MD&A start page not found within strict 3-line window; skipping\n",
      "2026-01-01 12:52:15,333 - INFO - Amit_spinning MD&A boundaries (INDEX): start=1, end=21\n",
      "2026-01-01 12:52:15,335 - INFO - Loaded PDF: 5200770316.pdf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected MD&A Start Page: 51\n",
      "Detected MD&A End Page  : 82\n",
      "✔ Boundary detection looks valid\n",
      "======================================================================\n",
      "Company Folder : Amit_spinning\n",
      "PDF File       : 5210760318.pdf\n",
      "Detected MD&A Start Page: 1\n",
      "Detected MD&A End Page  : 21\n",
      "✔ Boundary detection looks valid\n",
      "======================================================================\n",
      "Company Folder : Amtek\n",
      "PDF File       : 5200770316.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-01 12:52:15,608 - INFO - MD&A boundaries (STRICT ToC blocks): start=63, end=71\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected MD&A Start Page: 63\n",
      "Detected MD&A End Page  : 71\n",
      "✔ Boundary detection looks valid\n",
      "\n",
      "Boundary detection test completed.\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "PDF_ROOT = Path(\"../data/pdfs\")\n",
    "\n",
    "# Pick ONE representative PDF per company\n",
    "test_pdfs = {}\n",
    "for pdf in PDF_ROOT.rglob(\"*.pdf\"):\n",
    "    company = pdf.parent.name\n",
    "    if company not in test_pdfs:\n",
    "        test_pdfs[company] = pdf\n",
    "\n",
    "# Prefer an INDEX-style Amit_spinning file that exercises the special-case logic\n",
    "amit_preferred = PDF_ROOT / \"Amit_spinning\" / \"5210760318.pdf\"\n",
    "if amit_preferred.exists():\n",
    "    test_pdfs[\"Amit_spinning\"] = amit_preferred\n",
    "\n",
    "print(\"Testing MD&A boundary detection on sample PDFs:\\n\")\n",
    "\n",
    "for company, pdf_path in test_pdfs.items():\n",
    "    print(\"=\" * 70)\n",
    "    print(f\"Company Folder : {company}\")\n",
    "    print(f\"PDF File       : {pdf_path.name}\")\n",
    "\n",
    "    pdf = PDFInterface(pdf_path)\n",
    "    pages = pdf.get_pages_text()\n",
    "\n",
    "    start_page, end_page = detect_mdna_boundaries(\n",
    "        pages_text=pages,\n",
    "        toc_start_page=None,\n",
    "        company_folder=company,\n",
    "    )\n",
    "\n",
    "    print(f\"Detected MD&A Start Page: {start_page}\")\n",
    "    print(f\"Detected MD&A End Page  : {end_page}\")\n",
    "\n",
    "    if start_page and end_page:\n",
    "        assert start_page <= end_page, \"Start page must be strictly before end page\"\n",
    "        assert 1 <= start_page <= len(pages), \"Start page out of range\"\n",
    "        assert 1 <= end_page <= len(pages), \"End page out of range\"\n",
    "        print(\"✔ Boundary detection looks valid\")\n",
    "    else:\n",
    "        print(\"⚠ MD&A boundaries not detected (may require fallback logic)\")\n",
    "\n",
    "print(\"\\nBoundary detection test completed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1867170e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-01 01:30:54,498 - INFO - Loaded PDF: 5210760315.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-01 01:30:54,498 - INFO - Loaded PDF: 5210760315.pdf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Amit_spinning PDFs: ['5210760315.pdf', '5210760316.pdf', '5210760317.pdf', '5210760318.pdf']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-01 01:30:54,751 - INFO - MD&A boundaries (STRICT ToC blocks): start=8, end=15\n",
      "2026-01-01 01:30:54,755 - INFO - Loaded PDF: 5210760316.pdf\n",
      "2026-01-01 01:30:54,944 - INFO - MD&A appears as sub-entry; inheriting parent start page 4 from 'Board's Report including'\n",
      "2026-01-01 01:30:54,947 - INFO - MD&A boundaries (STRICT ToC blocks): start=4, end=16\n",
      "2026-01-01 01:30:54,950 - INFO - Loaded PDF: 5210760317.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-01 01:30:54,498 - INFO - Loaded PDF: 5210760315.pdf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Amit_spinning PDFs: ['5210760315.pdf', '5210760316.pdf', '5210760317.pdf', '5210760318.pdf']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-01 01:30:54,751 - INFO - MD&A boundaries (STRICT ToC blocks): start=8, end=15\n",
      "2026-01-01 01:30:54,755 - INFO - Loaded PDF: 5210760316.pdf\n",
      "2026-01-01 01:30:54,944 - INFO - MD&A appears as sub-entry; inheriting parent start page 4 from 'Board's Report including'\n",
      "2026-01-01 01:30:54,947 - INFO - MD&A boundaries (STRICT ToC blocks): start=4, end=16\n",
      "2026-01-01 01:30:54,950 - INFO - Loaded PDF: 5210760317.pdf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5210760315.pdf: start=8, end=15, doc_pages=46\n",
      "5210760316.pdf: start=4, end=16, doc_pages=49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-01 01:30:54,498 - INFO - Loaded PDF: 5210760315.pdf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Amit_spinning PDFs: ['5210760315.pdf', '5210760316.pdf', '5210760317.pdf', '5210760318.pdf']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-01 01:30:54,751 - INFO - MD&A boundaries (STRICT ToC blocks): start=8, end=15\n",
      "2026-01-01 01:30:54,755 - INFO - Loaded PDF: 5210760316.pdf\n",
      "2026-01-01 01:30:54,944 - INFO - MD&A appears as sub-entry; inheriting parent start page 4 from 'Board's Report including'\n",
      "2026-01-01 01:30:54,947 - INFO - MD&A boundaries (STRICT ToC blocks): start=4, end=16\n",
      "2026-01-01 01:30:54,950 - INFO - Loaded PDF: 5210760317.pdf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5210760315.pdf: start=8, end=15, doc_pages=46\n",
      "5210760316.pdf: start=4, end=16, doc_pages=49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-01 01:30:55,154 - WARNING - MD&A start page not found within strict 3-line window; skipping\n",
      "2026-01-01 01:30:55,155 - INFO - Amit_spinning MD&A boundaries (INDEX): start=3, end=28\n",
      "2026-01-01 01:30:55,159 - INFO - Loaded PDF: 5210760318.pdf\n",
      "2026-01-01 01:30:55,320 - WARNING - MD&A start page not found within strict 3-line window; skipping\n",
      "2026-01-01 01:30:55,326 - INFO - Amit_spinning MD&A boundaries (INDEX): start=1, end=21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-01 01:30:54,498 - INFO - Loaded PDF: 5210760315.pdf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Amit_spinning PDFs: ['5210760315.pdf', '5210760316.pdf', '5210760317.pdf', '5210760318.pdf']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-01 01:30:54,751 - INFO - MD&A boundaries (STRICT ToC blocks): start=8, end=15\n",
      "2026-01-01 01:30:54,755 - INFO - Loaded PDF: 5210760316.pdf\n",
      "2026-01-01 01:30:54,944 - INFO - MD&A appears as sub-entry; inheriting parent start page 4 from 'Board's Report including'\n",
      "2026-01-01 01:30:54,947 - INFO - MD&A boundaries (STRICT ToC blocks): start=4, end=16\n",
      "2026-01-01 01:30:54,950 - INFO - Loaded PDF: 5210760317.pdf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5210760315.pdf: start=8, end=15, doc_pages=46\n",
      "5210760316.pdf: start=4, end=16, doc_pages=49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-01 01:30:55,154 - WARNING - MD&A start page not found within strict 3-line window; skipping\n",
      "2026-01-01 01:30:55,155 - INFO - Amit_spinning MD&A boundaries (INDEX): start=3, end=28\n",
      "2026-01-01 01:30:55,159 - INFO - Loaded PDF: 5210760318.pdf\n",
      "2026-01-01 01:30:55,320 - WARNING - MD&A start page not found within strict 3-line window; skipping\n",
      "2026-01-01 01:30:55,326 - INFO - Amit_spinning MD&A boundaries (INDEX): start=1, end=21\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5210760317.pdf: start=3, end=28, doc_pages=49\n",
      "5210760318.pdf: start=1, end=21, doc_pages=48\n"
     ]
    }
   ],
   "source": [
    "# Diagnostic: test ALL Amit_spinning PDFs (INDEX-style ToC)\n",
    "from pathlib import Path\n",
    "\n",
    "amit_dir = Path(\"../data/pdfs/Amit_spinning\")\n",
    "amit_pdfs = sorted(amit_dir.glob(\"*.pdf\"))\n",
    "print(\"\\nAmit_spinning PDFs:\", [p.name for p in amit_pdfs])\n",
    "\n",
    "for p in amit_pdfs:\n",
    "    pdf = PDFInterface(p)\n",
    "    pages = pdf.get_pages_text()\n",
    "    s, e = detect_mdna_boundaries(pages_text=pages, toc_start_page=None, company_folder=\"Amit_spinning\")\n",
    "    print(f\"{p.name}: start={s}, end={e}, doc_pages={len(pages)}\")\n",
    "    pdf.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "15174a28",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-01 01:30:55,346 - INFO - Loaded PDF: 5210760316.pdf\n",
      "2026-01-01 01:30:55,554 - INFO - MD&A appears as sub-entry; inheriting parent start page 4 from 'Board's Report including'\n",
      "2026-01-01 01:30:55,559 - INFO - MD&A boundaries (STRICT ToC blocks): start=4, end=16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-01 01:30:55,346 - INFO - Loaded PDF: 5210760316.pdf\n",
      "2026-01-01 01:30:55,554 - INFO - MD&A appears as sub-entry; inheriting parent start page 4 from 'Board's Report including'\n",
      "2026-01-01 01:30:55,559 - INFO - MD&A boundaries (STRICT ToC blocks): start=4, end=16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Amit_spinning 5210760316.pdf ToC MD&A debug ---\n",
      "doc_pages: 49 toc_lines: 216\n",
      "mdna_block: (61, 62)\n",
      "mdna_block_text: Management Discussions & Analysis Report\n",
      "\n",
      "Context around detected MD&A block:\n",
      "  [toc_p3 line57] Notice\n",
      "  [toc_p3 line58] 1\n",
      "  [toc_p3 line59] Board's Report including\n",
      "  [toc_p3 line60] 4\n",
      "> [toc_p3 line61] Management Discussions &\n",
      "> [toc_p3 line62] Analysis Report\n",
      "  [toc_p3 line63] Annexures to Boards' Report\n",
      "  [toc_p3 line64] 8\n",
      "  [toc_p3 line65] Corporate Governance\n",
      "  [toc_p3 line66] 17\n",
      "  [toc_p3 line67] Auditor's Report\n",
      "  [toc_p3 line68] 24\n",
      "  [toc_p3 line69] Balance Sheet\n",
      "\n",
      "resolved_details: {'page': 8, 'page_span_start': 0, 'page_span_end': 1, 'page_line_idx': 64}\n",
      "page_line_text: 8\n",
      "page_line_nums: [('8', 0, 1)]\n",
      "\n",
      "strict_toc result: (4, 16)\n"
     ]
    }
   ],
   "source": [
    "# Diagnostic: inspect ToC raw lines for Amit_spinning 5210760316.pdf (why start=8?)\n",
    "from pathlib import Path\n",
    "\n",
    "p = Path(\"../data/pdfs/Amit_spinning\") / \"5210760316.pdf\"\n",
    "if not p.exists():\n",
    "    print(\"Missing:\", p)\n",
    "else:\n",
    "    pdf = PDFInterface(p)\n",
    "    pages = pdf.get_pages_text()\n",
    "    raw = collect_toc_raw_lines(pages, max_pages=5)\n",
    "\n",
    "    mdna_title_re = re.compile(\n",
    "        r\"\\bmanagement(?:\\s*[’']?s)?\\s+discussion(?:s)?\\s+(?:and|&)\\s+analysis(?:\\s+report)?\\b\",\n",
    "        re.IGNORECASE,\n",
    "    )\n",
    "    mdna_anchor_re = re.compile(r\"\\bmanagement\\b\", re.IGNORECASE)\n",
    "\n",
    "    print(\"\\n--- Amit_spinning 5210760316.pdf ToC MD&A debug ---\")\n",
    "    print(\"doc_pages:\", len(pages), \"toc_lines:\", len(raw))\n",
    "\n",
    "    s_idx, e_idx, block_text = find_title_block_strict(\n",
    "        raw,\n",
    "        mdna_title_re,\n",
    "        max_join_lines=3,\n",
    "        anchor_re=mdna_anchor_re,\n",
    "    )\n",
    "\n",
    "    print(\"mdna_block:\", (s_idx, e_idx))\n",
    "    print(\"mdna_block_text:\", block_text)\n",
    "\n",
    "    if s_idx is not None:\n",
    "        lo = max(0, s_idx - 4)\n",
    "        up = min(len(raw), e_idx + 8)\n",
    "        print(\"\\nContext around detected MD&A block:\")\n",
    "        for j in range(lo, up):\n",
    "            it = raw[j]\n",
    "            prefix = \">\" if s_idx <= j <= e_idx else \" \"\n",
    "            print(f\"{prefix} [toc_p{it['toc_page']} line{it['line_index']}] {it['line_text']}\")\n",
    "\n",
    "        details = resolve_page_number_for_title_block_strict_with_details(\n",
    "            raw,\n",
    "            title_start_idx=s_idx,\n",
    "            title_end_idx=e_idx,\n",
    "            title_re=mdna_title_re,\n",
    "            max_page=len(pages),\n",
    "            lookahead_lines=3,\n",
    "        )\n",
    "        print(\"\\nresolved_details:\", details)\n",
    "        if details:\n",
    "            line = raw[details[\"page_line_idx\"]].get(\"line_text\") or \"\"\n",
    "            nums = [(mm.group(0), mm.start(), mm.end()) for mm in re.finditer(r\"\\b\\d{1,3}\\b\", line)]\n",
    "            print(\"page_line_text:\", line)\n",
    "            print(\"page_line_nums:\", nums)\n",
    "\n",
    "    # Show final strict detector output\n",
    "    s1, e1 = _detect_mdna_boundaries_strict_toc(raw, max_page=len(pages))\n",
    "    print(\"\\nstrict_toc result:\", (s1, e1))\n",
    "\n",
    "    pdf.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "962d6d98",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-01 01:30:55,586 - INFO - Loaded PDF: 5210760317.pdf\n",
      "2026-01-01 01:30:55,798 - INFO - Loaded PDF: 5210760318.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-01 01:30:55,586 - INFO - Loaded PDF: 5210760317.pdf\n",
      "2026-01-01 01:30:55,798 - INFO - Loaded PDF: 5210760318.pdf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 5210760317.pdf ---\n",
      "doc_pages: 49 index_line: 49\n",
      "[toc_p3 line49] INDEX\n",
      "[toc_p3 line50] Page No.\n",
      "[toc_p3 line51] Notice\n",
      "[toc_p3 line52] Board’s Report Including\n",
      "[toc_p3 line53] Management Discussions &\n",
      "[toc_p3 line54] Analysis Report\n",
      "[toc_p3 line55] Annexures to Boards’ Report\n",
      "[toc_p3 line56] Corporate Governance\n",
      "[toc_p3 line57] Auditor’s Report\n",
      "[toc_p3 line58] Balance Sheet\n",
      "[toc_p3 line59] Statement of Profit & Loss\n",
      "[toc_p3 line60] Cash Flow Statement\n",
      "[toc_p3 line61] Notes\n",
      "[toc_p3 line62] 25th AGM\n",
      "[toc_p3 line63] •\n",
      "[toc_p3 line64] Date\n",
      "[toc_p3 line65] :\n",
      "[toc_p3 line66] September 25, 2017 Time 11:30 A.M.\n",
      "[toc_p3 line67] Venue\n",
      "[toc_p3 line68] :\n",
      "[toc_p3 line69] Bipin Chandra Pal Memorial Bhavan, A-81, Chittaranjan Park, New Delhi - 110 019\n",
      "[toc_p3 line70] •\n",
      "[toc_p3 line71] Book Closure :\n",
      "[toc_p3 line72] From Thursday September 21, 2017 to Monday, September 25, 2017 (both days inclusive).\n",
      "[toc_p3 line73] Company’s shares are listed on BSE Ltd. and National Stock Exchange of India Ltd.\n",
      "[toc_p3 line74] 1\n",
      "[toc_p3 line75] 3\n",
      "[toc_p3 line76] 8\n",
      "[toc_p3 line77] 15\n",
      "[toc_p3 line78] 23\n",
      "[toc_p3 line79] 29\n",
      "[toc_p3 line80] 30\n",
      "[toc_p3 line81] 31\n",
      "[toc_p3 line82] 32\n",
      "[toc_p4 line83] ANNUAL REPORT 2016 - 2017\n",
      "[toc_p4 line84] 1\n",
      "[toc_p4 line85] N O T I C E\n",
      "[toc_p4 line86] NOTICE is hereby given that the 25th Annual General Meeting of the Members of Amit Spinning Industries Limited will\n",
      "[toc_p4 line87] be held on Monday the 25th day of September, 2017 at 11.30 A.M at  Bipin Chandra Pal Memorial Bhavan, A-81,\n",
      "[toc_p4 line88] Chittaranjan Park, New Delhi 110019 to transact the following business:\n",
      "\n",
      "--- 5210760318.pdf ---\n",
      "doc_pages: 48 index_line: 100\n",
      "[toc_p3 line100] INDEX\n",
      "[toc_p3 line101] Page No.\n",
      "[toc_p3 line102] Board’s Report Including\n",
      "[toc_p3 line103] Management Discussions &\n",
      "[toc_p3 line104] Analysis Report\n",
      "[toc_p3 line105] Annexures to Boards’ Report\n",
      "[toc_p3 line106] Corporate Governance\n",
      "[toc_p3 line107] Auditor’s Report\n",
      "[toc_p3 line108] Balance Sheet\n",
      "[toc_p3 line109] Statement of Profit & Loss\n",
      "[toc_p3 line110] Cash Flow Statement\n",
      "[toc_p3 line111] Notes\n",
      "[toc_p3 line112] 26th AGM\n",
      "[toc_p3 line113] •\n",
      "[toc_p3 line114] Date\n",
      "[toc_p3 line115] :\n",
      "[toc_p3 line116] September 27, 2018 Time 11:30 A.M.\n",
      "[toc_p3 line117] Venue\n",
      "[toc_p3 line118] :\n",
      "[toc_p3 line119] Bipin Chandra Pal Memorial Bhavan, A-81, Chittaranjan Park, New Delhi - 110 019\n",
      "[toc_p3 line120] •\n",
      "[toc_p3 line121] Book Closure :\n",
      "[toc_p3 line122] Saturday, the 22nd September, 2018 to Thursday, the 27th September, 2018 (both days inclusive)\n",
      "[toc_p3 line123] Company’s shares are listed on BSE Ltd. and National Stock Exchange of India Ltd.\n",
      "[toc_p3 line124] 1\n",
      "[toc_p3 line125] 6\n",
      "[toc_p3 line126] 9\n",
      "[toc_p3 line127] 16\n",
      "[toc_p3 line128] 22\n",
      "[toc_p3 line129] 23\n",
      "[toc_p3 line130] 24\n",
      "[toc_p3 line131] 25\n",
      "[toc_p4 line132] ANNUAL REPORT 2017 - 2018\n",
      "[toc_p4 line133] 1\n",
      "[toc_p4 line134] BOARD'S REPORT\n",
      "[toc_p4 line135] Dear Members,\n",
      "[toc_p4 line136] Your Directors have great pleasure in presenting the 26th Annual Report together with Audited Statements of Accounts of\n",
      "[toc_p4 line137] the Company for the year ended March 31, 2018.\n",
      "[toc_p4 line138] FINANCIAL RESULTS:\n",
      "[toc_p4 line139] The summarized financial results for the year ended March 31, 2018 as compared to the previous year are as follows:\n"
     ]
    }
   ],
   "source": [
    "# Diagnostic: show INDEX raw lines for Amit_spinning PDFs 0317/0318\n",
    "from pathlib import Path\n",
    "\n",
    "for name in [\"5210760317.pdf\", \"5210760318.pdf\"]:\n",
    "    p = Path(\"../data/pdfs/Amit_spinning\") / name\n",
    "    pdf = PDFInterface(p)\n",
    "    pages = pdf.get_pages_text()\n",
    "    raw = collect_toc_raw_lines(pages, max_pages=5)\n",
    "\n",
    "    idx_pos = None\n",
    "    for i, it in enumerate(raw):\n",
    "        if \"INDEX\" in (it.get(\"line_text\") or \"\").upper():\n",
    "            idx_pos = i\n",
    "            break\n",
    "\n",
    "    print(\"\\n---\", name, \"---\")\n",
    "    print(\"doc_pages:\", len(pages), \"index_line:\", idx_pos)\n",
    "    if idx_pos is None:\n",
    "        pdf.close()\n",
    "        continue\n",
    "\n",
    "    for it in raw[idx_pos : idx_pos + 40]:\n",
    "        print(f\"[toc_p{it['toc_page']} line{it['line_index']}] {it['line_text']}\")\n",
    "\n",
    "    pdf.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "802dd04d",
   "metadata": {},
   "source": [
    "### Sanity check  after cell 4: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "38ebeec6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-01 01:30:55,960 - INFO - Loaded PDF: 5267070319.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-01 01:30:55,960 - INFO - Loaded PDF: 5267070319.pdf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: c:\\Users\\LOQ\\Desktop\\SPJIMR\\mdna_extraction_project\\notebooks\n",
      "PDF_ROOT: ..\\data\\pdfs\n",
      "PDF_ROOT exists: True\n",
      "PDF_ROOT resolved: C:\\Users\\LOQ\\Desktop\\SPJIMR\\mdna_extraction_project\\data\\pdfs\n",
      "Total PDFs found: 14\n",
      "\n",
      "Sample PDFs selected for testing:\n",
      "- Alcheimist: 5267070319.pdf\n",
      "- ALok: 5210700315.pdf\n",
      "- Amit_spinning: 5210760315.pdf\n",
      "- Amtek: 5200770316.pdf\n",
      "\n",
      "--- Running Sanity Checks ---\n",
      "\n",
      "Testing company: Alcheimist\n",
      "PDF: 5267070319.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-01 01:30:55,960 - INFO - Loaded PDF: 5267070319.pdf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: c:\\Users\\LOQ\\Desktop\\SPJIMR\\mdna_extraction_project\\notebooks\n",
      "PDF_ROOT: ..\\data\\pdfs\n",
      "PDF_ROOT exists: True\n",
      "PDF_ROOT resolved: C:\\Users\\LOQ\\Desktop\\SPJIMR\\mdna_extraction_project\\data\\pdfs\n",
      "Total PDFs found: 14\n",
      "\n",
      "Sample PDFs selected for testing:\n",
      "- Alcheimist: 5267070319.pdf\n",
      "- ALok: 5210700315.pdf\n",
      "- Amit_spinning: 5210760315.pdf\n",
      "- Amtek: 5200770316.pdf\n",
      "\n",
      "--- Running Sanity Checks ---\n",
      "\n",
      "Testing company: Alcheimist\n",
      "PDF: 5267070319.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-01 01:30:56,488 - INFO - Extracted company name: ALCHEMIST LTD\n",
      "2026-01-01 01:30:56,489 - INFO - Extracted financial year: 2018-19\n",
      "2026-01-01 01:30:56,496 - INFO - Loaded PDF: 5210700315.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-01 01:30:55,960 - INFO - Loaded PDF: 5267070319.pdf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: c:\\Users\\LOQ\\Desktop\\SPJIMR\\mdna_extraction_project\\notebooks\n",
      "PDF_ROOT: ..\\data\\pdfs\n",
      "PDF_ROOT exists: True\n",
      "PDF_ROOT resolved: C:\\Users\\LOQ\\Desktop\\SPJIMR\\mdna_extraction_project\\data\\pdfs\n",
      "Total PDFs found: 14\n",
      "\n",
      "Sample PDFs selected for testing:\n",
      "- Alcheimist: 5267070319.pdf\n",
      "- ALok: 5210700315.pdf\n",
      "- Amit_spinning: 5210760315.pdf\n",
      "- Amtek: 5200770316.pdf\n",
      "\n",
      "--- Running Sanity Checks ---\n",
      "\n",
      "Testing company: Alcheimist\n",
      "PDF: 5267070319.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-01 01:30:56,488 - INFO - Extracted company name: ALCHEMIST LTD\n",
      "2026-01-01 01:30:56,489 - INFO - Extracted financial year: 2018-19\n",
      "2026-01-01 01:30:56,496 - INFO - Loaded PDF: 5210700315.pdf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pages extracted: 145\n",
      "Extracted Company Name: ALCHEMIST LTD\n",
      "Extracted Financial Year: 2018-19\n",
      "--------------------------------------------------\n",
      "Testing company: ALok\n",
      "PDF: 5210700315.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-01 01:30:55,960 - INFO - Loaded PDF: 5267070319.pdf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: c:\\Users\\LOQ\\Desktop\\SPJIMR\\mdna_extraction_project\\notebooks\n",
      "PDF_ROOT: ..\\data\\pdfs\n",
      "PDF_ROOT exists: True\n",
      "PDF_ROOT resolved: C:\\Users\\LOQ\\Desktop\\SPJIMR\\mdna_extraction_project\\data\\pdfs\n",
      "Total PDFs found: 14\n",
      "\n",
      "Sample PDFs selected for testing:\n",
      "- Alcheimist: 5267070319.pdf\n",
      "- ALok: 5210700315.pdf\n",
      "- Amit_spinning: 5210760315.pdf\n",
      "- Amtek: 5200770316.pdf\n",
      "\n",
      "--- Running Sanity Checks ---\n",
      "\n",
      "Testing company: Alcheimist\n",
      "PDF: 5267070319.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-01 01:30:56,488 - INFO - Extracted company name: ALCHEMIST LTD\n",
      "2026-01-01 01:30:56,489 - INFO - Extracted financial year: 2018-19\n",
      "2026-01-01 01:30:56,496 - INFO - Loaded PDF: 5210700315.pdf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pages extracted: 145\n",
      "Extracted Company Name: ALCHEMIST LTD\n",
      "Extracted Financial Year: 2018-19\n",
      "--------------------------------------------------\n",
      "Testing company: ALok\n",
      "PDF: 5210700315.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-01 01:30:57,533 - WARNING - Company name not found in header region; using folder name: ALok\n",
      "2026-01-01 01:30:57,535 - INFO - Financial year not found in first 5 pages\n",
      "2026-01-01 01:30:57,538 - INFO - Loaded PDF: 5210760315.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-01 01:30:55,960 - INFO - Loaded PDF: 5267070319.pdf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: c:\\Users\\LOQ\\Desktop\\SPJIMR\\mdna_extraction_project\\notebooks\n",
      "PDF_ROOT: ..\\data\\pdfs\n",
      "PDF_ROOT exists: True\n",
      "PDF_ROOT resolved: C:\\Users\\LOQ\\Desktop\\SPJIMR\\mdna_extraction_project\\data\\pdfs\n",
      "Total PDFs found: 14\n",
      "\n",
      "Sample PDFs selected for testing:\n",
      "- Alcheimist: 5267070319.pdf\n",
      "- ALok: 5210700315.pdf\n",
      "- Amit_spinning: 5210760315.pdf\n",
      "- Amtek: 5200770316.pdf\n",
      "\n",
      "--- Running Sanity Checks ---\n",
      "\n",
      "Testing company: Alcheimist\n",
      "PDF: 5267070319.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-01 01:30:56,488 - INFO - Extracted company name: ALCHEMIST LTD\n",
      "2026-01-01 01:30:56,489 - INFO - Extracted financial year: 2018-19\n",
      "2026-01-01 01:30:56,496 - INFO - Loaded PDF: 5210700315.pdf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pages extracted: 145\n",
      "Extracted Company Name: ALCHEMIST LTD\n",
      "Extracted Financial Year: 2018-19\n",
      "--------------------------------------------------\n",
      "Testing company: ALok\n",
      "PDF: 5210700315.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-01 01:30:57,533 - WARNING - Company name not found in header region; using folder name: ALok\n",
      "2026-01-01 01:30:57,535 - INFO - Financial year not found in first 5 pages\n",
      "2026-01-01 01:30:57,538 - INFO - Loaded PDF: 5210760315.pdf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pages extracted: 208\n",
      "Extracted Company Name: ALOK\n",
      "Extracted Financial Year: None\n",
      "--------------------------------------------------\n",
      "Testing company: Amit_spinning\n",
      "PDF: 5210760315.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-01 01:30:57,829 - INFO - Extracted company name: AMIT SPINNING INDUSTRIES LIMITED\n",
      "2026-01-01 01:30:57,831 - INFO - Extracted financial year: 2014-15\n",
      "2026-01-01 01:30:57,836 - INFO - Loaded PDF: 5200770316.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-01 01:30:55,960 - INFO - Loaded PDF: 5267070319.pdf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: c:\\Users\\LOQ\\Desktop\\SPJIMR\\mdna_extraction_project\\notebooks\n",
      "PDF_ROOT: ..\\data\\pdfs\n",
      "PDF_ROOT exists: True\n",
      "PDF_ROOT resolved: C:\\Users\\LOQ\\Desktop\\SPJIMR\\mdna_extraction_project\\data\\pdfs\n",
      "Total PDFs found: 14\n",
      "\n",
      "Sample PDFs selected for testing:\n",
      "- Alcheimist: 5267070319.pdf\n",
      "- ALok: 5210700315.pdf\n",
      "- Amit_spinning: 5210760315.pdf\n",
      "- Amtek: 5200770316.pdf\n",
      "\n",
      "--- Running Sanity Checks ---\n",
      "\n",
      "Testing company: Alcheimist\n",
      "PDF: 5267070319.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-01 01:30:56,488 - INFO - Extracted company name: ALCHEMIST LTD\n",
      "2026-01-01 01:30:56,489 - INFO - Extracted financial year: 2018-19\n",
      "2026-01-01 01:30:56,496 - INFO - Loaded PDF: 5210700315.pdf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pages extracted: 145\n",
      "Extracted Company Name: ALCHEMIST LTD\n",
      "Extracted Financial Year: 2018-19\n",
      "--------------------------------------------------\n",
      "Testing company: ALok\n",
      "PDF: 5210700315.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-01 01:30:57,533 - WARNING - Company name not found in header region; using folder name: ALok\n",
      "2026-01-01 01:30:57,535 - INFO - Financial year not found in first 5 pages\n",
      "2026-01-01 01:30:57,538 - INFO - Loaded PDF: 5210760315.pdf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pages extracted: 208\n",
      "Extracted Company Name: ALOK\n",
      "Extracted Financial Year: None\n",
      "--------------------------------------------------\n",
      "Testing company: Amit_spinning\n",
      "PDF: 5210760315.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-01 01:30:57,829 - INFO - Extracted company name: AMIT SPINNING INDUSTRIES LIMITED\n",
      "2026-01-01 01:30:57,831 - INFO - Extracted financial year: 2014-15\n",
      "2026-01-01 01:30:57,836 - INFO - Loaded PDF: 5200770316.pdf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pages extracted: 46\n",
      "Extracted Company Name: AMIT SPINNING INDUSTRIES LIMITED\n",
      "Extracted Financial Year: 2014-15\n",
      "--------------------------------------------------\n",
      "Testing company: Amtek\n",
      "PDF: 5200770316.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-01 01:30:55,960 - INFO - Loaded PDF: 5267070319.pdf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: c:\\Users\\LOQ\\Desktop\\SPJIMR\\mdna_extraction_project\\notebooks\n",
      "PDF_ROOT: ..\\data\\pdfs\n",
      "PDF_ROOT exists: True\n",
      "PDF_ROOT resolved: C:\\Users\\LOQ\\Desktop\\SPJIMR\\mdna_extraction_project\\data\\pdfs\n",
      "Total PDFs found: 14\n",
      "\n",
      "Sample PDFs selected for testing:\n",
      "- Alcheimist: 5267070319.pdf\n",
      "- ALok: 5210700315.pdf\n",
      "- Amit_spinning: 5210760315.pdf\n",
      "- Amtek: 5200770316.pdf\n",
      "\n",
      "--- Running Sanity Checks ---\n",
      "\n",
      "Testing company: Alcheimist\n",
      "PDF: 5267070319.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-01 01:30:56,488 - INFO - Extracted company name: ALCHEMIST LTD\n",
      "2026-01-01 01:30:56,489 - INFO - Extracted financial year: 2018-19\n",
      "2026-01-01 01:30:56,496 - INFO - Loaded PDF: 5210700315.pdf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pages extracted: 145\n",
      "Extracted Company Name: ALCHEMIST LTD\n",
      "Extracted Financial Year: 2018-19\n",
      "--------------------------------------------------\n",
      "Testing company: ALok\n",
      "PDF: 5210700315.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-01 01:30:57,533 - WARNING - Company name not found in header region; using folder name: ALok\n",
      "2026-01-01 01:30:57,535 - INFO - Financial year not found in first 5 pages\n",
      "2026-01-01 01:30:57,538 - INFO - Loaded PDF: 5210760315.pdf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pages extracted: 208\n",
      "Extracted Company Name: ALOK\n",
      "Extracted Financial Year: None\n",
      "--------------------------------------------------\n",
      "Testing company: Amit_spinning\n",
      "PDF: 5210760315.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-01 01:30:57,829 - INFO - Extracted company name: AMIT SPINNING INDUSTRIES LIMITED\n",
      "2026-01-01 01:30:57,831 - INFO - Extracted financial year: 2014-15\n",
      "2026-01-01 01:30:57,836 - INFO - Loaded PDF: 5200770316.pdf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pages extracted: 46\n",
      "Extracted Company Name: AMIT SPINNING INDUSTRIES LIMITED\n",
      "Extracted Financial Year: 2014-15\n",
      "--------------------------------------------------\n",
      "Testing company: Amtek\n",
      "PDF: 5200770316.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-01 01:30:58,351 - INFO - Extracted company name: AMTEK AUTO LIMITED\n",
      "2026-01-01 01:30:58,352 - INFO - Extracted financial year: 2015-16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-01 01:30:55,960 - INFO - Loaded PDF: 5267070319.pdf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: c:\\Users\\LOQ\\Desktop\\SPJIMR\\mdna_extraction_project\\notebooks\n",
      "PDF_ROOT: ..\\data\\pdfs\n",
      "PDF_ROOT exists: True\n",
      "PDF_ROOT resolved: C:\\Users\\LOQ\\Desktop\\SPJIMR\\mdna_extraction_project\\data\\pdfs\n",
      "Total PDFs found: 14\n",
      "\n",
      "Sample PDFs selected for testing:\n",
      "- Alcheimist: 5267070319.pdf\n",
      "- ALok: 5210700315.pdf\n",
      "- Amit_spinning: 5210760315.pdf\n",
      "- Amtek: 5200770316.pdf\n",
      "\n",
      "--- Running Sanity Checks ---\n",
      "\n",
      "Testing company: Alcheimist\n",
      "PDF: 5267070319.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-01 01:30:56,488 - INFO - Extracted company name: ALCHEMIST LTD\n",
      "2026-01-01 01:30:56,489 - INFO - Extracted financial year: 2018-19\n",
      "2026-01-01 01:30:56,496 - INFO - Loaded PDF: 5210700315.pdf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pages extracted: 145\n",
      "Extracted Company Name: ALCHEMIST LTD\n",
      "Extracted Financial Year: 2018-19\n",
      "--------------------------------------------------\n",
      "Testing company: ALok\n",
      "PDF: 5210700315.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-01 01:30:57,533 - WARNING - Company name not found in header region; using folder name: ALok\n",
      "2026-01-01 01:30:57,535 - INFO - Financial year not found in first 5 pages\n",
      "2026-01-01 01:30:57,538 - INFO - Loaded PDF: 5210760315.pdf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pages extracted: 208\n",
      "Extracted Company Name: ALOK\n",
      "Extracted Financial Year: None\n",
      "--------------------------------------------------\n",
      "Testing company: Amit_spinning\n",
      "PDF: 5210760315.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-01 01:30:57,829 - INFO - Extracted company name: AMIT SPINNING INDUSTRIES LIMITED\n",
      "2026-01-01 01:30:57,831 - INFO - Extracted financial year: 2014-15\n",
      "2026-01-01 01:30:57,836 - INFO - Loaded PDF: 5200770316.pdf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pages extracted: 46\n",
      "Extracted Company Name: AMIT SPINNING INDUSTRIES LIMITED\n",
      "Extracted Financial Year: 2014-15\n",
      "--------------------------------------------------\n",
      "Testing company: Amtek\n",
      "PDF: 5200770316.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-01 01:30:58,351 - INFO - Extracted company name: AMTEK AUTO LIMITED\n",
      "2026-01-01 01:30:58,352 - INFO - Extracted financial year: 2015-16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pages extracted: 145\n",
      "Extracted Company Name: AMTEK AUTO LIMITED\n",
      "Extracted Financial Year: 2015-16\n",
      "--------------------------------------------------\n",
      "\n",
      "Sanity check completed successfully.\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "# ---- CONFIG ----\n",
    "PDF_ROOT = Path(\"../data/pdfs\")\n",
    "\n",
    "print(f\"Current working directory: {os.getcwd()}\")\n",
    "print(f\"PDF_ROOT: {PDF_ROOT}\")\n",
    "print(f\"PDF_ROOT exists: {PDF_ROOT.exists()}\")\n",
    "print(f\"PDF_ROOT resolved: {PDF_ROOT.resolve()}\")\n",
    "\n",
    "# ---- STEP 1: Discover PDFs ----\n",
    "pdf_files = list(PDF_ROOT.rglob(\"*.pdf\"))\n",
    "\n",
    "print(f\"Total PDFs found: {len(pdf_files)}\")\n",
    "\n",
    "if not pdf_files:\n",
    "    print(\"No PDFs found in ../data/pdfs directory. Please add PDF files to test the pipeline.\")\n",
    "    print(\"Skipping sanity checks.\")\n",
    "else:\n",
    "    # Pick one PDF from each company (if available)\n",
    "    sample_pdfs = {}\n",
    "    for pdf in pdf_files:\n",
    "        company = pdf.parent.name\n",
    "        if company not in sample_pdfs:\n",
    "            sample_pdfs[company] = pdf\n",
    "\n",
    "    print(\"\\nSample PDFs selected for testing:\")\n",
    "    for company, pdf in sample_pdfs.items():\n",
    "        print(f\"- {company}: {pdf.name}\")\n",
    "\n",
    "    # ---- STEP 2: Test PDFInterface + Metadata Extraction ----\n",
    "    print(\"\\n--- Running Sanity Checks ---\\n\")\n",
    "\n",
    "    for company, pdf_path in sample_pdfs.items():\n",
    "        print(f\"Testing company: {company}\")\n",
    "        print(f\"PDF: {pdf_path.name}\")\n",
    "\n",
    "        pdf = PDFInterface(pdf_path)\n",
    "        pages = pdf.get_pages_text()\n",
    "\n",
    "        print(\"Pages extracted:\", len(pages))\n",
    "        assert len(pages) > 0, \"No pages extracted!\"\n",
    "\n",
    "        # Metadata extraction\n",
    "        extracted_company = extract_company_name(pages, company_folder=company)\n",
    "        extracted_year = extract_financial_year(pages)\n",
    "\n",
    "        print(\"Extracted Company Name:\", extracted_company)\n",
    "        print(\"Extracted Financial Year:\", extracted_year)\n",
    "\n",
    "        print(\"-\" * 50)\n",
    "\n",
    "    print(\"\\nSanity check completed successfully.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
