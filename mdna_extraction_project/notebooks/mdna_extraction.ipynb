{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e6cae672",
   "metadata": {},
   "source": [
    "## Automated Extraction of Management Discussion & Analysis (MD&A) Sections from Indian Annual Report PDFs\n",
    "\n",
    "### Introduction\n",
    "\n",
    "The Management Discussion & Analysis (MD&A) section is a critical component of corporate annual reports, providing qualitative insights into a company's financial performance, operational challenges, risk factors, and future outlook. As mandated by regulatory frameworks such as the Companies Act, 2013 in India, MD&A serves as a strategic tool for stakeholders to assess management perspectives beyond quantitative financial statements, enabling informed decision-making in investment, risk assessment, and corporate governance.\n",
    "\n",
    "Extracting MD&A content from PDF-based annual reports presents significant technical challenges. Annual reports are inherently unstructured documents, featuring complex layouts with embedded tables, images, and multi-column text that complicate text extraction. Layout variability across companies due to differing design choices, font styles, and page structures further hinders automated processing. Additionally, MD&A sections are often integrated with other report components, such as Directors' Reports or financial statements, making precise boundary identification difficult.\n",
    "\n",
    "Indian annual reports exhibit particular structural diversity in MD&A presentation. Some companies provide standalone MD&A sections, while others embed the content within annexures or integrate it directly into the Directors' Report. This variability necessitates robust extraction methods capable of adapting to multiple organizational patterns.\n",
    "\n",
    "This notebook implements a systematic pipeline for MD&A extraction, comprising the following stages:\n",
    "\n",
    "1. **Data Collection**: Identification and organization of PDF annual reports from diverse Indian companies.\n",
    "2. **PDF Parsing**: Extraction of raw text and structural elements using specialized libraries.\n",
    "3. **Text Preprocessing**: Cleaning and normalization of extracted content to handle encoding artifacts and formatting inconsistencies.\n",
    "4. **Section Detection**: Identification of MD&A boundaries through pattern matching and keyword-based analysis.\n",
    "5. **Content Extraction**: Precise isolation of MD&A text while filtering extraneous sections.\n",
    "6. **Validation and Output**: Quality assessment of extracted content and structured output generation for downstream analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b7953f6",
   "metadata": {},
   "source": [
    "### 2. Imports & Configuration Layer : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5d4aee36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz  \n",
    "import pandas as pd\n",
    "import re\n",
    "import logging\n",
    "from tqdm import tqdm\n",
    "import pathlib\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "\n",
    "PROJECT_ROOT = pathlib.Path.cwd()\n",
    "\n",
    "INPUT_PDF_DIR = PROJECT_ROOT / \"../data\" / \"../pdfs\"\n",
    "OUTPUT_DIR = PROJECT_ROOT / \"../output\"\n",
    "\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d7dd9e5",
   "metadata": {},
   "source": [
    "### 3. PDF Interface Layer : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "78fb3497",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PDFInterface:\n",
    "    def __init__(self, pdf_path):\n",
    "        self.pdf_path = pathlib.Path(pdf_path)\n",
    "        self.doc = fitz.open(self.pdf_path)\n",
    "        logging.info(\"Loaded PDF: %s\", self.pdf_path.name)\n",
    "\n",
    "    def get_pages_text(self):\n",
    "        pages = []\n",
    "        for page_index in range(self.doc.page_count):\n",
    "            page = self.doc.load_page(page_index)\n",
    "            pages.append(\n",
    "                {\n",
    "                    \"page_number\": page_index + 1,\n",
    "                    \"text\": page.get_text(),\n",
    "                }\n",
    "            )\n",
    "        return pages\n",
    "\n",
    "    def close(self):\n",
    "        self.doc.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b73f231",
   "metadata": {},
   "source": [
    "###  4. Company Name & Financial Year Extraction: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "69f8dc92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_company_name(pages_text):\n",
    "    \"\"\"\n",
    "    Extract company name from the first 3 pages of PDF text.\n",
    "\n",
    "    Args:\n",
    "        pages_text: List of page dictionaries with 'page_number' and 'text'\n",
    "\n",
    "    Returns:\n",
    "        str: Company name or None if not found\n",
    "    \"\"\"\n",
    "    # Regex pattern for company names ending with LIMITED, Limited, or Ltd.\n",
    "    company_pattern = re.compile(\n",
    "        r'([A-Z][A-Za-z\\s&\\(\\),.-]+?(?:LIMITED|Limited|Ltd\\.?))',\n",
    "        re.MULTILINE,\n",
    "    )\n",
    "\n",
    "    matches = []\n",
    "\n",
    "    # Search only first 3 pages\n",
    "    for page in pages_text[:3]:\n",
    "        text = page['text']\n",
    "        found = company_pattern.findall(text)\n",
    "        matches.extend(found)\n",
    "\n",
    "    if not matches:\n",
    "        logging.info(\"Company name not found in first 3 pages\")\n",
    "        return None\n",
    "\n",
    "    # Return the longest match (most confident)\n",
    "    company_name = max(matches, key=len).strip()\n",
    "    logging.info(\"Extracted company name: %s\", company_name)\n",
    "    return company_name\n",
    "\n",
    "\n",
    "def extract_financial_year(pages_text):\n",
    "    \"\"\"Extract financial year from the first 5 pages of PDF text.\n",
    "\n",
    "    Supported examples:\n",
    "      - \"Annual Report 2019-20\"\n",
    "      - \"31st Annual Report 2019-20\"\n",
    "      - \"Year ended March 31, 2020\"\n",
    "\n",
    "    Returns:\n",
    "        str: Normalized financial year (e.g., '2019-20') or None if not found\n",
    "    \"\"\"\n",
    "\n",
    "    # Patterns for various year formats (search order matters: more specific first)\n",
    "    year_patterns = [\n",
    "        # 31st Annual Report 2019-20 / 31st Annual Report 2019 - 2020\n",
    "        re.compile(\n",
    "            r\"\\b\\d{1,3}(?:st|nd|rd|th)\\s+Annual\\s+Report\\s+(\\d{4})\\s*[-–]\\s*(\\d{2,4})\\b\",\n",
    "            re.IGNORECASE,\n",
    "        ),\n",
    "        # Annual Report 2019-20 / Annual Report 2019 - 2020\n",
    "        re.compile(\n",
    "            r\"\\bAnnual\\s+Report\\s+(\\d{4})\\s*[-–]\\s*(\\d{2,4})\\b\",\n",
    "            re.IGNORECASE,\n",
    "        ),\n",
    "        # Year ended March 31, 2020 (or similar)\n",
    "        re.compile(\n",
    "            r\"\\bYear\\s+ended\\s+\\w+\\s+\\d{1,2},\\s+(\\d{4})\\b\",\n",
    "            re.IGNORECASE,\n",
    "        ),\n",
    "    ]\n",
    "\n",
    "    # Search first 5 pages\n",
    "    for page in pages_text[:5]:\n",
    "        text = page.get('text', '')\n",
    "\n",
    "        for pattern in year_patterns:\n",
    "            match = pattern.search(text)\n",
    "            if not match:\n",
    "                continue\n",
    "\n",
    "            groups = match.groups()\n",
    "\n",
    "            if len(groups) == 1:\n",
    "                # Single year (e.g., Year ended March 31, 2020) -> previous year - last 2 digits\n",
    "                year = groups[0]\n",
    "                prev_year = str(int(year) - 1)\n",
    "                normalized = f\"{prev_year}-{year[-2:]}\"\n",
    "            else:\n",
    "                year1, year2 = groups\n",
    "                if len(year2) == 2:\n",
    "                    normalized = f\"{year1}-{year2}\"\n",
    "                else:\n",
    "                    normalized = f\"{year1}-{year2[-2:]}\"\n",
    "\n",
    "            logging.info(\"Extracted financial year: %s\", normalized)\n",
    "            return normalized\n",
    "\n",
    "    logging.info(\"Financial year not found in first 5 pages\")\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c2e17d2",
   "metadata": {},
   "source": [
    "### 5. Table of Contents (ToC) Analyzer: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "afccf4cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_toc_raw_lines(pages_text, max_pages=5):\n",
    "    \"\"\"Collect STRICT ToC raw lines from ONLY the first `max_pages` pages.\n",
    "\n",
    "    Returns a list preserving original extracted order exactly (per splitlines()).\n",
    "    Each item:\n",
    "      {\n",
    "        \"toc_page\": int,\n",
    "        \"line_index\": int,   # 0-based across non-empty ToC lines\n",
    "        \"line_text\": str\n",
    "      }\n",
    "\n",
    "    Notes:\n",
    "      - This collects ALL non-empty lines (not just those with digits), because\n",
    "        MD&A titles can appear without a page number on the same extracted line,\n",
    "        and titles can be wrapped across multiple extracted lines.\n",
    "      - Downstream logic MUST NOT consult body text; this is ToC-page-only.\n",
    "    \"\"\"\n",
    "\n",
    "    raw_lines = []\n",
    "    line_index = 0\n",
    "\n",
    "    for page in pages_text[:max_pages]:\n",
    "        toc_page_no = page.get(\"page_number\")\n",
    "        text = page.get(\"text\", \"\") or \"\"\n",
    "\n",
    "        for ln in text.splitlines():\n",
    "            s = (ln or \"\").strip()\n",
    "            if not s:\n",
    "                continue\n",
    "\n",
    "            raw_lines.append(\n",
    "                {\n",
    "                    \"toc_page\": toc_page_no,\n",
    "                    \"line_index\": line_index,\n",
    "                    \"line_text\": s,\n",
    "                }\n",
    "            )\n",
    "            line_index += 1\n",
    "\n",
    "    return raw_lines\n",
    "\n",
    "\n",
    "def detect_toc_entries(pages_text, max_pages=5):\n",
    "    \"\"\"STRICT ToC line collection.\n",
    "\n",
    "    Non-negotiable behavior (per spec):\n",
    "      - Scan ONLY the first `max_pages` pages.\n",
    "      - Collect all non-empty lines containing BOTH:\n",
    "          * at least one alphabetic character, AND\n",
    "          * at least one numeric character\n",
    "      - Preserve original line order exactly as extracted.\n",
    "\n",
    "    Returns:\n",
    "      list[dict] with keys: toc_page, line_index, line_text\n",
    "    \"\"\"\n",
    "\n",
    "    raw_lines = collect_toc_raw_lines(pages_text, max_pages=max_pages)\n",
    "\n",
    "    entries = []\n",
    "    for item in raw_lines:\n",
    "        txt = item.get(\"line_text\", \"\")\n",
    "        if re.search(r\"[A-Za-z]\", txt) and re.search(r\"\\d\", txt):\n",
    "            entries.append(item)\n",
    "\n",
    "    logging.info(\"Collected %d strict ToC declaration lines (first %d pages)\", len(entries), max_pages)\n",
    "    return entries\n",
    "\n",
    "\n",
    "_PAGE_INT_RE = re.compile(r\"\\b(\\d{1,4})\\b\")\n",
    "\n",
    "\n",
    "def _first_valid_page_number_in_text(text: str, max_page: int):\n",
    "    for m in _PAGE_INT_RE.finditer(text or \"\"):\n",
    "        try:\n",
    "            n = int(m.group(1))\n",
    "        except ValueError:\n",
    "            continue\n",
    "        if 1 <= n <= max_page:\n",
    "            return n\n",
    "    return None\n",
    "\n",
    "\n",
    "def _first_valid_page_number_after_pos(text: str, start_pos: int, max_page: int):\n",
    "    res = _first_valid_page_number_after_pos_with_span(text, start_pos, max_page)\n",
    "    return res[0] if res else None\n",
    "\n",
    "\n",
    "def _first_valid_page_number_after_pos_with_span(text: str, start_pos: int, max_page: int):\n",
    "    for m in _PAGE_INT_RE.finditer(text or \"\"):\n",
    "        if m.start() < (start_pos or 0):\n",
    "            continue\n",
    "        try:\n",
    "            n = int(m.group(1))\n",
    "        except ValueError:\n",
    "            continue\n",
    "        if 1 <= n <= max_page:\n",
    "            return n, m.start(), m.end()\n",
    "    return None\n",
    "\n",
    "\n",
    "def resolve_page_number_strict(raw_lines, title_line_index: int, max_page: int, lookahead_lines: int = 3):\n",
    "    \"\"\"STRICT page-number association (no fallback logic).\n",
    "\n",
    "    Rules:\n",
    "      - If the title line contains a valid integer page number, use it.\n",
    "      - ELSE look ONLY at the immediately following lines (max next `lookahead_lines`).\n",
    "      - The FIRST valid integer page number encountered is used.\n",
    "      - If none found in this strict window, return None.\n",
    "\n",
    "    Note:\n",
    "      - This is the generic helper; for section titles that may share a line with\n",
    "        other sections (multi-column extraction), prefer\n",
    "        resolve_page_number_for_title_block_strict().\n",
    "    \"\"\"\n",
    "\n",
    "    if title_line_index < 0 or title_line_index >= len(raw_lines):\n",
    "        return None\n",
    "\n",
    "    # If the line contains a page number, use it.\n",
    "    same_line = raw_lines[title_line_index].get(\"line_text\", \"\")\n",
    "    n = _first_valid_page_number_in_text(same_line, max_page)\n",
    "    if n is not None:\n",
    "        return n\n",
    "\n",
    "    # Else look at the next lines only.\n",
    "    for offset in range(1, lookahead_lines + 1):\n",
    "        j = title_line_index + offset\n",
    "        if j >= len(raw_lines):\n",
    "            break\n",
    "\n",
    "        candidate_line = raw_lines[j].get(\"line_text\", \"\")\n",
    "        n = _first_valid_page_number_in_text(candidate_line, max_page)\n",
    "        if n is not None:\n",
    "            return n\n",
    "\n",
    "    return None\n",
    "\n",
    "\n",
    "def find_title_block_strict(\n",
    "    raw_lines,\n",
    "    title_re: re.Pattern,\n",
    "    max_join_lines: int = 3,\n",
    "    anchor_re: re.Pattern | None = None,\n",
    "):\n",
    "    \"\"\"Find a title match treating the ToC as structural blocks.\n",
    "\n",
    "    Deterministic behavior:\n",
    "      - Scans raw_lines in order.\n",
    "      - Only considers a block starting at line i if anchor_re matches line i\n",
    "        (when anchor_re is provided). This prevents accidentally starting a\n",
    "        block on an unrelated neighboring section.\n",
    "      - At each valid start position i, tests the concatenation of\n",
    "        1..max_join_lines lines (joined with a single space) against title_re.\n",
    "      - Returns (start_idx, end_idx, block_text) for the first match.\n",
    "\n",
    "    It does NOT consult body text and does NOT search beyond the ToC pages.\n",
    "    \"\"\"\n",
    "\n",
    "    n = len(raw_lines)\n",
    "    for i in range(n):\n",
    "        start_line = raw_lines[i].get(\"line_text\", \"\")\n",
    "        if anchor_re is not None and not anchor_re.search(start_line or \"\"):\n",
    "            continue\n",
    "\n",
    "        parts = []\n",
    "        for j in range(i, min(n, i + max_join_lines)):\n",
    "            parts.append(raw_lines[j].get(\"line_text\", \"\"))\n",
    "            block_text = \" \".join(p for p in parts if p)\n",
    "            if title_re.search(block_text or \"\"):\n",
    "                return i, j, block_text\n",
    "\n",
    "    return None, None, None\n",
    "\n",
    "\n",
    "def resolve_page_number_for_title_block_strict(\n",
    "    raw_lines,\n",
    "    title_start_idx: int,\n",
    "    title_end_idx: int,\n",
    "    title_re: re.Pattern,\n",
    "    max_page: int,\n",
    "    lookahead_lines: int = 3,\n",
    "):\n",
    "    \"\"\"STRICT page-number association for a title block, robust to multi-column merges.\n",
    "\n",
    "    Deterministic rules:\n",
    "      - If the title appears on a line that also contains multiple page numbers,\n",
    "        choose the FIRST valid integer page number that occurs AFTER the matched\n",
    "        title text on that line.\n",
    "      - Otherwise (no resolvable number on the title-containing line), search\n",
    "        ONLY the next `lookahead_lines` lines after the title block; FIRST valid\n",
    "        integer page number wins.\n",
    "      - If none found, return None.\n",
    "\n",
    "    This is still ToC-only and bounded; no body-text inference.\n",
    "    \"\"\"\n",
    "\n",
    "    details = resolve_page_number_for_title_block_strict_with_details(\n",
    "        raw_lines,\n",
    "        title_start_idx=title_start_idx,\n",
    "        title_end_idx=title_end_idx,\n",
    "        title_re=title_re,\n",
    "        max_page=max_page,\n",
    "        lookahead_lines=lookahead_lines,\n",
    "    )\n",
    "    return details[\"page\"] if details else None\n",
    "\n",
    "\n",
    "def resolve_page_number_for_title_block_strict_with_details(\n",
    "    raw_lines,\n",
    "    title_start_idx: int,\n",
    "    title_end_idx: int,\n",
    "    title_re: re.Pattern,\n",
    "    max_page: int,\n",
    "    lookahead_lines: int = 3,\n",
    "):\n",
    "    \"\"\"Same as resolve_page_number_for_title_block_strict, but returns details.\n",
    "\n",
    "    Returns dict:\n",
    "      {\n",
    "        \"page\": int,\n",
    "        \"page_span_start\": int | None,\n",
    "        \"page_span_end\": int | None,\n",
    "        \"page_line_idx\": int,\n",
    "      }\n",
    "    \"\"\"\n",
    "\n",
    "    if title_start_idx is None or title_end_idx is None:\n",
    "        return None\n",
    "\n",
    "    # 1) Prefer a page number that occurs after the matched title on the same line.\n",
    "    for i in range(title_start_idx, title_end_idx + 1):\n",
    "        line = raw_lines[i].get(\"line_text\", \"\")\n",
    "        m = title_re.search(line or \"\")\n",
    "        if not m:\n",
    "            continue\n",
    "\n",
    "        res = _first_valid_page_number_after_pos_with_span(line, m.end(), max_page)\n",
    "        if res is not None:\n",
    "            n, s, e = res\n",
    "            return {\n",
    "                \"page\": n,\n",
    "                \"page_span_start\": s,\n",
    "                \"page_span_end\": e,\n",
    "                \"page_line_idx\": i,\n",
    "            }\n",
    "\n",
    "    # 2) Otherwise, search next N lines after the title block.\n",
    "    for offset in range(1, lookahead_lines + 1):\n",
    "        j = title_end_idx + offset\n",
    "        if j >= len(raw_lines):\n",
    "            break\n",
    "\n",
    "        line = raw_lines[j].get(\"line_text\", \"\")\n",
    "        res = _first_valid_page_number_after_pos_with_span(line, 0, max_page)\n",
    "        if res is not None:\n",
    "            n, s, e = res\n",
    "            return {\n",
    "                \"page\": n,\n",
    "                \"page_span_start\": s,\n",
    "                \"page_span_end\": e,\n",
    "                \"page_line_idx\": j,\n",
    "            }\n",
    "\n",
    "    return None\n",
    "\n",
    "\n",
    "def find_mdna_start_from_toc(pages_text):\n",
    "    \"\"\"Backward-compatible helper: STRICT MD&A start-page discovery from ToC pages only.\"\"\"\n",
    "\n",
    "    raw_lines = collect_toc_raw_lines(pages_text, max_pages=5)\n",
    "    if not raw_lines:\n",
    "        logging.info(\"No ToC raw lines found in first 5 pages\")\n",
    "        return None\n",
    "\n",
    "    max_page = len(pages_text)\n",
    "\n",
    "    mdna_title_re = re.compile(\n",
    "        r\"\\bmanagement\\s+discussion\\s+(?:and|&)\\s+analysis(?:\\s+report)?\\b\",\n",
    "        re.IGNORECASE,\n",
    "    )\n",
    "\n",
    "    mdna_anchor_re = re.compile(r\"\\bmanagement\\b\", re.IGNORECASE)\n",
    "\n",
    "    start_idx, end_idx, _ = find_title_block_strict(\n",
    "        raw_lines,\n",
    "        mdna_title_re,\n",
    "        max_join_lines=3,\n",
    "        anchor_re=mdna_anchor_re,\n",
    "    )\n",
    "\n",
    "    if start_idx is None:\n",
    "        logging.info(\"MD&A title block not found in ToC raw lines\")\n",
    "        return None\n",
    "\n",
    "    start_page = resolve_page_number_for_title_block_strict(\n",
    "        raw_lines,\n",
    "        title_start_idx=start_idx,\n",
    "        title_end_idx=end_idx,\n",
    "        title_re=mdna_title_re,\n",
    "        max_page=max_page,\n",
    "        lookahead_lines=3,\n",
    "    )\n",
    "\n",
    "    if start_page is None:\n",
    "        logging.info(\"MD&A page number not found within strict 3-line window\")\n",
    "        return None\n",
    "\n",
    "    logging.info(\n",
    "        \"MD&A ToC entry found (strict block): '%s' -> page %s\",\n",
    "        \" \".join(raw_lines[i].get(\"line_text\", \"\") for i in range(start_idx, end_idx + 1)),\n",
    "        start_page,\n",
    "    )\n",
    "    return start_page\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "599ddf8e",
   "metadata": {},
   "source": [
    "### 6. MD&A Boundary Detection : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "a93c761f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import logging\n",
    "\n",
    "\n",
    "def detect_mdna_boundaries(pages_text, toc_start_page=None):\n",
    "    \"\"\"Detect MD&A boundaries using STRICT Table of Contents (ToC) rules ONLY.\n",
    "\n",
    "    Required behavior:\n",
    "      - ToC is the only source of truth (first 5 pages only).\n",
    "      - Treat ToC as STRUCTURAL BLOCKS: titles may be wrapped across lines.\n",
    "      - When MD&A title is detected, search ONLY next 3 extracted lines for page number.\n",
    "      - Deterministic alignment, no body-text inference; if not resolvable, SKIP.\n",
    "\n",
    "    End page:\n",
    "      - end_page = (next ToC section page - 1)\n",
    "      - If next section page is missing, end_page = last page of document.\n",
    "\n",
    "    Exclusions preserved:\n",
    "      - Directors’ Report\n",
    "      - Secretarial Audit (MR-3)\n",
    "      - Corporate Information\n",
    "      - Auditors’ Report\n",
    "      - Corporate Governance\n",
    "\n",
    "    Returns:\n",
    "      (start_page, end_page) or (None, None)\n",
    "    \"\"\"\n",
    "\n",
    "    max_page = len(pages_text)\n",
    "    if max_page <= 0:\n",
    "        logging.warning(\"Empty document; cannot detect MD&A boundaries\")\n",
    "        return None, None\n",
    "\n",
    "    raw_lines = collect_toc_raw_lines(pages_text, max_pages=5)\n",
    "    if not raw_lines:\n",
    "        logging.warning(\"No ToC raw lines detected in the first 5 pages\")\n",
    "        return None, None\n",
    "\n",
    "    mdna_title_re = re.compile(\n",
    "        r\"\\bmanagement(?:\\s*[’']?s)?\\s+discussion(?:s)?\\s+(?:and|&)\\s+analysis(?:\\s+report)?\\b\",\n",
    "        re.IGNORECASE,\n",
    "    )\n",
    "    mdna_anchor_re = re.compile(r\"\\bmanagement\\b\", re.IGNORECASE)\n",
    "\n",
    "    # Exclusion regexes (kept strict)\n",
    "    directors_re = re.compile(r\"\\bdirectors\\s*[’']?\\s*report\\b\", re.IGNORECASE)\n",
    "    secretarial_re = re.compile(r\"\\bsecretarial\\s+audit\\b\", re.IGNORECASE)\n",
    "    mr3_re = re.compile(r\"\\bform\\s+mr\\s*[-–]?\\s*3\\b|\\bmr\\s*[-–]?\\s*3\\b\", re.IGNORECASE)\n",
    "    corp_info_re = re.compile(r\"\\bcorporate\\s+information\\b\", re.IGNORECASE)\n",
    "    auditors_re = re.compile(r\"\\bauditors?\\s*[’']?\\s*report\\b|\\bindependent\\s+auditor\\b\", re.IGNORECASE)\n",
    "    corp_gov_re = re.compile(r\"\\bcorporate\\s+governance\\b\", re.IGNORECASE)\n",
    "\n",
    "    disallowed = [\n",
    "        (directors_re, re.compile(r\"\\bdirectors\\b\", re.IGNORECASE)),\n",
    "        (secretarial_re, re.compile(r\"\\bsecretarial\\b\", re.IGNORECASE)),\n",
    "        (mr3_re, re.compile(r\"\\bmr\\b|\\bform\\b\", re.IGNORECASE)),\n",
    "        (corp_info_re, re.compile(r\"\\bcorporate\\b\", re.IGNORECASE)),\n",
    "        (auditors_re, re.compile(r\"\\bauditor\\b|\\bindependent\\b\", re.IGNORECASE)),\n",
    "        (corp_gov_re, re.compile(r\"\\bgovernance\\b|\\bcorporate\\b\", re.IGNORECASE)),\n",
    "    ]\n",
    "\n",
    "    # --- 1) Find MD&A title as a structural block (up to 3 joined lines) ---\n",
    "    mdna_start_idx, mdna_end_idx, mdna_block_text = find_title_block_strict(\n",
    "        raw_lines,\n",
    "        mdna_title_re,\n",
    "        max_join_lines=3,\n",
    "        anchor_re=mdna_anchor_re,\n",
    "    )\n",
    "\n",
    "    # --- 1a) Handle special case: MD&A is part of Directors' Report block ---\n",
    "    if mdna_start_idx is None:\n",
    "        logging.info(\"MD&A not found as standalone title; checking inside Directors' Report block\")\n",
    "        directors_anchor_re = re.compile(r\"\\bdirectors\\b\", re.IGNORECASE)\n",
    "        dir_start_idx, dir_end_idx, dir_block_text = find_title_block_strict(\n",
    "            raw_lines,\n",
    "            directors_re,\n",
    "            max_join_lines=3,\n",
    "            anchor_re=directors_anchor_re,\n",
    "        )\n",
    "\n",
    "        if dir_block_text and mdna_title_re.search(dir_block_text):\n",
    "            logging.info(\"MD&A title found inside Directors' Report block; using its boundaries\")\n",
    "            mdna_start_idx = dir_start_idx\n",
    "            mdna_end_idx = dir_end_idx\n",
    "            mdna_block_text = dir_block_text\n",
    "        else:\n",
    "            logging.warning(\"MD&A title block not found in ToC raw lines; skipping\")\n",
    "            return None, None\n",
    "\n",
    "    # --- 2) STRICT page number association: page number after MD&A match, else next 3 lines ---\n",
    "    mdna_page_details = resolve_page_number_for_title_block_strict_with_details(\n",
    "        raw_lines,\n",
    "        title_start_idx=mdna_start_idx,\n",
    "        title_end_idx=mdna_end_idx,\n",
    "        title_re=mdna_title_re,\n",
    "        max_page=max_page,\n",
    "        lookahead_lines=3,\n",
    "    )\n",
    "\n",
    "    if not mdna_page_details:\n",
    "        logging.warning(\"MD&A start page not found within strict 3-line window; skipping\")\n",
    "        return None, None\n",
    "\n",
    "    start_page = mdna_page_details[\"page\"]\n",
    "\n",
    "    # --- 3) Determine next section page (including same-line multi-column cases) ---\n",
    "    def _next_page_number_in_same_line(line_text: str, after_pos: int, current_start_page: int):\n",
    "        # Prefer numbers that occur after the current entry's page span (when ordering is preserved).\n",
    "        res = _first_valid_page_number_after_pos_with_span(line_text, after_pos, max_page)\n",
    "        if res:\n",
    "            n, _, _ = res\n",
    "            if n > current_start_page:\n",
    "                return n\n",
    "\n",
    "        # Fallback for multi-column merges where extraction order may be scrambled within the same line:\n",
    "        # choose the smallest page number on the line that is greater than the current start page.\n",
    "        candidates = []\n",
    "        for m in _PAGE_INT_RE.finditer(line_text or \"\"):\n",
    "            try:\n",
    "                n = int(m.group(1))\n",
    "            except ValueError:\n",
    "                continue\n",
    "            if current_start_page < n <= max_page:\n",
    "                candidates.append(n)\n",
    "\n",
    "        return min(candidates) if candidates else None\n",
    "\n",
    "    def _next_section_start_page_after_line(after_line_idx: int, current_start_page: int):\n",
    "        for j in range(after_line_idx + 1, len(raw_lines)):\n",
    "            txt = raw_lines[j].get(\"line_text\", \"\")\n",
    "            if not re.search(r\"[A-Za-z]\", txt or \"\"):\n",
    "                continue\n",
    "\n",
    "            # Avoid treating the same MD&A title again\n",
    "            if mdna_title_re.search(txt or \"\"):\n",
    "                continue\n",
    "\n",
    "            candidate = resolve_page_number_strict(raw_lines, j, max_page=max_page, lookahead_lines=3)\n",
    "            if candidate is None:\n",
    "                continue\n",
    "\n",
    "            if candidate > current_start_page:\n",
    "                return candidate\n",
    "\n",
    "        return None\n",
    "\n",
    "    same_line_idx = mdna_page_details[\"page_line_idx\"]\n",
    "    same_line_text = raw_lines[same_line_idx].get(\"line_text\", \"\")\n",
    "    same_line_next_page = _next_page_number_in_same_line(\n",
    "        same_line_text,\n",
    "        after_pos=mdna_page_details.get(\"page_span_end\") or 0,\n",
    "        current_start_page=start_page,\n",
    "    )\n",
    "\n",
    "    next_section_page = same_line_next_page\n",
    "    if next_section_page is None:\n",
    "        next_section_page = _next_section_start_page_after_line(mdna_end_idx, start_page)\n",
    "\n",
    "    end_page = max_page if next_section_page is None else (next_section_page - 1)\n",
    "\n",
    "    if end_page < start_page:\n",
    "        logging.warning(\"Computed invalid MD&A range: start=%s end=%s; skipping\", start_page, end_page)\n",
    "        return None, None\n",
    "\n",
    "    # --- 4) Exclusion ranges (handle same-line next-section; do not require resolving ALL exclusions) ---\n",
    "    def _excluded_ranges():\n",
    "        ranges = []\n",
    "\n",
    "        for title_re, anchor_re in disallowed:\n",
    "            # If MD&A was found inside the Directors' Report, don't treat Directors' Report as an exclusion\n",
    "            if directors_re.pattern == title_re.pattern and mdna_title_re.search(mdna_block_text or \"\"):\n",
    "                if directors_re.search(mdna_block_text or \"\"):\n",
    "                    continue\n",
    "\n",
    "            ex_start_idx, ex_end_idx, ex_block_text = find_title_block_strict(\n",
    "                raw_lines,\n",
    "                title_re,\n",
    "                max_join_lines=3,\n",
    "                anchor_re=anchor_re,\n",
    "            )\n",
    "\n",
    "            if ex_start_idx is None:\n",
    "                continue\n",
    "\n",
    "            ex_details = resolve_page_number_for_title_block_strict_with_details(\n",
    "                raw_lines,\n",
    "                title_start_idx=ex_start_idx,\n",
    "                title_end_idx=ex_end_idx,\n",
    "                title_re=title_re,\n",
    "                max_page=max_page,\n",
    "                lookahead_lines=3,\n",
    "            )\n",
    "\n",
    "            # If exclusion exists but cannot be aligned within strict window, we cannot\n",
    "            # form a reliable range; skip enforcing that specific exclusion.\n",
    "            if not ex_details:\n",
    "                logging.warning(\"Excluded section found but page number not aligned; ignoring exclusion: %s\", ex_block_text)\n",
    "                continue\n",
    "\n",
    "            ex_start_page = ex_details[\"page\"]\n",
    "\n",
    "            ex_same_line_idx = ex_details[\"page_line_idx\"]\n",
    "            ex_same_line_text = raw_lines[ex_same_line_idx].get(\"line_text\", \"\")\n",
    "            ex_same_line_next = _next_page_number_in_same_line(\n",
    "                ex_same_line_text,\n",
    "                after_pos=ex_details.get(\"page_span_end\") or 0,\n",
    "                current_start_page=ex_start_page,\n",
    "            )\n",
    "\n",
    "            ex_next_page = ex_same_line_next\n",
    "            if ex_next_page is None:\n",
    "                ex_next_page = _next_section_start_page_after_line(ex_end_idx, ex_start_page)\n",
    "\n",
    "            # Critical safety for multi-column/boxed ToCs:\n",
    "            # if an excluded section starts before MD&A (by page number), it must end no later\n",
    "            # than the MD&A start page (as both are ToC-derived section starts), even if the\n",
    "            # extracted line order is scrambled.\n",
    "            if ex_start_page < start_page:\n",
    "                if ex_next_page is None or start_page < ex_next_page:\n",
    "                    ex_next_page = start_page\n",
    "\n",
    "            ex_end_page = max_page if ex_next_page is None else (ex_next_page - 1)\n",
    "\n",
    "            ranges.append(\n",
    "                {\n",
    "                    \"title\": ex_block_text,\n",
    "                    \"start\": ex_start_page,\n",
    "                    \"end\": ex_end_page,\n",
    "                }\n",
    "            )\n",
    "\n",
    "        return ranges\n",
    "\n",
    "    ex_ranges = _excluded_ranges()\n",
    "\n",
    "    for r in ex_ranges:\n",
    "        if r[\"start\"] <= start_page <= r[\"end\"]:\n",
    "            logging.warning(\n",
    "                \"MD&A start page %s falls inside excluded section '%s' (%s-%s); skipping\",\n",
    "                start_page,\n",
    "                r[\"title\"],\n",
    "                r[\"start\"],\n",
    "                r[\"end\"],\n",
    "            )\n",
    "            return None, None\n",
    "\n",
    "    logging.info(\"MD&A boundaries (STRICT ToC blocks): start=%s, end=%s\", start_page, end_page)\n",
    "    return start_page, end_page\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "521c7f4c",
   "metadata": {},
   "source": [
    "### 7. MD&A Text Extraction (Boundary-Aware) : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34d448a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-29 22:50:38,643 | INFO | root | MD&A pages included: 6\n",
      "2025-12-29 22:50:38,655 | INFO | root | Extracted MD&A text length (chars): 18561\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MD&A preview:\n",
      "\n",
      "56 | AMTEK AUTO LIMITED\n",
      "AMTEK AUTO LIMITED\n",
      "MANAGEMENT DISCUSSION AND ANALYSIS REPORT\n",
      "1.\n",
      "GLOBAL ECONOMIC OVERVIEW\n",
      "The overall performance of the global economy remained subdued through 2014, as well as into 2015. The world\n",
      "economy grew 3.4% in 2014, impacted by a slowdown in many developing countries, which account for approximately\n",
      "75% of the world economy. According to the International Monetary Fund (IMF), the global GDP growth rate is expected\n",
      "to decline further by 30bps to 3.1% in 2015. A modest pickup in advanced economies and continued challenges in\n",
      "emerging markets are the major factors behind these lower projections. The GDP growth for emerging markets and\n",
      "developing countries in 2015 is expected to decline by 60bps to 4.0%, owing to weaker economic growth in the oil\n",
      "exporting countries, a slowdown in China and expected negative growth in Brazil.\n",
      "2.\n",
      "INDIAN ECONOMIC OVERVIEW\n",
      "During fiscal year 2015, the Indian economy started to show signs of a recovery after a prolonged slowdow\n"
     ]
    }
   ],
   "source": [
    "def extract_mdna_text(pages_text, start_page, end_page):\n",
    "    \"\"\"Extract raw MD&A text from PDF pages using detected boundaries.\n",
    "\n",
    "    Args:\n",
    "        pages_text: List of page dictionaries from PDFInterface.get_pages_text(),\n",
    "                    each like {\"page_number\": int, \"text\": str}\n",
    "        start_page: 1-based start page number (inclusive)\n",
    "        end_page: 1-based end page number (inclusive)\n",
    "\n",
    "    Returns:\n",
    "        str: Concatenated raw MD&A text (no cleaning), with double newlines\n",
    "             inserted between pages.\n",
    "    \"\"\"\n",
    "\n",
    "    included_text_chunks = []\n",
    "    included_pages = 0\n",
    "\n",
    "    for page in pages_text:\n",
    "        page_no = page.get(\"page_number\")\n",
    "        if page_no is None:\n",
    "            continue\n",
    "\n",
    "        if start_page <= page_no <= end_page:\n",
    "            included_pages += 1\n",
    "            included_text_chunks.append(page.get(\"text\", \"\"))\n",
    "\n",
    "    mdna_text = \"\\n\\n\".join(included_text_chunks)\n",
    "\n",
    "    logging.info(\"MD&A pages included: %d\", included_pages)\n",
    "    logging.info(\"Extracted MD&A text length (chars): %d\", len(mdna_text))\n",
    "\n",
    "    return mdna_text\n",
    "\n",
    "\n",
    "# mdna_text = extract_mdna_text(pages, start_page, end_page)\n",
    "\n",
    "# print(\"MD&A preview:\\n\")\n",
    "# print(mdna_text[:1000])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "099b0200",
   "metadata": {},
   "source": [
    "### 8. MD&A Text Cleaning & Artifact Removal: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08b64a72",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-29 15:06:51,628 | INFO | root | MD&A text original length (chars): 39415\n",
      "2025-12-29 15:06:51,629 | INFO | root | MD&A text cleaned length (chars): 37792\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned MD&A preview:\n",
      "\n",
      "20 | AMTEK AUTO LIMITED\n",
      "SECRETARIAL AUDIT REPORT\n",
      "The Board has appointed M/s S. Khurana & Associates, Company Secretaries, to conduct Secretarial Audit for the financial\n",
      "year 2015-16. The Secretarial Audit Report for the financial year ended March 31, 2016 is annexed herewith marked as\n",
      "Annexure - I to this Report. The Secretarial Audit Report does not contain any qualification, reservation or adverse remark.\n",
      "As per the directive of Securities and Exchange Board of India, M/s S. Khurana & Associates Company Secretaries, New\n",
      "Delhi, undertook the Reconciliation of Share Capital Audit on a quarterly basis. The purpose of the audit is to reconcile the\n",
      "total number of shares held in National Securities Depository Limited (NSDL), Central Depository Services (India) Limited\n",
      "(CDSL) and in physical form with the respect to admitted, issued and paid up capital of the Company.\n",
      "CORPORATE GOVERNANCE\n",
      "The Company is committed to maintain high standards of Corporate Governance and adhere to the Corporate Governance\n",
      "requirements set out by SEBI. The Report on Corporate Governance as stipulated under SEBI (Listing Obligations and\n",
      "Disclosure Requirements) Regulations, 2015 forms an Integral part of th\n"
     ]
    }
   ],
   "source": [
    "def clean_mdna_text(raw_text):\n",
    "    \"\"\"Conservatively clean extracted MD&A text.\n",
    "\n",
    "    What this does (conservative heuristics):\n",
    "    - Removes obvious repeating headers/footers (e.g., 'Annual Report ...', standalone page numbers,\n",
    "      and very header-like company-name lines when they appear repeatedly).\n",
    "    - Removes obvious table artifacts (high digit-density lines, and separator-only lines).\n",
    "    - Normalizes whitespace while preserving paragraph breaks.\n",
    "\n",
    "    What this does NOT do:\n",
    "    - Does not lowercase text\n",
    "    - Does not remove punctuation\n",
    "    - Does not change wording\n",
    "\n",
    "    Args:\n",
    "        raw_text: str\n",
    "\n",
    "    Returns:\n",
    "        str: cleaned MD&A text\n",
    "    \"\"\"\n",
    "\n",
    "    if raw_text is None:\n",
    "        raw_text = \"\"\n",
    "\n",
    "    original_len = len(raw_text)\n",
    "\n",
    "    # Split into lines to enable conservative line-based removals.\n",
    "    lines = raw_text.splitlines()\n",
    "\n",
    "    # Pre-compute line frequencies (normalized) to detect repeated headers/footers.\n",
    "    def _norm_line_for_freq(line: str) -> str:\n",
    "        return re.sub(r\"\\s+\", \" \", (line or \"\").strip())\n",
    "\n",
    "    normalized_lines = [_norm_line_for_freq(ln) for ln in lines]\n",
    "    freq = {}\n",
    "    for nl in normalized_lines:\n",
    "        if not nl:\n",
    "            continue\n",
    "        freq[nl] = freq.get(nl, 0) + 1\n",
    "\n",
    "    annual_report_re = re.compile(r\"^\\s*Annual\\s+Report(?:\\s+\\d{4}\\s*[-–]\\s*\\d{2,4})?\\s*$\", re.IGNORECASE)\n",
    "    standalone_page_no_re = re.compile(r\"^\\s*(?:page\\s*)?\\d{1,4}\\s*$\", re.IGNORECASE)\n",
    "    separators_only_re = re.compile(r\"^[\\s\\-_=*~•·\\.\\|:;,+/\\\\]+$\")\n",
    "\n",
    "    def _is_company_name_like(line: str) -> bool:\n",
    "        # Conservative: only remove if it looks like a standalone header/footer line.\n",
    "        s = (line or \"\").strip()\n",
    "        if not s:\n",
    "            return False\n",
    "        if len(s) > 90:\n",
    "            return False\n",
    "\n",
    "        # Must contain common company suffixes.\n",
    "        if not re.search(r\"\\b(LIMITED|LTD\\.?|PVT\\.?\\s+LTD\\.?|PRIVATE\\s+LIMITED)\\b\", s, flags=re.IGNORECASE):\n",
    "            return False\n",
    "\n",
    "        # Must be mostly uppercase (typical header styling).\n",
    "        letters = re.findall(r\"[A-Za-z]\", s)\n",
    "        if not letters:\n",
    "            return False\n",
    "        upper_letters = sum(1 for ch in letters if ch.isupper())\n",
    "        if upper_letters / len(letters) < 0.8:\n",
    "            return False\n",
    "\n",
    "        # Keep it short in words (header/footer line).\n",
    "        if len(s.split()) > 10:\n",
    "            return False\n",
    "\n",
    "        return True\n",
    "\n",
    "    def _is_high_numeric_density(line: str) -> bool:\n",
    "        s = (line or \"\").strip()\n",
    "        if len(s) < 12:\n",
    "            return False\n",
    "        # Density computed over non-space characters.\n",
    "        compact = re.sub(r\"\\s+\", \"\", s)\n",
    "        if not compact:\n",
    "            return False\n",
    "        digits = sum(1 for ch in compact if ch.isdigit())\n",
    "        return (digits / len(compact)) > 0.40\n",
    "\n",
    "    cleaned_lines = []\n",
    "\n",
    "    for raw_line, norm_line in zip(lines, normalized_lines):\n",
    "        s = (raw_line or \"\").rstrip()\n",
    "        sn = norm_line\n",
    "\n",
    "        # Remove obvious separators/formatting-only lines.\n",
    "        if sn and separators_only_re.match(sn):\n",
    "            continue\n",
    "\n",
    "        # Remove obvious page numbers (standalone).\n",
    "        if sn and standalone_page_no_re.match(sn):\n",
    "            continue\n",
    "\n",
    "        # Remove 'Annual Report' headers/footers.\n",
    "        if sn and annual_report_re.match(sn):\n",
    "            continue\n",
    "\n",
    "        # Remove frequent header/footer-like lines conservatively.\n",
    "        # (Only if repeated AND header-ish AND not too long.)\n",
    "        if sn and freq.get(sn, 0) >= 3:\n",
    "            if _is_company_name_like(sn) or annual_report_re.match(sn) or standalone_page_no_re.match(sn):\n",
    "                continue\n",
    "\n",
    "        # Remove obvious table artifacts: high numeric density.\n",
    "        if _is_high_numeric_density(sn):\n",
    "            continue\n",
    "\n",
    "        # Whitespace normalization inside the line.\n",
    "        s = re.sub(r\"[ \\t]{2,}\", \" \", s).strip(\" \")\n",
    "        cleaned_lines.append(s)\n",
    "\n",
    "    # Re-join with newlines and normalize paragraph spacing.\n",
    "    cleaned_text = \"\\n\".join(cleaned_lines)\n",
    "\n",
    "    # Reduce 3+ consecutive newlines to at most 2.\n",
    "    cleaned_text = re.sub(r\"\\n{3,}\", \"\\n\\n\", cleaned_text)\n",
    "\n",
    "    # Trim leading/trailing whitespace/newlines.\n",
    "    cleaned_text = cleaned_text.strip()\n",
    "\n",
    "    logging.info(\"MD&A text original length (chars): %d\", original_len)\n",
    "    logging.info(\"MD&A text cleaned length (chars): %d\", len(cleaned_text))\n",
    "\n",
    "    return cleaned_text\n",
    "\n",
    "#sanity test: \n",
    "# cleaned_text = clean_mdna_text(mdna_text)\n",
    "\n",
    "# print(\"Cleaned MD&A preview:\\n\")\n",
    "# print(cleaned_text[:1200])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d36041d",
   "metadata": {},
   "source": [
    "### 9. MD&A Quality Verification & Validation Metrics : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "fc5792c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify_mdna_quality(mdna_text, pages_match_toc: bool):\n",
    "    \"\"\"Verify extracted/cleaned MD&A text quality using STRICT semantics.\n",
    "\n",
    "    quality_passed MUST be TRUE only if:\n",
    "      - Extracted pages match the ToC-declared MD&A range exactly (pages_match_toc=True)\n",
    "      - Text contains at least 2 MD&A-specific phrases (case-insensitive)\n",
    "\n",
    "    Guardrail:\n",
    "      - Audit / Corporate / Director section signals must ALWAYS fail quality.\n",
    "\n",
    "    Returns:\n",
    "        dict with keys:\n",
    "          - word_count (int)\n",
    "          - narrative_density (float)\n",
    "          - keyword_hits (list[str])\n",
    "          - quality_passed (bool)\n",
    "    \"\"\"\n",
    "\n",
    "    if mdna_text is None:\n",
    "        mdna_text = \"\"\n",
    "\n",
    "    # a) Word count\n",
    "    words = re.findall(r\"\\b\\w+\\b\", mdna_text)\n",
    "    word_count = len(words)\n",
    "\n",
    "    # b) Narrative density (alphabetic chars / total chars)\n",
    "    total_chars = len(mdna_text)\n",
    "    alpha_chars = sum(1 for ch in mdna_text if ch.isalpha())\n",
    "    narrative_density = (alpha_chars / total_chars) if total_chars else 0.0\n",
    "\n",
    "    lower_text = mdna_text.lower()\n",
    "\n",
    "    # c) Required MD&A phrases\n",
    "    mdna_phrases = [\n",
    "        \"industry outlook\",\n",
    "        \"opportunities and threats\",\n",
    "        \"risk management\",\n",
    "        \"future outlook\",\n",
    "        \"segment performance\",\n",
    "        \"global economy\",\n",
    "    ]\n",
    "\n",
    "    keyword_hits = [p for p in mdna_phrases if p in lower_text]\n",
    "\n",
    "    # Disqualifiers: MUST always fail\n",
    "    disqualifiers = [\n",
    "        \"independent auditor\",\n",
    "        \"auditor's report\",\n",
    "        \"auditors' report\",\n",
    "        \"auditors report\",\n",
    "        \"secretarial audit\",\n",
    "        \"form mr-3\",\n",
    "        \"mr-3\",\n",
    "        \"corporate information\",\n",
    "        \"corporate governance\",\n",
    "        \"directors' report\",\n",
    "        \"director's report\",\n",
    "        \"directors report\",\n",
    "    ]\n",
    "\n",
    "    disqualifier_hit = any(bad in lower_text for bad in disqualifiers)\n",
    "\n",
    "    criteria_pages_match = bool(pages_match_toc)\n",
    "    criteria_phrases = len(keyword_hits) >= 2\n",
    "\n",
    "    quality_passed = bool(criteria_pages_match and criteria_phrases and (not disqualifier_hit))\n",
    "\n",
    "    logging.info(\"MD&A quality — word_count: %d\", word_count)\n",
    "    logging.info(\"MD&A quality — narrative_density: %.4f\", narrative_density)\n",
    "    logging.info(\"MD&A quality — keyword_hits (%d): %s\", len(keyword_hits), keyword_hits)\n",
    "    logging.info(\"MD&A quality — pages_match_toc: %s\", criteria_pages_match)\n",
    "    logging.info(\"MD&A quality — disqualifier_hit: %s\", disqualifier_hit)\n",
    "\n",
    "    if quality_passed:\n",
    "        logging.info(\"MD&A quality PASSED\")\n",
    "    else:\n",
    "        logging.warning(\n",
    "            \"MD&A quality FLAGGED (pages_match_toc=%s, phrases_ok=%s, disqualifier_hit=%s)\",\n",
    "            criteria_pages_match,\n",
    "            criteria_phrases,\n",
    "            disqualifier_hit,\n",
    "        )\n",
    "\n",
    "    return {\n",
    "        \"word_count\": word_count,\n",
    "        \"narrative_density\": float(narrative_density),\n",
    "        \"keyword_hits\": keyword_hits,\n",
    "        \"quality_passed\": quality_passed,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "26992cc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-30 00:04:04,490 | INFO | root | Discovered 14 PDFs under ..\\data\\pdfs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-30 00:04:04,492 | INFO | root | (1/14) Processing: Alcheimist/5267070319.pdf\n",
      "2025-12-30 00:04:04,496 | INFO | root | Loaded PDF: 5267070319.pdf\n",
      "2025-12-30 00:04:04,891 | INFO | root | Extracted company name: You are requested to take the above mentioned information on your records.\n",
      "For Alchemist Limited\n",
      "2025-12-30 00:04:04,892 | INFO | root | Extracted financial year: 2018-19\n",
      "2025-12-30 00:04:04,893 | WARNING | root | Excluded section found but page number not aligned; ignoring exclusion: DIRECTORS’ REPORT\n",
      "2025-12-30 00:04:04,895 | INFO | root | MD&A boundaries (STRICT ToC blocks): start=23, end=100\n",
      "2025-12-30 00:04:04,895 | INFO | root | MD&A pages included: 78\n",
      "2025-12-30 00:04:04,896 | INFO | root | Extracted MD&A text length (chars): 243745\n",
      "2025-12-30 00:04:04,952 | INFO | root | MD&A text original length (chars): 243745\n",
      "2025-12-30 00:04:04,953 | INFO | root | MD&A text cleaned length (chars): 229396\n",
      "2025-12-30 00:04:04,983 | INFO | root | MD&A quality — word_count: 37325\n",
      "2025-12-30 00:04:04,985 | INFO | root | MD&A quality — narrative_density: 0.7704\n",
      "2025-12-30 00:04:04,985 | INFO | root | MD&A quality — keyword_hits (2): ['risk management', 'segment performance']\n",
      "2025-12-30 00:04:04,986 | INFO | root | MD&A quality — pages_match_toc: True\n",
      "2025-12-30 00:04:04,987 | INFO | root | MD&A quality — disqualifier_hit: True\n",
      "2025-12-30 00:04:04,987 | WARNING | root | MD&A quality FLAGGED (pages_match_toc=True, phrases_ok=True, disqualifier_hit=True)\n",
      "2025-12-30 00:04:04,989 | INFO | root | (2/14) Processing: Alcheimist/67050526707.pdf\n",
      "2025-12-30 00:04:04,992 | INFO | root | Loaded PDF: 67050526707.pdf\n",
      "2025-12-30 00:04:05,264 | INFO | root | Extracted company name: Bankers\n",
      "Punjab National Bank\n",
      "Bank Of india\n",
      "HDFC Bank\n",
      "Registrar & Share Transfers Agent\n",
      "Link Intime India Private Limited\n",
      "2025-12-30 00:04:05,266 | INFO | root | Extracted financial year: 2019-20\n",
      "2025-12-30 00:04:05,268 | INFO | root | MD&A boundaries (STRICT ToC blocks): start=29, end=31\n",
      "2025-12-30 00:04:05,269 | INFO | root | MD&A pages included: 3\n",
      "2025-12-30 00:04:05,269 | INFO | root | Extracted MD&A text length (chars): 17487\n",
      "2025-12-30 00:04:05,274 | INFO | root | MD&A text original length (chars): 17487\n",
      "2025-12-30 00:04:05,274 | INFO | root | MD&A text cleaned length (chars): 17281\n",
      "2025-12-30 00:04:05,278 | INFO | root | MD&A quality — word_count: 2740\n",
      "2025-12-30 00:04:05,278 | INFO | root | MD&A quality — narrative_density: 0.8167\n",
      "2025-12-30 00:04:05,279 | INFO | root | MD&A quality — keyword_hits (0): []\n",
      "2025-12-30 00:04:05,280 | INFO | root | MD&A quality — pages_match_toc: True\n",
      "2025-12-30 00:04:05,280 | INFO | root | MD&A quality — disqualifier_hit: False\n",
      "2025-12-30 00:04:05,281 | WARNING | root | MD&A quality FLAGGED (pages_match_toc=True, phrases_ok=False, disqualifier_hit=False)\n",
      "2025-12-30 00:04:05,282 | INFO | root | (3/14) Processing: ALok/5210700315.pdf\n",
      "2025-12-30 00:04:05,290 | INFO | root | Loaded PDF: 5210700315.pdf\n",
      "2025-12-30 00:04:05,926 | INFO | root | Company name not found in first 3 pages\n",
      "2025-12-30 00:04:05,927 | INFO | root | Financial year not found in first 5 pages\n",
      "2025-12-30 00:04:05,928 | INFO | root | MD&A boundaries (STRICT ToC blocks): start=51, end=82\n",
      "2025-12-30 00:04:05,929 | INFO | root | MD&A pages included: 32\n",
      "2025-12-30 00:04:05,930 | INFO | root | Extracted MD&A text length (chars): 103632\n",
      "2025-12-30 00:04:05,956 | INFO | root | MD&A text original length (chars): 103632\n",
      "2025-12-30 00:04:05,957 | INFO | root | MD&A text cleaned length (chars): 99910\n",
      "2025-12-30 00:04:05,973 | INFO | root | MD&A quality — word_count: 16737\n",
      "2025-12-30 00:04:05,974 | INFO | root | MD&A quality — narrative_density: 0.7510\n",
      "2025-12-30 00:04:05,975 | INFO | root | MD&A quality — keyword_hits (0): []\n",
      "2025-12-30 00:04:05,976 | INFO | root | MD&A quality — pages_match_toc: True\n",
      "2025-12-30 00:04:05,976 | INFO | root | MD&A quality — disqualifier_hit: False\n",
      "2025-12-30 00:04:05,978 | WARNING | root | MD&A quality FLAGGED (pages_match_toc=True, phrases_ok=False, disqualifier_hit=False)\n",
      "2025-12-30 00:04:05,981 | INFO | root | (4/14) Processing: ALok/5210700316.pdf\n",
      "2025-12-30 00:04:05,986 | INFO | root | Loaded PDF: 5210700316.pdf\n",
      "2025-12-30 00:04:06,446 | INFO | root | Company name not found in first 3 pages\n",
      "2025-12-30 00:04:06,448 | INFO | root | Extracted financial year: 2015-16\n",
      "2025-12-30 00:04:06,449 | INFO | root | MD&A boundaries (STRICT ToC blocks): start=46, end=62\n",
      "2025-12-30 00:04:06,450 | INFO | root | MD&A pages included: 17\n",
      "2025-12-30 00:04:06,451 | INFO | root | Extracted MD&A text length (chars): 72251\n",
      "2025-12-30 00:04:06,471 | INFO | root | MD&A text original length (chars): 72251\n",
      "2025-12-30 00:04:06,471 | INFO | root | MD&A text cleaned length (chars): 70143\n",
      "2025-12-30 00:04:06,484 | INFO | root | MD&A quality — word_count: 11815\n",
      "2025-12-30 00:04:06,486 | INFO | root | MD&A quality — narrative_density: 0.7553\n",
      "2025-12-30 00:04:06,487 | INFO | root | MD&A quality — keyword_hits (0): []\n",
      "2025-12-30 00:04:06,488 | INFO | root | MD&A quality — pages_match_toc: True\n",
      "2025-12-30 00:04:06,488 | INFO | root | MD&A quality — disqualifier_hit: True\n",
      "2025-12-30 00:04:06,489 | WARNING | root | MD&A quality FLAGGED (pages_match_toc=True, phrases_ok=False, disqualifier_hit=True)\n",
      "2025-12-30 00:04:06,491 | INFO | root | (5/14) Processing: ALok/5210700317.pdf\n",
      "2025-12-30 00:04:06,500 | INFO | root | Loaded PDF: 5210700317.pdf\n",
      "2025-12-30 00:04:07,242 | INFO | root | Company name not found in first 3 pages\n",
      "2025-12-30 00:04:07,243 | INFO | root | Extracted financial year: 2016-17\n",
      "2025-12-30 00:04:07,245 | INFO | root | MD&A boundaries (STRICT ToC blocks): start=9, end=9\n",
      "2025-12-30 00:04:07,246 | INFO | root | MD&A pages included: 1\n",
      "2025-12-30 00:04:07,247 | INFO | root | Extracted MD&A text length (chars): 2323\n",
      "2025-12-30 00:04:07,248 | INFO | root | MD&A text original length (chars): 2323\n",
      "2025-12-30 00:04:07,249 | INFO | root | MD&A text cleaned length (chars): 2281\n",
      "2025-12-30 00:04:07,251 | INFO | root | MD&A quality — word_count: 368\n",
      "2025-12-30 00:04:07,252 | INFO | root | MD&A quality — narrative_density: 0.8203\n",
      "2025-12-30 00:04:07,253 | INFO | root | MD&A quality — keyword_hits (0): []\n",
      "2025-12-30 00:04:07,253 | INFO | root | MD&A quality — pages_match_toc: True\n",
      "2025-12-30 00:04:07,254 | INFO | root | MD&A quality — disqualifier_hit: False\n",
      "2025-12-30 00:04:07,254 | WARNING | root | MD&A quality FLAGGED (pages_match_toc=True, phrases_ok=False, disqualifier_hit=False)\n",
      "2025-12-30 00:04:07,257 | INFO | root | (6/14) Processing: ALok/5210700318.pdf\n",
      "2025-12-30 00:04:07,264 | INFO | root | Loaded PDF: 5210700318.pdf\n",
      "2025-12-30 00:04:07,870 | INFO | root | Company name not found in first 3 pages\n",
      "2025-12-30 00:04:07,871 | INFO | root | Extracted financial year: 2017-18\n",
      "2025-12-30 00:04:07,873 | INFO | root | MD&A boundaries (STRICT ToC blocks): start=46, end=62\n",
      "2025-12-30 00:04:07,873 | INFO | root | MD&A pages included: 17\n",
      "2025-12-30 00:04:07,874 | INFO | root | Extracted MD&A text length (chars): 56104\n",
      "2025-12-30 00:04:07,894 | INFO | root | MD&A text original length (chars): 56104\n",
      "2025-12-30 00:04:07,895 | INFO | root | MD&A text cleaned length (chars): 54599\n",
      "2025-12-30 00:04:07,904 | INFO | root | MD&A quality — word_count: 9254\n",
      "2025-12-30 00:04:07,905 | INFO | root | MD&A quality — narrative_density: 0.7307\n",
      "2025-12-30 00:04:07,905 | INFO | root | MD&A quality — keyword_hits (2): ['risk management', 'global economy']\n",
      "2025-12-30 00:04:07,906 | INFO | root | MD&A quality — pages_match_toc: True\n",
      "2025-12-30 00:04:07,907 | INFO | root | MD&A quality — disqualifier_hit: True\n",
      "2025-12-30 00:04:07,907 | WARNING | root | MD&A quality FLAGGED (pages_match_toc=True, phrases_ok=True, disqualifier_hit=True)\n",
      "2025-12-30 00:04:07,911 | INFO | root | (7/14) Processing: Amit_spinning/5210760315.pdf\n",
      "2025-12-30 00:04:07,914 | INFO | root | Loaded PDF: 5210760315.pdf\n",
      "2025-12-30 00:04:08,070 | INFO | root | Extracted company name: AMIT SPINNING INDUSTRIES LIMITED\n",
      "2025-12-30 00:04:08,071 | INFO | root | Extracted financial year: 2014-15\n",
      "2025-12-30 00:04:08,073 | INFO | root | MD&A boundaries (STRICT ToC blocks): start=8, end=15\n",
      "2025-12-30 00:04:08,074 | INFO | root | MD&A pages included: 8\n",
      "2025-12-30 00:04:08,075 | INFO | root | Extracted MD&A text length (chars): 37547\n",
      "2025-12-30 00:04:08,082 | INFO | root | MD&A text original length (chars): 37547\n",
      "2025-12-30 00:04:08,083 | INFO | root | MD&A text cleaned length (chars): 36394\n",
      "2025-12-30 00:04:08,089 | INFO | root | MD&A quality — word_count: 5952\n",
      "2025-12-30 00:04:08,090 | INFO | root | MD&A quality — narrative_density: 0.7748\n",
      "2025-12-30 00:04:08,091 | INFO | root | MD&A quality — keyword_hits (2): ['risk management', 'future outlook']\n",
      "2025-12-30 00:04:08,091 | INFO | root | MD&A quality — pages_match_toc: True\n",
      "2025-12-30 00:04:08,092 | INFO | root | MD&A quality — disqualifier_hit: True\n",
      "2025-12-30 00:04:08,092 | WARNING | root | MD&A quality FLAGGED (pages_match_toc=True, phrases_ok=True, disqualifier_hit=True)\n",
      "2025-12-30 00:04:08,094 | INFO | root | (8/14) Processing: Amit_spinning/5210760316.pdf\n",
      "2025-12-30 00:04:08,098 | INFO | root | Loaded PDF: 5210760316.pdf\n",
      "2025-12-30 00:04:08,233 | INFO | root | Extracted company name: JM Financial Asset Reconstruction Company Pvt. Ltd.\n",
      "2025-12-30 00:04:08,234 | INFO | root | Extracted financial year: 2015-16\n",
      "2025-12-30 00:04:08,237 | INFO | root | MD&A boundaries (STRICT ToC blocks): start=8, end=16\n",
      "2025-12-30 00:04:08,238 | INFO | root | MD&A pages included: 9\n",
      "2025-12-30 00:04:08,238 | INFO | root | Extracted MD&A text length (chars): 35662\n",
      "2025-12-30 00:04:08,252 | INFO | root | MD&A text original length (chars): 35662\n",
      "2025-12-30 00:04:08,253 | INFO | root | MD&A text cleaned length (chars): 34214\n",
      "2025-12-30 00:04:08,261 | INFO | root | MD&A quality — word_count: 5666\n",
      "2025-12-30 00:04:08,262 | INFO | root | MD&A quality — narrative_density: 0.7572\n",
      "2025-12-30 00:04:08,263 | INFO | root | MD&A quality — keyword_hits (1): ['risk management']\n",
      "2025-12-30 00:04:08,264 | INFO | root | MD&A quality — pages_match_toc: True\n",
      "2025-12-30 00:04:08,264 | INFO | root | MD&A quality — disqualifier_hit: True\n",
      "2025-12-30 00:04:08,265 | WARNING | root | MD&A quality FLAGGED (pages_match_toc=True, phrases_ok=False, disqualifier_hit=True)\n",
      "2025-12-30 00:04:08,266 | INFO | root | (9/14) Processing: Amit_spinning/5210760317.pdf\n",
      "2025-12-30 00:04:08,271 | INFO | root | Loaded PDF: 5210760317.pdf\n",
      "2025-12-30 00:04:08,399 | INFO | root | Extracted company name: JM Financial Asset Reconstruction\n",
      "Company Pvt. Ltd.\n",
      "2025-12-30 00:04:08,400 | INFO | root | Extracted financial year: 2016-17\n",
      "2025-12-30 00:04:08,401 | WARNING | root | MD&A start page not found within strict 3-line window; skipping\n",
      "2025-12-30 00:04:08,402 | WARNING | root | Skipping (MD&A boundaries not determinable via STRICT ToC rules): 5210760317.pdf\n",
      "2025-12-30 00:04:08,403 | INFO | root | (10/14) Processing: Amit_spinning/5210760318.pdf\n",
      "2025-12-30 00:04:08,406 | INFO | root | Loaded PDF: 5210760318.pdf\n",
      "2025-12-30 00:04:08,484 | INFO | root | Extracted company name: Please take the above on record.\n",
      "Thanking you,\n",
      "Yours truly,\n",
      "For AMIT SPINNING INDUSTRIES LIMITED\n",
      "2025-12-30 00:04:08,485 | INFO | root | Extracted financial year: 2017-18\n",
      "2025-12-30 00:04:08,485 | WARNING | root | MD&A start page not found within strict 3-line window; skipping\n",
      "2025-12-30 00:04:08,486 | WARNING | root | Skipping (MD&A boundaries not determinable via STRICT ToC rules): 5210760318.pdf\n",
      "2025-12-30 00:04:08,487 | INFO | root | (11/14) Processing: Amtek/5200770316.pdf\n",
      "2025-12-30 00:04:08,489 | INFO | root | Loaded PDF: 5200770316.pdf\n",
      "2025-12-30 00:04:08,749 | INFO | root | Extracted company name: Bankers\n",
      "Corporation Bank\n",
      "Andhra Bank\n",
      "Indian Overseas Bank\n",
      "IDBI Bank\n",
      "Registrar & Share Transfer Agent\n",
      "Beetal Financial & Computer\n",
      "Services Pvt. Ltd.\n",
      "2025-12-30 00:04:08,751 | INFO | root | Extracted financial year: 2015-16\n",
      "2025-12-30 00:04:08,753 | INFO | root | MD&A boundaries (STRICT ToC blocks): start=63, end=71\n",
      "2025-12-30 00:04:08,754 | INFO | root | MD&A pages included: 9\n",
      "2025-12-30 00:04:08,754 | INFO | root | Extracted MD&A text length (chars): 30612\n",
      "2025-12-30 00:04:08,761 | INFO | root | MD&A text original length (chars): 30612\n",
      "2025-12-30 00:04:08,761 | INFO | root | MD&A text cleaned length (chars): 30344\n",
      "2025-12-30 00:04:08,766 | INFO | root | MD&A quality — word_count: 4742\n",
      "2025-12-30 00:04:08,766 | INFO | root | MD&A quality — narrative_density: 0.8014\n",
      "2025-12-30 00:04:08,767 | INFO | root | MD&A quality — keyword_hits (2): ['risk management', 'global economy']\n",
      "2025-12-30 00:04:08,768 | INFO | root | MD&A quality — pages_match_toc: True\n",
      "2025-12-30 00:04:08,768 | INFO | root | MD&A quality — disqualifier_hit: True\n",
      "2025-12-30 00:04:08,769 | WARNING | root | MD&A quality FLAGGED (pages_match_toc=True, phrases_ok=True, disqualifier_hit=True)\n",
      "2025-12-30 00:04:08,770 | INFO | root | (12/14) Processing: Amtek/5200770317.pdf\n",
      "2025-12-30 00:04:08,772 | INFO | root | Loaded PDF: 5200770317.pdf\n",
      "2025-12-30 00:04:09,083 | INFO | root | Extracted company name: Bankers\n",
      "Corporation Bank\n",
      "Andhra Bank\n",
      "Indian Overseas Bank\n",
      "IDBI Bank\n",
      "Registrar & Share Transfer Agent\n",
      "Beetal Financial & Computer\n",
      "Services Pvt. Ltd.\n",
      "2025-12-30 00:04:09,084 | INFO | root | Extracted financial year: 2016-17\n",
      "2025-12-30 00:04:09,086 | INFO | root | MD&A boundaries (STRICT ToC blocks): start=64, end=72\n",
      "2025-12-30 00:04:09,087 | INFO | root | MD&A pages included: 9\n",
      "2025-12-30 00:04:09,087 | INFO | root | Extracted MD&A text length (chars): 31926\n",
      "2025-12-30 00:04:09,093 | INFO | root | MD&A text original length (chars): 31926\n",
      "2025-12-30 00:04:09,094 | INFO | root | MD&A text cleaned length (chars): 31707\n",
      "2025-12-30 00:04:09,099 | INFO | root | MD&A quality — word_count: 4994\n",
      "2025-12-30 00:04:09,100 | INFO | root | MD&A quality — narrative_density: 0.8025\n",
      "2025-12-30 00:04:09,100 | INFO | root | MD&A quality — keyword_hits (0): []\n",
      "2025-12-30 00:04:09,101 | INFO | root | MD&A quality — pages_match_toc: True\n",
      "2025-12-30 00:04:09,102 | INFO | root | MD&A quality — disqualifier_hit: True\n",
      "2025-12-30 00:04:09,102 | WARNING | root | MD&A quality FLAGGED (pages_match_toc=True, phrases_ok=False, disqualifier_hit=True)\n",
      "2025-12-30 00:04:09,103 | INFO | root | (13/14) Processing: Amtek/5200770318.pdf\n",
      "2025-12-30 00:04:09,109 | INFO | root | Loaded PDF: 5200770318.pdf\n",
      "2025-12-30 00:04:09,543 | INFO | root | Extracted company name: Bankers\n",
      "Corporation Bank\n",
      "Andhra Bank\n",
      "Indian Overseas Bank\n",
      "IDBI Bank\n",
      "Registrar & Share Transfer Agent\n",
      "Beetal Financial & Computer\n",
      "Services Pvt. Ltd.\n",
      "2025-12-30 00:04:09,545 | INFO | root | Extracted financial year: 2017-18\n",
      "2025-12-30 00:04:09,547 | INFO | root | MD&A boundaries (STRICT ToC blocks): start=65, end=74\n",
      "2025-12-30 00:04:09,548 | INFO | root | MD&A pages included: 10\n",
      "2025-12-30 00:04:09,549 | INFO | root | Extracted MD&A text length (chars): 25803\n",
      "2025-12-30 00:04:09,553 | INFO | root | MD&A text original length (chars): 25803\n",
      "2025-12-30 00:04:09,554 | INFO | root | MD&A text cleaned length (chars): 25302\n",
      "2025-12-30 00:04:09,558 | INFO | root | MD&A quality — word_count: 4007\n",
      "2025-12-30 00:04:09,558 | INFO | root | MD&A quality — narrative_density: 0.7948\n",
      "2025-12-30 00:04:09,559 | INFO | root | MD&A quality — keyword_hits (1): ['global economy']\n",
      "2025-12-30 00:04:09,560 | INFO | root | MD&A quality — pages_match_toc: True\n",
      "2025-12-30 00:04:09,561 | INFO | root | MD&A quality — disqualifier_hit: True\n",
      "2025-12-30 00:04:09,562 | WARNING | root | MD&A quality FLAGGED (pages_match_toc=True, phrases_ok=False, disqualifier_hit=True)\n",
      "2025-12-30 00:04:09,563 | INFO | root | (14/14) Processing: Amtek/5200770915.pdf\n",
      "2025-12-30 00:04:09,567 | INFO | root | Loaded PDF: 5200770915.pdf\n",
      "2025-12-30 00:04:09,750 | INFO | root | Extracted company name: Bankers\n",
      "Corporation Bank\n",
      "Andhra Bank\n",
      "Indian Overseas Bank\n",
      "IDBI Bank\n",
      "Registrar & Share Transfer Agent\n",
      "Beetal Financial\n",
      "& Computer Services Pvt. Ltd.\n",
      "2025-12-30 00:04:09,751 | INFO | root | Extracted financial year: 2014-15\n",
      "2025-12-30 00:04:09,754 | INFO | root | MD&A boundaries (STRICT ToC blocks): start=56, end=63\n",
      "2025-12-30 00:04:09,755 | INFO | root | MD&A pages included: 8\n",
      "2025-12-30 00:04:09,756 | INFO | root | Extracted MD&A text length (chars): 23796\n",
      "2025-12-30 00:04:09,762 | INFO | root | MD&A text original length (chars): 23796\n",
      "2025-12-30 00:04:09,763 | INFO | root | MD&A text cleaned length (chars): 23497\n",
      "2025-12-30 00:04:09,767 | INFO | root | MD&A quality — word_count: 3631\n",
      "2025-12-30 00:04:09,768 | INFO | root | MD&A quality — narrative_density: 0.8120\n",
      "2025-12-30 00:04:09,769 | INFO | root | MD&A quality — keyword_hits (2): ['risk management', 'global economy']\n",
      "2025-12-30 00:04:09,771 | INFO | root | MD&A quality — pages_match_toc: True\n",
      "2025-12-30 00:04:09,771 | INFO | root | MD&A quality — disqualifier_hit: True\n",
      "2025-12-30 00:04:09,772 | WARNING | root | MD&A quality FLAGGED (pages_match_toc=True, phrases_ok=True, disqualifier_hit=True)\n",
      "2025-12-30 00:04:09,774 | INFO | root | Total PDFs discovered: 14\n",
      "2025-12-30 00:04:09,774 | INFO | root | Total PDFs attempted: 14\n",
      "2025-12-30 00:04:09,775 | INFO | root | Total PDFs succeeded: 12\n",
      "2025-12-30 00:04:09,777 | INFO | root | Total PDFs skipped (no STRICT ToC boundaries): 2\n",
      "2025-12-30 00:04:09,778 | INFO | root | Total PDFs failed: 0\n",
      "2025-12-30 00:04:09,779 | INFO | root | Quality checks passed: 0\n",
      "2025-12-30 00:04:09,780 | INFO | root | Quality checks flagged: 12\n",
      "2025-12-30 00:04:09,813 | INFO | root | Wrote CSV: c:\\Users\\LOQ\\Desktop\\SPJIMR\\mdna_extraction_project\\notebooks\\..\\output\\mdna_extracted.csv\n",
      "2025-12-30 00:04:09,875 | INFO | root | Wrote Excel: c:\\Users\\LOQ\\Desktop\\SPJIMR\\mdna_extraction_project\\notebooks\\..\\output\\mdna_extracted.xlsx\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company_folder</th>\n",
       "      <th>company_name</th>\n",
       "      <th>report_file</th>\n",
       "      <th>financial_year</th>\n",
       "      <th>mdna_text</th>\n",
       "      <th>mdna_word_count</th>\n",
       "      <th>narrative_density</th>\n",
       "      <th>keyword_hits</th>\n",
       "      <th>quality_passed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alcheimist</td>\n",
       "      <td>You are requested to take the above mentioned ...</td>\n",
       "      <td>5267070319.pdf</td>\n",
       "      <td>2018-19</td>\n",
       "      <td>V.\\nINDEBTEDNESS - Indebtedness of the Company...</td>\n",
       "      <td>37325</td>\n",
       "      <td>0.770414</td>\n",
       "      <td>[risk management, segment performance]</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alcheimist</td>\n",
       "      <td>Bankers\\nPunjab National Bank\\nBank Of india\\n...</td>\n",
       "      <td>67050526707.pdf</td>\n",
       "      <td>2019-20</td>\n",
       "      <td>Annexure VI\\nMANAGEMENT DISCUSSION AND ANALYSI...</td>\n",
       "      <td>2740</td>\n",
       "      <td>0.816677</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ALok</td>\n",
       "      <td>None</td>\n",
       "      <td>5210700315.pdf</td>\n",
       "      <td>None</td>\n",
       "      <td>PRIMED\\nTO UNLOCK VALUE\\n28th Annual Report | ...</td>\n",
       "      <td>16737</td>\n",
       "      <td>0.750986</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ALok</td>\n",
       "      <td>None</td>\n",
       "      <td>5210700316.pdf</td>\n",
       "      <td>2015-16</td>\n",
       "      <td>Innovative Textile Solutions 43\\nForm No. MR-3...</td>\n",
       "      <td>11815</td>\n",
       "      <td>0.755314</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ALok</td>\n",
       "      <td>None</td>\n",
       "      <td>5210700317.pdf</td>\n",
       "      <td>2016-17</td>\n",
       "      <td>As mentioned earlier, the overall performance ...</td>\n",
       "      <td>368</td>\n",
       "      <td>0.820254</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ALok</td>\n",
       "      <td>None</td>\n",
       "      <td>5210700318.pdf</td>\n",
       "      <td>2017-18</td>\n",
       "      <td>(vi)\\nThe following laws are applicable to the...</td>\n",
       "      <td>9254</td>\n",
       "      <td>0.730728</td>\n",
       "      <td>[risk management, global economy]</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Amit_spinning</td>\n",
       "      <td>AMIT SPINNING INDUSTRIES LIMITED</td>\n",
       "      <td>5210760315.pdf</td>\n",
       "      <td>2014-15</td>\n",
       "      <td>DIRECTORS’ REPORT\\nYour Directors have great p...</td>\n",
       "      <td>5952</td>\n",
       "      <td>0.774771</td>\n",
       "      <td>[risk management, future outlook]</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Amit_spinning</td>\n",
       "      <td>JM Financial Asset Reconstruction Company Pvt....</td>\n",
       "      <td>5210760316.pdf</td>\n",
       "      <td>2015-16</td>\n",
       "      <td>SUBSIDIARY COMPANIES, JOINT VENTURES AND ASSOC...</td>\n",
       "      <td>5666</td>\n",
       "      <td>0.757234</td>\n",
       "      <td>[risk management]</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Amtek</td>\n",
       "      <td>Bankers\\nCorporation Bank\\nAndhra Bank\\nIndian...</td>\n",
       "      <td>5200770316.pdf</td>\n",
       "      <td>2015-16</td>\n",
       "      <td>62 | AMTEK AUTO LIMITED\\nAUDITORS’ REPORT ON C...</td>\n",
       "      <td>4742</td>\n",
       "      <td>0.801443</td>\n",
       "      <td>[risk management, global economy]</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Amtek</td>\n",
       "      <td>Bankers\\nCorporation Bank\\nAndhra Bank\\nIndian...</td>\n",
       "      <td>5200770317.pdf</td>\n",
       "      <td>2016-17</td>\n",
       "      <td>ANNUAL REPORT 2016-17 | 63\\nCEO/CFO CERTIFICAT...</td>\n",
       "      <td>4994</td>\n",
       "      <td>0.802536</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Amtek</td>\n",
       "      <td>Bankers\\nCorporation Bank\\nAndhra Bank\\nIndian...</td>\n",
       "      <td>5200770318.pdf</td>\n",
       "      <td>2017-18</td>\n",
       "      <td>64 | AMTEK AUTO LIMITED\\n(Company under Corpor...</td>\n",
       "      <td>4007</td>\n",
       "      <td>0.794838</td>\n",
       "      <td>[global economy]</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Amtek</td>\n",
       "      <td>Bankers\\nCorporation Bank\\nAndhra Bank\\nIndian...</td>\n",
       "      <td>5200770915.pdf</td>\n",
       "      <td>2014-15</td>\n",
       "      <td>56 | AMTEK AUTO LIMITED\\nMANAGEMENT DISCUSSION...</td>\n",
       "      <td>3631</td>\n",
       "      <td>0.811976</td>\n",
       "      <td>[risk management, global economy]</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   company_folder                                       company_name  \\\n",
       "0      Alcheimist  You are requested to take the above mentioned ...   \n",
       "1      Alcheimist  Bankers\\nPunjab National Bank\\nBank Of india\\n...   \n",
       "2            ALok                                               None   \n",
       "3            ALok                                               None   \n",
       "4            ALok                                               None   \n",
       "5            ALok                                               None   \n",
       "6   Amit_spinning                   AMIT SPINNING INDUSTRIES LIMITED   \n",
       "7   Amit_spinning  JM Financial Asset Reconstruction Company Pvt....   \n",
       "8           Amtek  Bankers\\nCorporation Bank\\nAndhra Bank\\nIndian...   \n",
       "9           Amtek  Bankers\\nCorporation Bank\\nAndhra Bank\\nIndian...   \n",
       "10          Amtek  Bankers\\nCorporation Bank\\nAndhra Bank\\nIndian...   \n",
       "11          Amtek  Bankers\\nCorporation Bank\\nAndhra Bank\\nIndian...   \n",
       "\n",
       "        report_file financial_year  \\\n",
       "0    5267070319.pdf        2018-19   \n",
       "1   67050526707.pdf        2019-20   \n",
       "2    5210700315.pdf           None   \n",
       "3    5210700316.pdf        2015-16   \n",
       "4    5210700317.pdf        2016-17   \n",
       "5    5210700318.pdf        2017-18   \n",
       "6    5210760315.pdf        2014-15   \n",
       "7    5210760316.pdf        2015-16   \n",
       "8    5200770316.pdf        2015-16   \n",
       "9    5200770317.pdf        2016-17   \n",
       "10   5200770318.pdf        2017-18   \n",
       "11   5200770915.pdf        2014-15   \n",
       "\n",
       "                                            mdna_text  mdna_word_count  \\\n",
       "0   V.\\nINDEBTEDNESS - Indebtedness of the Company...            37325   \n",
       "1   Annexure VI\\nMANAGEMENT DISCUSSION AND ANALYSI...             2740   \n",
       "2   PRIMED\\nTO UNLOCK VALUE\\n28th Annual Report | ...            16737   \n",
       "3   Innovative Textile Solutions 43\\nForm No. MR-3...            11815   \n",
       "4   As mentioned earlier, the overall performance ...              368   \n",
       "5   (vi)\\nThe following laws are applicable to the...             9254   \n",
       "6   DIRECTORS’ REPORT\\nYour Directors have great p...             5952   \n",
       "7   SUBSIDIARY COMPANIES, JOINT VENTURES AND ASSOC...             5666   \n",
       "8   62 | AMTEK AUTO LIMITED\\nAUDITORS’ REPORT ON C...             4742   \n",
       "9   ANNUAL REPORT 2016-17 | 63\\nCEO/CFO CERTIFICAT...             4994   \n",
       "10  64 | AMTEK AUTO LIMITED\\n(Company under Corpor...             4007   \n",
       "11  56 | AMTEK AUTO LIMITED\\nMANAGEMENT DISCUSSION...             3631   \n",
       "\n",
       "    narrative_density                            keyword_hits  quality_passed  \n",
       "0            0.770414  [risk management, segment performance]           False  \n",
       "1            0.816677                                      []           False  \n",
       "2            0.750986                                      []           False  \n",
       "3            0.755314                                      []           False  \n",
       "4            0.820254                                      []           False  \n",
       "5            0.730728       [risk management, global economy]           False  \n",
       "6            0.774771       [risk management, future outlook]           False  \n",
       "7            0.757234                       [risk management]           False  \n",
       "8            0.801443       [risk management, global economy]           False  \n",
       "9            0.802536                                      []           False  \n",
       "10           0.794838                        [global economy]           False  \n",
       "11           0.811976       [risk management, global economy]           False  "
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "# -----------------------------\n",
    "# End-to-end MD&A Extraction Pipeline (STRICT ToC-Only Boundaries)\n",
    "# -----------------------------\n",
    "PDF_ROOT = Path(\"../data/pdfs\")\n",
    "\n",
    "# Prefer the configured OUTPUT_DIR if present; otherwise default to ../output\n",
    "try:\n",
    "    output_dir = OUTPUT_DIR\n",
    "except NameError:\n",
    "    output_dir = Path(\"../output\")\n",
    "\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "pdf_paths = sorted(PDF_ROOT.rglob(\"*.pdf\"))\n",
    "logging.info(\"Discovered %d PDFs under %s\", len(pdf_paths), PDF_ROOT)\n",
    "\n",
    "results = []\n",
    "\n",
    "attempted = 0\n",
    "succeeded = 0\n",
    "skipped_no_boundaries = 0\n",
    "failed = 0\n",
    "passed_quality = 0\n",
    "flagged_quality = 0\n",
    "\n",
    "for idx, pdf_path in enumerate(pdf_paths, start=1):\n",
    "    attempted += 1\n",
    "    company_folder = pdf_path.parent.name\n",
    "\n",
    "    logging.info(\"(%d/%d) Processing: %s/%s\", idx, len(pdf_paths), company_folder, pdf_path.name)\n",
    "\n",
    "    pdf = None\n",
    "    try:\n",
    "        pdf = PDFInterface(pdf_path)\n",
    "        pages = pdf.get_pages_text()\n",
    "\n",
    "        company_name = extract_company_name(pages)\n",
    "        financial_year = extract_financial_year(pages)\n",
    "\n",
    "        # STRICT ToC-only boundaries: if not deterministically resolvable from ToC lines, skip.\n",
    "        start_page, end_page = detect_mdna_boundaries(pages_text=pages, toc_start_page=None)\n",
    "\n",
    "        if not start_page or not end_page:\n",
    "            skipped_no_boundaries += 1\n",
    "            logging.warning(\"Skipping (MD&A boundaries not determinable via STRICT ToC rules): %s\", pdf_path.name)\n",
    "            continue\n",
    "\n",
    "        raw_mdna_text = extract_mdna_text(pages_text=pages, start_page=start_page, end_page=end_page)\n",
    "        cleaned_mdna_text = clean_mdna_text(raw_mdna_text)\n",
    "\n",
    "        # STRICT: pages must match the ToC-declared MD&A range exactly\n",
    "        expected_pages = end_page - start_page + 1\n",
    "        actual_pages = sum(\n",
    "            1\n",
    "            for p in pages\n",
    "            if isinstance(p.get(\"page_number\"), int) and start_page <= p.get(\"page_number\") <= end_page\n",
    "        )\n",
    "        pages_match_toc = (expected_pages == actual_pages)\n",
    "\n",
    "        quality_report = verify_mdna_quality(cleaned_mdna_text, pages_match_toc=pages_match_toc)\n",
    "\n",
    "        results.append(\n",
    "            {\n",
    "                \"company_folder\": company_folder,\n",
    "                \"company_name\": company_name,\n",
    "                \"report_file\": pdf_path.name,\n",
    "                \"financial_year\": financial_year,\n",
    "                \"mdna_text\": cleaned_mdna_text,\n",
    "                \"mdna_word_count\": quality_report.get(\"word_count\"),\n",
    "                \"narrative_density\": quality_report.get(\"narrative_density\"),\n",
    "                \"keyword_hits\": quality_report.get(\"keyword_hits\"),\n",
    "                \"quality_passed\": quality_report.get(\"quality_passed\"),\n",
    "            }\n",
    "        )\n",
    "\n",
    "        succeeded += 1\n",
    "        if quality_report.get(\"quality_passed\"):\n",
    "            passed_quality += 1\n",
    "        else:\n",
    "            flagged_quality += 1\n",
    "\n",
    "    except Exception as exc:\n",
    "        failed += 1\n",
    "        logging.exception(\"Failed processing %s: %s\", pdf_path, exc)\n",
    "\n",
    "    finally:\n",
    "        try:\n",
    "            if pdf is not None:\n",
    "                pdf.close()\n",
    "        except Exception:\n",
    "            # Ignore close errors to keep the pipeline robust.\n",
    "            pass\n",
    "\n",
    "logging.info(\"Total PDFs discovered: %d\", len(pdf_paths))\n",
    "logging.info(\"Total PDFs attempted: %d\", attempted)\n",
    "logging.info(\"Total PDFs succeeded: %d\", succeeded)\n",
    "logging.info(\"Total PDFs skipped (no STRICT ToC boundaries): %d\", skipped_no_boundaries)\n",
    "logging.info(\"Total PDFs failed: %d\", failed)\n",
    "logging.info(\"Quality checks passed: %d\", passed_quality)\n",
    "logging.info(\"Quality checks flagged: %d\", flagged_quality)\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "csv_path = output_dir / \"mdna_extracted.csv\"\n",
    "xlsx_path = output_dir / \"mdna_extracted.xlsx\"\n",
    "\n",
    "# Safe writes: Windows may lock files if they're open in Excel.\n",
    "run_stamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "try:\n",
    "    results_df.to_csv(csv_path, index=False)\n",
    "    logging.info(\"Wrote CSV: %s\", csv_path)\n",
    "except PermissionError as exc:\n",
    "    fallback_csv = output_dir / f\"mdna_extracted_{run_stamp}.csv\"\n",
    "    logging.warning(\"CSV locked (%s). Writing fallback CSV: %s\", exc, fallback_csv)\n",
    "    results_df.to_csv(fallback_csv, index=False)\n",
    "\n",
    "# Excel export needs sanitization because openpyxl rejects some control characters.\n",
    "_illegal_excel_chars_re = re.compile(r\"[\\x00-\\x08\\x0B\\x0C\\x0E-\\x1F]\")\n",
    "\n",
    "def _sanitize_for_excel(value):\n",
    "    if value is None:\n",
    "        return value\n",
    "    if isinstance(value, str):\n",
    "        return _illegal_excel_chars_re.sub(\"\", value)\n",
    "    return value\n",
    "\n",
    "excel_df = results_df.copy()\n",
    "if \"keyword_hits\" in excel_df.columns:\n",
    "    excel_df[\"keyword_hits\"] = excel_df[\"keyword_hits\"].apply(\n",
    "        lambda x: \", \".join(x) if isinstance(x, list) else x\n",
    "    )\n",
    "\n",
    "for col in excel_df.columns:\n",
    "    if excel_df[col].dtype == \"object\":\n",
    "        excel_df[col] = excel_df[col].apply(_sanitize_for_excel)\n",
    "\n",
    "try:\n",
    "    excel_df.to_excel(xlsx_path, index=False)\n",
    "    logging.info(\"Wrote Excel: %s\", xlsx_path)\n",
    "except PermissionError as exc:\n",
    "    fallback_xlsx = output_dir / f\"mdna_extracted_{run_stamp}.xlsx\"\n",
    "    logging.warning(\"Excel locked (%s). Writing fallback Excel: %s\", exc, fallback_xlsx)\n",
    "    excel_df.to_excel(fallback_xlsx, index=False)\n",
    "except Exception as exc:\n",
    "    logging.exception(\"Failed to write Excel output: %s\", exc)\n",
    "\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "87c53bf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Pipeline output summary\n",
      "- results_df shape: (12, 9)\n",
      "- quality passed: 0\n",
      "- quality flagged: 12\n"
     ]
    }
   ],
   "source": [
    "# Quick summary of how many rows were extracted\n",
    "print(\"\\nPipeline output summary\")\n",
    "print(\"- results_df shape:\", results_df.shape)\n",
    "print(\"- quality passed:\", int((results_df[\"quality_passed\"] == True).sum()) if \"quality_passed\" in results_df.columns else \"N/A\")\n",
    "print(\"- quality flagged:\", int((results_df[\"quality_passed\"] == False).sum()) if \"quality_passed\" in results_df.columns else \"N/A\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58af4447",
   "metadata": {},
   "source": [
    "### Test cell — MD&A Boundary Detection "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "eccabf06",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-30 00:01:47,457 | INFO | root | Loaded PDF: 5267070319.pdf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing MD&A boundary detection on sample PDFs:\n",
      "\n",
      "======================================================================\n",
      "Company Folder : Alcheimist\n",
      "PDF File       : 5267070319.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-30 00:01:47,845 | WARNING | root | Excluded section found but page number not aligned; ignoring exclusion: DIRECTORS’ REPORT\n",
      "2025-12-30 00:01:47,847 | INFO | root | MD&A boundaries (STRICT ToC blocks): start=23, end=100\n",
      "2025-12-30 00:01:47,853 | INFO | root | Loaded PDF: 5210700315.pdf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected MD&A Start Page: 23\n",
      "Detected MD&A End Page  : 100\n",
      "✔ Boundary detection looks valid\n",
      "======================================================================\n",
      "Company Folder : ALok\n",
      "PDF File       : 5210700315.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-30 00:01:48,463 | INFO | root | MD&A boundaries (STRICT ToC blocks): start=51, end=82\n",
      "2025-12-30 00:01:48,466 | INFO | root | Loaded PDF: 5210760315.pdf\n",
      "2025-12-30 00:01:48,627 | INFO | root | MD&A boundaries (STRICT ToC blocks): start=8, end=15\n",
      "2025-12-30 00:01:48,630 | INFO | root | Loaded PDF: 5200770316.pdf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected MD&A Start Page: 51\n",
      "Detected MD&A End Page  : 82\n",
      "✔ Boundary detection looks valid\n",
      "======================================================================\n",
      "Company Folder : Amit_spinning\n",
      "PDF File       : 5210760315.pdf\n",
      "Detected MD&A Start Page: 8\n",
      "Detected MD&A End Page  : 15\n",
      "✔ Boundary detection looks valid\n",
      "======================================================================\n",
      "Company Folder : Amtek\n",
      "PDF File       : 5200770316.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-30 00:01:48,912 | INFO | root | MD&A boundaries (STRICT ToC blocks): start=63, end=71\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected MD&A Start Page: 63\n",
      "Detected MD&A End Page  : 71\n",
      "✔ Boundary detection looks valid\n",
      "\n",
      "Boundary detection test completed.\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "PDF_ROOT = Path(\"../data/pdfs\")\n",
    "\n",
    "# Pick ONE representative PDF per company\n",
    "test_pdfs = {}\n",
    "for pdf in PDF_ROOT.rglob(\"*.pdf\"):\n",
    "    company = pdf.parent.name\n",
    "    if company not in test_pdfs:\n",
    "        test_pdfs[company] = pdf\n",
    "\n",
    "print(\"Testing MD&A boundary detection on sample PDFs:\\n\")\n",
    "\n",
    "for company, pdf_path in test_pdfs.items():\n",
    "    print(\"=\" * 70) \n",
    "    print(f\"Company Folder : {company}\")\n",
    "    print(f\"PDF File       : {pdf_path.name}\")\n",
    "\n",
    "    pdf = PDFInterface(pdf_path)\n",
    "    pages = pdf.get_pages_text()\n",
    "\n",
    "    start_page, end_page = detect_mdna_boundaries(\n",
    "        pages_text=pages,\n",
    "        toc_start_page=None\n",
    "    )\n",
    "\n",
    "    print(f\"Detected MD&A Start Page: {start_page}\")\n",
    "    print(f\"Detected MD&A End Page  : {end_page}\")\n",
    "\n",
    "    if start_page and end_page:\n",
    "        assert start_page <= end_page, \"Start page must be strictly before end page\"\n",
    "        assert 1 <= start_page <= len(pages), \"Start page out of range\"\n",
    "        assert 1 <= end_page <= len(pages), \"End page out of range\"\n",
    "        print(\"✔ Boundary detection looks valid\")\n",
    "    else:\n",
    "        print(\"⚠ MD&A boundaries not detected (may require fallback logic)\")\n",
    "\n",
    "print(\"\\nBoundary detection test completed.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "802dd04d",
   "metadata": {},
   "source": [
    "### Sanity check  after cell 4: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "38ebeec6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-30 00:02:52,892 | INFO | root | Loaded PDF: 5267070319.pdf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: c:\\Users\\LOQ\\Desktop\\SPJIMR\\mdna_extraction_project\\notebooks\n",
      "PDF_ROOT: ..\\data\\pdfs\n",
      "PDF_ROOT exists: True\n",
      "PDF_ROOT resolved: C:\\Users\\LOQ\\Desktop\\SPJIMR\\mdna_extraction_project\\data\\pdfs\n",
      "Total PDFs found: 14\n",
      "\n",
      "Sample PDFs selected for testing:\n",
      "- Alcheimist: 5267070319.pdf\n",
      "- ALok: 5210700315.pdf\n",
      "- Amit_spinning: 5210760315.pdf\n",
      "- Amtek: 5200770316.pdf\n",
      "\n",
      "--- Running Sanity Checks ---\n",
      "\n",
      "Testing company: Alcheimist\n",
      "PDF: 5267070319.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-30 00:02:53,310 | INFO | root | Extracted company name: You are requested to take the above mentioned information on your records.\n",
      "For Alchemist Limited\n",
      "2025-12-30 00:02:53,311 | INFO | root | Extracted financial year: 2018-19\n",
      "2025-12-30 00:02:53,316 | INFO | root | Loaded PDF: 5210700315.pdf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pages extracted: 145\n",
      "Extracted Company Name: You are requested to take the above mentioned information on your records.\n",
      "For Alchemist Limited\n",
      "Extracted Financial Year: 2018-19\n",
      "--------------------------------------------------\n",
      "Testing company: ALok\n",
      "PDF: 5210700315.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-30 00:02:53,995 | INFO | root | Company name not found in first 3 pages\n",
      "2025-12-30 00:02:53,996 | INFO | root | Financial year not found in first 5 pages\n",
      "2025-12-30 00:02:53,999 | INFO | root | Loaded PDF: 5210760315.pdf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pages extracted: 208\n",
      "Extracted Company Name: None\n",
      "Extracted Financial Year: None\n",
      "--------------------------------------------------\n",
      "Testing company: Amit_spinning\n",
      "PDF: 5210760315.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-30 00:02:54,216 | INFO | root | Extracted company name: AMIT SPINNING INDUSTRIES LIMITED\n",
      "2025-12-30 00:02:54,217 | INFO | root | Extracted financial year: 2014-15\n",
      "2025-12-30 00:02:54,220 | INFO | root | Loaded PDF: 5200770316.pdf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pages extracted: 46\n",
      "Extracted Company Name: AMIT SPINNING INDUSTRIES LIMITED\n",
      "Extracted Financial Year: 2014-15\n",
      "--------------------------------------------------\n",
      "Testing company: Amtek\n",
      "PDF: 5200770316.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-30 00:02:54,522 | INFO | root | Extracted company name: Bankers\n",
      "Corporation Bank\n",
      "Andhra Bank\n",
      "Indian Overseas Bank\n",
      "IDBI Bank\n",
      "Registrar & Share Transfer Agent\n",
      "Beetal Financial & Computer\n",
      "Services Pvt. Ltd.\n",
      "2025-12-30 00:02:54,522 | INFO | root | Extracted financial year: 2015-16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pages extracted: 145\n",
      "Extracted Company Name: Bankers\n",
      "Corporation Bank\n",
      "Andhra Bank\n",
      "Indian Overseas Bank\n",
      "IDBI Bank\n",
      "Registrar & Share Transfer Agent\n",
      "Beetal Financial & Computer\n",
      "Services Pvt. Ltd.\n",
      "Extracted Financial Year: 2015-16\n",
      "--------------------------------------------------\n",
      "\n",
      "Sanity check completed successfully.\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "# ---- CONFIG ----\n",
    "PDF_ROOT = Path(\"../data/pdfs\")\n",
    "\n",
    "print(f\"Current working directory: {os.getcwd()}\")\n",
    "print(f\"PDF_ROOT: {PDF_ROOT}\")\n",
    "print(f\"PDF_ROOT exists: {PDF_ROOT.exists()}\")\n",
    "print(f\"PDF_ROOT resolved: {PDF_ROOT.resolve()}\")\n",
    "\n",
    "# ---- STEP 1: Discover PDFs ----\n",
    "pdf_files = list(PDF_ROOT.rglob(\"*.pdf\"))\n",
    "\n",
    "print(f\"Total PDFs found: {len(pdf_files)}\")\n",
    "\n",
    "if not pdf_files:\n",
    "    print(\"No PDFs found in ../data/pdfs directory. Please add PDF files to test the pipeline.\")\n",
    "    print(\"Skipping sanity checks.\")\n",
    "else:\n",
    "    # Pick one PDF from each company (if available)\n",
    "    sample_pdfs = {}\n",
    "    for pdf in pdf_files:\n",
    "        company = pdf.parent.name\n",
    "        if company not in sample_pdfs:\n",
    "            sample_pdfs[company] = pdf\n",
    "\n",
    "    print(\"\\nSample PDFs selected for testing:\")\n",
    "    for company, pdf in sample_pdfs.items():\n",
    "        print(f\"- {company}: {pdf.name}\")\n",
    "\n",
    "    # ---- STEP 2: Test PDFInterface + Metadata Extraction ----\n",
    "    print(\"\\n--- Running Sanity Checks ---\\n\")\n",
    "\n",
    "    for company, pdf_path in sample_pdfs.items():\n",
    "        print(f\"Testing company: {company}\")\n",
    "        print(f\"PDF: {pdf_path.name}\")\n",
    "\n",
    "        pdf = PDFInterface(pdf_path)\n",
    "        pages = pdf.get_pages_text()\n",
    "\n",
    "        print(\"Pages extracted:\", len(pages))\n",
    "        assert len(pages) > 0, \"No pages extracted!\"\n",
    "\n",
    "        # Metadata extraction\n",
    "        extracted_company = extract_company_name(pages)\n",
    "        extracted_year = extract_financial_year(pages)\n",
    "\n",
    "        print(\"Extracted Company Name:\", extracted_company)\n",
    "        print(\"Extracted Financial Year:\", extracted_year)\n",
    "\n",
    "        print(\"-\" * 50)\n",
    "\n",
    "    print(\"\\nSanity check completed successfully.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
